{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19156,"status":"ok","timestamp":1707321307505,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"},"user_tz":300},"id":"ZvEaSkDvuLpf","outputId":"ec7ec3e2-4f55-4535-f5d7-f639fdc5b98f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"9fcbb8bju5AR"},"source":["# Data Loader"]},{"cell_type":"code","source":[],"metadata":{"id":"Dr8pyxf2Jyc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Oc-K3qrYuMUa","executionInfo":{"status":"ok","timestamp":1707321312366,"user_tz":300,"elapsed":4864,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","def prepare_data_main_model(df, seq_length, output_size, date_range):\n","    '''\n","    df: pandas df contain all the data\n","    seq_length: number of days consider as input\n","    output_size: number of days to predict\n","    date_range: length of history to consider\n","    Output:\n","    - full_data: Prepared data as a list of tuples (input_sequence, target_labels).\n","    - state_ordered: List of unique states in the data.\n","    '''\n","    full_data = []\n","    state_ordered = []\n","\n","    for state in df.index.get_level_values('fips').unique():\n","        df_state = df.iloc[df.index.get_level_values('fips') == state]\n"," # If the length of data is less than or equal to date_range, consider all data\n","        if len(df_state) <= date_range:\n","            L = len(df_state.to_numpy())\n","            train_state = []\n","            for i in range(L - seq_length - output_size + 1):\n","                train_seq = df_state.to_numpy()[i:i + seq_length]\n","                train_label = df_state.to_numpy()[i:i + seq_length + output_size][seq_length:seq_length + output_size,\n","                              0]\n","                train_state.append((train_seq, train_label))\n","\n","            for x in train_state:\n","                full_data.append(x)\n","            state_ordered.append(state)\n","# If data is larger than date_range, consider the most recent date_range data\n","        else:\n","            df_state = df.iloc[df.index.get_level_values('fips') == state][-date_range:]\n","\n","            train_state = []\n","\n","            L = len(df_state.to_numpy())\n","            for i in range(L - seq_length - output_size + 1):\n","                train_seq = df_state.to_numpy()[i:i + seq_length]\n","                train_label = df_state.to_numpy()[i:i + seq_length + output_size][seq_length:seq_length + output_size,\n","                              0]\n","                train_state.append((train_seq, train_label))\n","\n","            for x in train_state:\n","                full_data.append(x)\n","            state_ordered.append(state)\n","    return full_data, state_ordered\n","\n","def splitdata(full_data, ratio, batch_size):\n","    '''\n","    Split the prepared data into training and testing datasets.\n","\n","    Parameters:\n","    - full_data: Prepared data as a list of tuples (input_sequence, target_labels).\n","    - ratio: Ratio of data to be used for training (e.g., 0.8 for 80% training, 20% testing).\n","    - batch_size: Size of mini-batches for DataLoader.\n","\n","    Output:\n","    - train_loader: DataLoader for the training dataset.\n","    - test_loader: DataLoader for the testing dataset.\n","    '''\n","    train_size = int(ratio * len(full_data))\n","    test_size = len(full_data) - train_size\n","    train_dataset, test_dataset = torch.utils.data.random_split(full_data, [train_size, test_size])\n","\n","    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                               batch_size=batch_size,\n","                                               shuffle=True, drop_last=True)\n","\n","    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                              batch_size=batch_size,\n","                                              shuffle=True, drop_last=True)\n","\n","    return train_loader, test_loader\n","\n","#gd = pd.read_csv('/content/drive/MyDrive/Flu Forecasting/code/groundtruth.csv')\n","gd = pd.read_csv('/content/drive/MyDrive/Flu Forecasting/code/groundtruth2m.csv')\n","gd['Week_end']  = pd.to_datetime(gd['Week_end'])\n"]},{"cell_type":"markdown","metadata":{"id":"JVxTwmywwvbl"},"source":["# Models"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EdF6LDM3wqoP","executionInfo":{"status":"ok","timestamp":1707321312367,"user_tz":300,"elapsed":6,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}}},"outputs":[],"source":["import torch\n","import pandas as pd\n","from torch import nn\n","import torch.nn.functional as F\n","pd.options.mode.chained_assignment = None"]},{"cell_type":"markdown","metadata":{"id":"CMCyfjPuwyR4"},"source":["## LSTM"]},{"cell_type":"markdown","source":["### Target: Rate ( rate = total admission * 100000/population) Current Version!!!"],"metadata":{"id":"Lw6GHLIXrUQb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1hbX1SyfrUQl"},"outputs":[],"source":["\n","\n","class LSTM(nn.Module):\n","\n","    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout_rate):\n","        super().__init__()\n","\n","        self.input_size = input_size\n","\n","        self.hidden_layer_size = hidden_layer_size\n","\n","        self.num_layers = num_layers\n","\n","        self.output_size = output_size\n","\n","        self.lstm = nn.LSTM(self.input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_rate)\n","\n","        self.linear = nn.Linear(hidden_layer_size, 1000)\n","\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        self.linear2 = nn.Linear(1000, output_size)\n","\n","    def forward(self, input_seq):\n","        h = (torch.zeros(self.num_layers, input_seq.size(0), self.hidden_layer_size).to(device),\n","             torch.zeros(self.num_layers, input_seq.size(0), self.hidden_layer_size).to(device))\n","\n","        lstm_out, self.hidden_cell = self.lstm(input_seq, h)\n","\n","        # only return the results for last sequence\n","        lstm_out = lstm_out[:, -1, :]\n","        predictions = self.linear(lstm_out)\n","        #predictions = F.relu(predictions)\n","        #predictions = F.softplus(predictions)\n","        predictions = F.leaky_relu(predictions, negative_slope=0.01)\n","        predictions = self.dropout(predictions)\n","        predictions = self.linear2(predictions)\n","\n","        return predictions"]},{"cell_type":"markdown","metadata":{"id":"bHhO3Ua3rUQl"},"source":["#### Main\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707318896974,"user_tz":300,"elapsed":3906717,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}},"outputId":"3b3f4950-f262-494f-db9d-e1a7083f852d","id":"0QcAMaHYrUQl"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","  2%|▏         | 1/50 [00:01<00:58,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  186.36368022114038\n","Test Loss:  50.24806038476527\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:57,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.66013035550714\n","Test Loss:  43.47965035121888\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:54,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  118.76577382907271\n","Test Loss:  35.48719818610698\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:53,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  93.59923825971782\n","Test Loss:  32.543324056779966\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:52,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.2637702608481\n","Test Loss:  25.094330733059905\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:07<00:51,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.988613720517606\n","Test Loss:  26.332708533620462\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:50,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  58.72301013302058\n","Test Loss:  22.50436907209223\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:48,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.5730148232542\n","Test Loss:  21.370381037064362\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:48,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.102509489282966\n","Test Loss:  20.87107097171247\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:47,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.329996249987744\n","Test Loss:  20.2079427203862\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:46,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.25703727756627\n","Test Loss:  19.716355271055363\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:14<00:46,  1.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.64345344569301\n","Test Loss:  20.281267781334464\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:15<00:44,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  50.78621922375169\n","Test Loss:  19.828386271721683\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:16<00:42,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.77029148582369\n","Test Loss:  18.79087724693818\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:41,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.000519901746884\n","Test Loss:  18.579199436760973\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:39,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.469594253983814\n","Test Loss:  17.6514772757655\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:19<00:38,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.2897169443313\n","Test Loss:  17.998083037673496\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:21<00:37,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  48.74842760665342\n","Test Loss:  17.975571057002526\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:22<00:35,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.57175063510658\n","Test Loss:  16.666865680890623\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:23<00:34,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.2112502483069\n","Test Loss:  16.368381858075736\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:24<00:33,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.204590057139285\n","Test Loss:  16.03480208030669\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:25<00:32,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.26450482418295\n","Test Loss:  16.99456899811048\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:26<00:30,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.60670147836208\n","Test Loss:  15.780858688580338\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:27<00:29,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.133473061490804\n","Test Loss:  15.970064134744462\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:29<00:28,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.75460903701605\n","Test Loss:  15.384622405603295\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:30<00:26,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.68871056614444\n","Test Loss:  15.67283711064374\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:31<00:26,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.68351270467974\n","Test Loss:  15.604445333243348\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:32<00:26,  1.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  41.07726382941473\n","Test Loss:  16.279994115117006\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:33<00:24,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.82749404074275\n","Test Loss:  15.281581731396727\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:34<00:23,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.0759240774787\n","Test Loss:  15.022616516565904\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:36<00:22,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.30650191893801\n","Test Loss:  15.052307642268715\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:37<00:21,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.89230198954465\n","Test Loss:  15.470627182949102\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:38<00:19,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  41.460270696203224\n","Test Loss:  15.271857952466235\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:39<00:18,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.88789149816148\n","Test Loss:  14.882430655357894\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:40<00:17,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.00183134630788\n","Test Loss:  15.115087618702091\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:41<00:16,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.09176025004126\n","Test Loss:  14.579700208210852\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:43<00:15,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.934058075305074\n","Test Loss:  14.885544243035838\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:44<00:13,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.80506942898501\n","Test Loss:  15.364438838150818\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:45<00:12,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.58020655642031\n","Test Loss:  14.490087096230127\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:46<00:11,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.11586278176401\n","Test Loss:  16.0025546932593\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:47<00:10,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.94170384469908\n","Test Loss:  14.39979499205947\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:48<00:09,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.06994946268969\n","Test Loss:  14.717379909008741\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:50<00:08,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.08714292763034\n","Test Loss:  14.36152801438584\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:51<00:07,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.8095065933303\n","Test Loss:  14.122844489655108\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:52<00:05,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.95063156314427\n","Test Loss:  14.436880525492597\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:53<00:04,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.38913321780274\n","Test Loss:  14.440737420576625\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [00:54<00:03,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.99163476761896\n","Test Loss:  13.981363426719327\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [00:55<00:02,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.044465811457485\n","Test Loss:  13.959780732751824\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 49/50 [00:56<00:01,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.78676694072783\n","Test Loss:  14.24614815559471\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:57<00:00,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.460087222920265\n","Test Loss:  16.423526907456107\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8500822632914325\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:57,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  153.50920113921165\n","Test Loss:  44.24602126982063\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:56,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  105.4912085160613\n","Test Loss:  29.720274740131572\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:55,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.39634855347686\n","Test Loss:  24.93978568603052\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:54,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.03216539230198\n","Test Loss:  23.536835227976553\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:53,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.74721504561603\n","Test Loss:  21.792911726544844\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:07<00:51,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.19743626576383\n","Test Loss:  21.162250548019074\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:50,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.4301608807873\n","Test Loss:  20.8090840424411\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:48,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.28051282238448\n","Test Loss:  23.923967393580824\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:47,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.16184073878685\n","Test Loss:  19.8819331144623\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:45,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  49.62584172911011\n","Test Loss:  21.01207843638258\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:44,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.60674729238963\n","Test Loss:  22.168515293800738\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:44,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.18966605619062\n","Test Loss:  18.389102315995842\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:15<00:42,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.5776690733619\n","Test Loss:  18.564699632232077\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:16<00:41,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.38269392284565\n","Test Loss:  18.736449613352306\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:40,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  45.57615219120635\n","Test Loss:  18.46803610699135\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:39,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.01887058275133\n","Test Loss:  18.0296896348882\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:19<00:38,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.40692106974893\n","Test Loss:  18.000604196538916\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:20<00:37,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.1631789697567\n","Test Loss:  17.13860153319547\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:22<00:36,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.02124815294519\n","Test Loss:  17.56100594988675\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:23<00:34,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.032242879795376\n","Test Loss:  17.91586230963003\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:24<00:33,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.15136144057033\n","Test Loss:  16.69046234700363\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:25<00:32,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.87476804945618\n","Test Loss:  17.44690158148296\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:26<00:31,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.92480296976282\n","Test Loss:  16.570148576633073\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:27<00:29,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.28911670847447\n","Test Loss:  17.56725733933854\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:28<00:28,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.3920816447353\n","Test Loss:  16.582691066985717\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:30<00:27,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.65744661167264\n","Test Loss:  16.803948896122165\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:31<00:26,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.31308617582545\n","Test Loss:  16.00648401817307\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:32<00:25,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.83083452936262\n","Test Loss:  16.646026022383012\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:33<00:24,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.504711962188594\n","Test Loss:  17.761535506986547\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:34<00:23,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.55167218344286\n","Test Loss:  15.861266078252811\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:35<00:22,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.94391196902143\n","Test Loss:  15.738350854779128\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:37<00:21,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.394721961114556\n","Test Loss:  15.635803569515701\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:38<00:19,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.34540447848849\n","Test Loss:  15.907854057441\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:39<00:18,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.12381102505606\n","Test Loss:  16.08846555434866\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:40<00:17,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.058443278307095\n","Test Loss:  15.771579281048616\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:41<00:16,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.30710611137329\n","Test Loss:  16.2202325098624\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:42<00:16,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  35.422977850510506\n","Test Loss:  17.62472233083099\n","Early stopping with best_loss:  15.635803569515701 and test_loss for this epoch:  17.62472233083099 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9528001349065489\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<01:00,  1.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  131.06326911598444\n","Test Loss:  36.79114293353632\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:59,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  87.15061368327588\n","Test Loss:  26.346799868391827\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:58,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.33232261799276\n","Test Loss:  20.765948105836287\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:05<00:58,  1.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.49018874205649\n","Test Loss:  25.61647424387047\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:06<00:57,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  57.45536756294314\n","Test Loss:  22.300751720031258\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:07<00:55,  1.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.597256216569804\n","Test Loss:  18.355757931509288\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:54,  1.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.82964660262223\n","Test Loss:  19.713496658107033\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:10<00:53,  1.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  52.9510629682336\n","Test Loss:  19.995813932764577\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:11<00:51,  1.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.778143875999376\n","Test Loss:  16.550653124868404\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:12<00:50,  1.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.97763959597796\n","Test Loss:  16.660931625345256\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:13<00:49,  1.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.60400990478229\n","Test Loss:  15.679089419034426\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:15<00:47,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.70508561254246\n","Test Loss:  15.956141801085323\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:16<00:46,  1.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.69551294168923\n","Test Loss:  14.67375977296615\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:17<00:45,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.71449085633503\n","Test Loss:  14.812747176038101\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:19<00:44,  1.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.62602103303652\n","Test Loss:  14.256799466034863\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:20<00:43,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.38163013057783\n","Test Loss:  14.467868682113476\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:21<00:42,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.001738016318996\n","Test Loss:  15.159538431325927\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:22<00:40,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  41.35939987003803\n","Test Loss:  15.303949621506035\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:24<00:39,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  41.61036237096414\n","Test Loss:  15.265581736632157\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:25<00:38,  1.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.43818105949322\n","Test Loss:  13.66333909064997\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:26<00:36,  1.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.15363274799893\n","Test Loss:  16.13734365813434\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:27<00:35,  1.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.033328330144286\n","Test Loss:  17.394675794872455\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:29<00:34,  1.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  37.41715686052339\n","Test Loss:  14.283017619978637\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:30<00:32,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  37.668146816140506\n","Test Loss:  13.855661926674657\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:31<00:34,  1.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  38.33892502845265\n","Test Loss:  14.245954435435124\n","Early stopping with best_loss:  13.66333909064997 and test_loss for this epoch:  14.245954435435124 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8001778928340749\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:14,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  320.44774841796607\n","Test Loss:  90.8315560259507\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:11,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  196.52502087736502\n","Test Loss:  77.03314055723604\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:08,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.56068171118386\n","Test Loss:  68.0108656337834\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:04,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.88100787380245\n","Test Loss:  58.741009588120505\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:01,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  116.71239028999116\n","Test Loss:  50.33765660808422\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<01:59,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  108.18385822576238\n","Test Loss:  46.08654081315035\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<01:56,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  99.53024420060683\n","Test Loss:  42.28273364919005\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:54,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  93.66697938099969\n","Test Loss:  42.32436210819287\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:51,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  92.08004964119755\n","Test Loss:  38.96984975007945\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:48,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  89.10629697775585\n","Test Loss:  38.77742295508506\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:29<01:45,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  89.17902821581811\n","Test Loss:  35.9914897702256\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:43,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  83.35104484023759\n","Test Loss:  34.77166183013469\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:35<01:39,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.00740360777127\n","Test Loss:  34.309904400171945\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:37<01:36,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.13950176886283\n","Test Loss:  33.57951653422788\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:40<01:34,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.38153606356354\n","Test Loss:  32.14672881655861\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:43<01:31,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  78.85615700035123\n","Test Loss:  33.366463698097505\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:46<01:29,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.02366256626556\n","Test Loss:  31.253961955400882\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:48<01:26,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  75.1543623325997\n","Test Loss:  32.920943409902975\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:51<01:23,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  72.53528676810674\n","Test Loss:  31.389178301920765\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:54<01:20,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.54072694195202\n","Test Loss:  30.448654678999446\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:56<01:17,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  70.867676765949\n","Test Loss:  30.953912952896644\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:59<01:15,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  69.87608568422729\n","Test Loss:  30.781975397316273\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:02<01:12,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  69.0120356073603\n","Test Loss:  32.56441355415154\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:04<01:09,  2.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  71.03944178496022\n","Test Loss:  31.198574862850364\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:07<01:13,  2.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  71.92238067105063\n","Test Loss:  31.162705637325416\n","Early stopping with best_loss:  30.448654678999446 and test_loss for this epoch:  31.162705637325416 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7803343429641552\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:12,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  262.3943213536404\n","Test Loss:  88.47422588872723\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:09,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  176.32788387546316\n","Test Loss:  73.44465916987974\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:06,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  145.38198431080673\n","Test Loss:  57.219645550474524\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:03,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  121.17915338964667\n","Test Loss:  48.096555369731504\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:01,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  104.83798293341533\n","Test Loss:  43.25870141640189\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<01:59,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  92.97905662690755\n","Test Loss:  45.96560067750397\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:56,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  91.32114099050523\n","Test Loss:  42.03950536123011\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:54,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.65062988398131\n","Test Loss:  37.0056380139431\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:51,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  84.50354948820313\n","Test Loss:  35.58759922639001\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:48,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  78.79569727688795\n","Test Loss:  37.11924361571437\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:29<01:45,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  80.2602526374103\n","Test Loss:  37.865156872954685\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:42,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.85887478050427\n","Test Loss:  33.56586985947797\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:35<01:41,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  74.7611586608109\n","Test Loss:  35.1229476207227\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:38,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.32741308846744\n","Test Loss:  31.17071871936787\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:40<01:35,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  71.36648314184276\n","Test Loss:  31.70774960203562\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:43<01:31,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.91673077089945\n","Test Loss:  30.551025273365667\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:46<01:29,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  69.21564449381549\n","Test Loss:  35.076865200171596\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:48<01:27,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.89492355124094\n","Test Loss:  30.320889881360927\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:51<01:24,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  69.77145480393665\n","Test Loss:  30.417193495537504\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:54<01:21,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.37099162102095\n","Test Loss:  29.57536829118908\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:56<01:18,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  65.55813063320238\n","Test Loss:  29.645209187699948\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:59<01:15,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.29069292379427\n","Test Loss:  28.347266068216413\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:02<01:13,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  64.94221603788901\n","Test Loss:  29.7069321005838\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:05<01:10,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  64.26450774568366\n","Test Loss:  30.222228207276203\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:07<01:07,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  64.89029691909673\n","Test Loss:  29.112143908510916\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:10<01:04,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.10523964141612\n","Test Loss:  27.77913848561002\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:13<01:01,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  62.372169233975\n","Test Loss:  27.786221069982275\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:15<00:59,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.05678914033342\n","Test Loss:  26.92394910719304\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:18<00:57,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  61.67813802935416\n","Test Loss:  28.463536113442387\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:21<00:54,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  65.85826521726267\n","Test Loss:  27.385359878797317\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:24<00:51,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  62.49861827713903\n","Test Loss:  26.962297300458886\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:26<00:48,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  61.24842076128698\n","Test Loss:  27.487322538843728\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:29<00:50,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  65.69461045178468\n","Test Loss:  30.798046310985228\n","Early stopping with best_loss:  26.92394910719304 and test_loss for this epoch:  30.798046310985228 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6539241045872936\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:25,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  226.83857451938093\n","Test Loss:  77.42279886920005\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:22,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.72630624019075\n","Test Loss:  49.42064723803196\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:18,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  108.93223187117837\n","Test Loss:  41.59171875123866\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:15,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  95.96438428305555\n","Test Loss:  36.871848913920985\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:13,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  89.59729197708657\n","Test Loss:  36.113545298954705\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:10,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  88.36327513388824\n","Test Loss:  32.85532206183416\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:07,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  82.25733415814466\n","Test Loss:  33.61662505730055\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:23<02:03,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.83603701647371\n","Test Loss:  30.23621961614117\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:26<02:00,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.09942437504651\n","Test Loss:  28.927428836148465\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:29<01:57,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  73.63868641745648\n","Test Loss:  33.104432948020985\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:32<01:54,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  76.1339821931906\n","Test Loss:  30.011686820245814\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:35<01:51,  2.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  74.00624907563906\n","Test Loss:  29.829358614777448\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:38<01:48,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.77908125764225\n","Test Loss:  27.10220928414492\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:41<01:45,  2.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  65.9176155369496\n","Test Loss:  27.647999432694633\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:44<01:42,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  68.5816559845116\n","Test Loss:  31.503144967195112\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:47<01:40,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.788622730317\n","Test Loss:  25.766143288230523\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:50<01:37,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  68.850370015105\n","Test Loss:  26.473700519185513\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:53<01:34,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  66.19687333967886\n","Test Loss:  26.188219494069926\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:56<01:31,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  66.86087022116408\n","Test Loss:  30.315881880553206\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:58<01:28,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.04415938432794\n","Test Loss:  24.446528053085785\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:01<01:25,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.14952011458809\n","Test Loss:  24.29598741661175\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:04<01:22,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.96749664239178\n","Test Loss:  27.468564334049006\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:07<01:19,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.70870907837525\n","Test Loss:  24.100046545441728\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:10<01:15,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  61.74156307143858\n","Test Loss:  27.193584462831495\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:13<01:13,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  58.3355798068078\n","Test Loss:  25.3694645431533\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:16<01:10,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.73318597429898\n","Test Loss:  23.217127101685037\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:19<01:07,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.76949304252048\n","Test Loss:  24.280199720051314\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:22<01:04,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  60.7498580365791\n","Test Loss:  24.100669979277882\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:25<01:01,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  59.80099248053739\n","Test Loss:  24.411890957853757\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:28<00:58,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  61.952336455651675\n","Test Loss:  24.086523452133406\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:31<01:00,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  59.3710893860989\n","Test Loss:  23.299345891311532\n","Early stopping with best_loss:  23.217127101685037 and test_loss for this epoch:  23.299345891311532 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5373200195649046\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:39,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  509.49169622082263\n","Test Loss:  147.22946973936632\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:37,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  331.8792960019782\n","Test Loss:  127.52145473961718\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:34,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  273.525681950734\n","Test Loss:  111.89429896243382\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:31,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  242.99492955120513\n","Test Loss:  101.24468847067328\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:28,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  224.82210688700434\n","Test Loss:  92.36922644247534\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:25,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  213.7722871408332\n","Test Loss:  85.42820695001865\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:21,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  198.57831673137844\n","Test Loss:  81.54789764335146\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:26<02:18,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  190.65711691670003\n","Test Loss:  83.06797677942086\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:14,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  187.85481752781197\n","Test Loss:  73.97786781814648\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:32<02:11,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  178.02807704691077\n","Test Loss:  71.5829237649159\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:36<02:07,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  174.8380680117989\n","Test Loss:  70.28483614086872\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:39<02:04,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  169.05027368868468\n","Test Loss:  65.524538720696\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:42<02:02,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.17566641012672\n","Test Loss:  64.45036673295544\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:46<01:58,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  164.47362026042538\n","Test Loss:  62.41024010523688\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:49<01:55,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  160.93650120924576\n","Test Loss:  61.69056507345522\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:52<01:52,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  161.843011583318\n","Test Loss:  61.12778437054658\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:56<01:49,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  155.13157201569993\n","Test Loss:  61.318123008008115\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:59<01:45,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  151.9362595412531\n","Test Loss:  63.235949919209816\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:02<01:41,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.72859891777625\n","Test Loss:  58.40393855131697\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:05<01:37,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  148.78798782848753\n","Test Loss:  60.69133310060715\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:08<01:34,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.43129605217837\n","Test Loss:  57.082830112369265\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:12<01:30,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  145.8522788133996\n","Test Loss:  59.810851747053675\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:15<01:28,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  148.97777498158393\n","Test Loss:  59.033101897119195\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:18<01:24,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  145.10353662556736\n","Test Loss:  65.58742351204273\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:21<01:21,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  143.53248252550839\n","Test Loss:  62.44495593433385\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:25<01:25,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  139.92799597833073\n","Test Loss:  62.51841668470297\n","Early stopping with best_loss:  57.082830112369265 and test_loss for this epoch:  62.51841668470297 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.2799054022105711\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:41,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  424.73143862048164\n","Test Loss:  135.93495170772076\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:38,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  298.5609013015637\n","Test Loss:  101.40417445864296\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:35,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  241.81576203077566\n","Test Loss:  93.90392670279834\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:33,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  202.88659624697175\n","Test Loss:  79.65483355819015\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:29,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  195.9667890681303\n","Test Loss:  74.29371158691356\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:25,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  184.92072846216615\n","Test Loss:  71.22271239841939\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:22,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  173.762791264744\n","Test Loss:  70.16902798367664\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:26<02:20,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  177.00841305661015\n","Test Loss:  66.67538152163615\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:16,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  161.64174726087367\n","Test Loss:  67.07863269175868\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:33<02:12,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  160.50357395387255\n","Test Loss:  61.80342366086552\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:36<02:08,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.76943402551115\n","Test Loss:  59.962027685018256\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:39<02:05,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.72222109913127\n","Test Loss:  58.68520646227989\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:43<02:02,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.82812155227293\n","Test Loss:  58.10561333791702\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:46<01:57,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  148.59064954373753\n","Test Loss:  58.41663717193296\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:49<01:54,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  146.3137399219995\n","Test Loss:  62.3384425934928\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:52<01:51,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  147.16538970803958\n","Test Loss:  58.705879403161816\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:56<01:48,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.30870809784392\n","Test Loss:  55.53330122883199\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:59<01:45,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.2084561775846\n","Test Loss:  54.501986022194615\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:02<01:42,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.62462997589319\n","Test Loss:  54.38011759018991\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:05<01:38,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  134.00465120060835\n","Test Loss:  52.15072291108663\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:09<01:35,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  138.0528697114787\n","Test Loss:  53.82797895357362\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:12<01:32,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  136.94046735294978\n","Test Loss:  54.1679001901357\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:15<01:28,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.01842703175498\n","Test Loss:  52.09570539870765\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:19<01:25,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  134.12190136345453\n","Test Loss:  52.41418542840984\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:22<01:21,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  131.39864648802904\n","Test Loss:  53.604856833582744\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:25<01:18,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  131.51735172467306\n","Test Loss:  60.841982495301636\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:29<01:15,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.4804969834222\n","Test Loss:  49.85982697720465\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:32<01:12,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  127.48318820731947\n","Test Loss:  52.13245634108898\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:35<01:08,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  128.00123685155995\n","Test Loss:  51.77606783906231\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:38<01:05,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  127.5822469346167\n","Test Loss:  49.6374963914277\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:42<01:02,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  127.04481779609341\n","Test Loss:  49.42914755328093\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:45<00:58,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  127.16265702265082\n","Test Loss:  53.6401663828874\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:48<00:55,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  125.65217875293456\n","Test Loss:  48.25906975008547\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:51<00:52,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  123.66778803651687\n","Test Loss:  49.80737865658011\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:55<00:49,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  122.6022540932172\n","Test Loss:  48.24674239032902\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:58<00:46,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  121.98759969256935\n","Test Loss:  50.46763860381907\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [02:01<00:42,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  118.43350963047124\n","Test Loss:  49.96192310562765\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [02:05<00:39,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  121.47528597773635\n","Test Loss:  48.24960759683745\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [02:08<00:36,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  121.79129049775656\n","Test Loss:  49.67975573326112\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [02:11<00:37,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  117.94329779061081\n","Test Loss:  52.744225815928075\n","Early stopping with best_loss:  48.24674239032902 and test_loss for this epoch:  52.744225815928075 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0729399073329569\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:52,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  376.0965503046755\n","Test Loss:  117.65319172176532\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:07<02:49,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  265.9350220991764\n","Test Loss:  86.50890748132952\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:47,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  212.33663626376074\n","Test Loss:  77.4937741458707\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:14<02:43,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  190.03821584105026\n","Test Loss:  70.27495316852583\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:17<02:38,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  178.09684233908774\n","Test Loss:  76.04396231111605\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:21<02:37,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.8445695923292\n","Test Loss:  64.78597620513756\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:24<02:33,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  161.4718413571827\n","Test Loss:  64.92824846704025\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:28<02:28,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.3374283547164\n","Test Loss:  60.329265208216384\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:31<02:25,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.70544448724831\n","Test Loss:  59.90247517482203\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:35<02:21,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  145.74053431881475\n","Test Loss:  61.76117256726138\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:39<02:18,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.74944688472897\n","Test Loss:  58.377930325921625\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:42<02:14,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.13898598225205\n","Test Loss:  59.201307449431624\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:46<02:10,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.71637439227197\n","Test Loss:  54.6847152649716\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:49<02:07,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  140.50212691762135\n","Test Loss:  65.35847784849466\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:53<02:04,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.18280942199635\n","Test Loss:  53.59620625487878\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:56<02:01,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.08860244069365\n","Test Loss:  54.76467728908756\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [01:00<01:57,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.81008184803068\n","Test Loss:  56.99735278438311\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:03<01:53,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.45681475132005\n","Test Loss:  52.73110928758979\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:07<01:50,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  131.13786290059215\n","Test Loss:  55.02709403989138\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:11<01:46,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.8399557042867\n","Test Loss:  51.52181540406309\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:14<01:43,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  128.88346151920268\n","Test Loss:  56.27856144472025\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:18<01:38,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  129.0202076327405\n","Test Loss:  59.2370932008489\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:21<01:36,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  130.22902777726995\n","Test Loss:  67.33827861768077\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:25<01:32,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  123.85663083638065\n","Test Loss:  53.224620116787264\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:28<01:28,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  125.32415736067924\n","Test Loss:  50.15313392592361\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:32<01:25,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  124.2468892048928\n","Test Loss:  51.7330657618586\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:35<01:21,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.84830435665208\n","Test Loss:  49.82019733308698\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:39<01:18,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.47440502390964\n","Test Loss:  49.11454658355797\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:43<01:15,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  118.10882749577286\n","Test Loss:  47.66787469336123\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:46<01:11,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  121.83150028536329\n","Test Loss:  53.08829764346592\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:50<01:08,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  122.67990155093139\n","Test Loss:  52.47229926404543\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:54<01:04,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  123.02365016224212\n","Test Loss:  52.696480472237454\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:57<01:01,  3.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  120.51693632427487\n","Test Loss:  47.86988254825701\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [02:01<01:02,  3.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  118.58993602913688\n","Test Loss:  51.58064002869651\n","Early stopping with best_loss:  47.66787469336123 and test_loss for this epoch:  51.58064002869651 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9934486222546515\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:52,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  184.76693292707205\n","Test Loss:  44.358424589037895\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:50,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.54486870020628\n","Test Loss:  36.911347980145365\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:50,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  115.70806895196438\n","Test Loss:  29.404894420411438\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:49,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  89.94506554771215\n","Test Loss:  24.3244406869635\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:48,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.89507532678545\n","Test Loss:  22.867244117805967\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:46,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.82957437308505\n","Test Loss:  20.337491840822622\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:45,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.14419311773963\n","Test Loss:  20.07515747193247\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:43,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  59.26882459037006\n","Test Loss:  21.39577696926426\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:42,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.898934880737215\n","Test Loss:  18.391801616468\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:41,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.92008166445885\n","Test Loss:  17.96128789515933\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:40,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.63186553923879\n","Test Loss:  17.798183214035816\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:12<00:39,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.34822025115136\n","Test Loss:  17.71505716291722\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:13<00:38,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.91599706199486\n","Test Loss:  17.08747020503506\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:14<00:37,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.008909631404094\n","Test Loss:  16.92220468528103\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:15<00:36,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.66518719820306\n","Test Loss:  18.76012661634013\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:16<00:36,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.556271382723935\n","Test Loss:  16.217252814676613\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:17<00:35,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.8830850495724\n","Test Loss:  16.28384997328976\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:18<00:33,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  47.38080878270557\n","Test Loss:  17.164038040849846\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:20<00:33,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.34191136463778\n","Test Loss:  15.633600262342952\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:21<00:31,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.33128597284667\n","Test Loss:  16.782422480056994\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:22<00:30,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.88426178274676\n","Test Loss:  15.904429278045427\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:23<00:29,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  46.0201434053306\n","Test Loss:  16.06998343410669\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:24<00:27,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  45.27383425628068\n","Test Loss:  15.79387462802697\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:25<00:26,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.63572872977238\n","Test Loss:  15.58461416355567\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:26<00:25,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.865498380037025\n","Test Loss:  14.723929757252336\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:27<00:24,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.55346014170209\n","Test Loss:  17.93440660799388\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:28<00:23,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.077367705642246\n","Test Loss:  14.714190792350564\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:29<00:22,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.75662887538783\n","Test Loss:  16.25307810585946\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:30<00:21,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.997604819363914\n","Test Loss:  15.01594611722976\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:31<00:20,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.429692281235475\n","Test Loss:  14.554595155175775\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:32<00:19,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.75820734485751\n","Test Loss:  16.144260867033154\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:33<00:18,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.19584257516544\n","Test Loss:  14.178160540701356\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:34<00:17,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.79529365809867\n","Test Loss:  14.565202079014853\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:35<00:16,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.70794254555949\n","Test Loss:  14.215165748028085\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:36<00:15,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.785032468964346\n","Test Loss:  13.930709124484565\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:37<00:14,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.06628032028675\n","Test Loss:  13.791899992036633\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:38<00:13,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.55878158577252\n","Test Loss:  13.90052962617483\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:39<00:12,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.37719717921573\n","Test Loss:  13.873290482792072\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:40<00:11,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.42623088270193\n","Test Loss:  15.53100974598783\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:41<00:10,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.37911709700711\n","Test Loss:  13.631915603182279\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:42<00:09,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.99433794867946\n","Test Loss:  13.66919218772091\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:43<00:08,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.33214701100951\n","Test Loss:  13.30520373271429\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:44<00:07,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.30691549167386\n","Test Loss:  13.328881213325076\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:45<00:06,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.76870373549173\n","Test Loss:  14.068422041134909\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:46<00:05,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.02473969530547\n","Test Loss:  14.588261564087588\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:47<00:04,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  38.027469848282635\n","Test Loss:  13.657274682773277\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:48<00:04,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  38.26645412208745\n","Test Loss:  13.442556341935415\n","Early stopping with best_loss:  13.30520373271429 and test_loss for this epoch:  13.442556341935415 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8551785437594375\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:52,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.82923643104732\n","Test Loss:  51.35347791202366\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:51,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  101.09338290337473\n","Test Loss:  39.38855210412294\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:50,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.89357749535702\n","Test Loss:  32.32398018508684\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:48,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.62273398414254\n","Test Loss:  29.879002486122772\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:47,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.92578177526593\n","Test Loss:  27.030285964370705\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:45,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.78902302053757\n","Test Loss:  27.35638892138377\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:44,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.51344509026967\n","Test Loss:  26.314375094079878\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:43,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.75957269396167\n","Test Loss:  27.628762157808524\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:42,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.320441846735775\n","Test Loss:  25.19535590754822\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:41,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.43058688112069\n","Test Loss:  24.71478681784356\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:41,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.81828547769692\n","Test Loss:  23.736484276130795\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:12<00:40,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.33751912531443\n","Test Loss:  23.523774710221915\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:13<00:39,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.43802469968796\n","Test Loss:  22.398449407686712\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:14<00:38,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.966946365719195\n","Test Loss:  22.474711907678284\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:15<00:37,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.386849761067424\n","Test Loss:  21.95139339240268\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:16<00:36,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.60892543772934\n","Test Loss:  22.68390247685602\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:17<00:35,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.11270461094682\n","Test Loss:  21.39293714769883\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:19<00:33,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.80169752589427\n","Test Loss:  20.89142641961371\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:20<00:32,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.06813374068588\n","Test Loss:  20.8905717888847\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:21<00:31,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.067624678689754\n","Test Loss:  20.729048959736247\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:22<00:30,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.06474617708591\n","Test Loss:  21.101137308462057\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:23<00:29,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.210753875551745\n","Test Loss:  20.496516718529165\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:24<00:28,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.49385160696693\n","Test Loss:  19.844471421441995\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:25<00:27,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.33058971280116\n","Test Loss:  20.125005831068847\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:26<00:26,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.154597551969346\n","Test Loss:  20.2796606728225\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:27<00:25,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.72903397021582\n","Test Loss:  19.366728489287198\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:28<00:23,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.00929490278941\n","Test Loss:  19.48800734851102\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:29<00:22,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.42218880605651\n","Test Loss:  18.924598102807067\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:30<00:21,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.85236584881204\n","Test Loss:  19.854349258414004\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:31<00:20,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.63019659278507\n","Test Loss:  18.7708179699257\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:32<00:19,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.943164944823366\n","Test Loss:  19.146054391283542\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:33<00:18,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.349997233366594\n","Test Loss:  19.160756914468948\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:34<00:17,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.603247933031525\n","Test Loss:  18.27218205970712\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:35<00:16,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.25508267595433\n","Test Loss:  18.458054738352075\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:36<00:15,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.198481712606736\n","Test Loss:  18.266022347321268\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:37<00:14,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  31.965248549473472\n","Test Loss:  19.06681406009011\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:38<00:13,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  31.423785512452014\n","Test Loss:  20.141455060394946\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:39<00:12,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  31.92636110552121\n","Test Loss:  17.705227946629748\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:40<00:11,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  31.41220617160434\n","Test Loss:  18.143046923505608\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:41<00:10,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  30.986010174790863\n","Test Loss:  17.552898767695297\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:43<00:09,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.10407584434142\n","Test Loss:  18.770336195942946\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:44<00:08,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  30.580227467697114\n","Test Loss:  17.435846783977468\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:45<00:07,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  30.280203189875465\n","Test Loss:  19.022095589505625\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:46<00:06,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  31.277592803817242\n","Test Loss:  18.886781201668782\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:47<00:05,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  29.243414000346093\n","Test Loss:  17.881648930662777\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:48<00:04,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  30.408430791052524\n","Test Loss:  17.08844695769949\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [00:49<00:03,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  29.832856843277114\n","Test Loss:  16.93307207315229\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [00:50<00:02,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  29.831769263138995\n","Test Loss:  18.150694371201098\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 49/50 [00:51<00:01,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  28.932154200650984\n","Test Loss:  17.348064697987866\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:52<00:00,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  30.612861307745334\n","Test Loss:  16.604095223010518\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1986141228531588\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:56,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  125.45890078973025\n","Test Loss:  41.38586773723364\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:55,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.9778036675416\n","Test Loss:  30.69169306900585\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:54,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.53101393207908\n","Test Loss:  25.792884673457593\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:52,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.34518103231676\n","Test Loss:  25.193287163740024\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:51,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.490032897447236\n","Test Loss:  24.3890526460018\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:50,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.290078165824525\n","Test Loss:  23.99990086152684\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:49,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.960791304765735\n","Test Loss:  22.26169995201053\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:48,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.27814403618686\n","Test Loss:  21.98830949194962\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:46,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.03580031869933\n","Test Loss:  20.818561308522476\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:45,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.68680310237687\n","Test Loss:  22.49867228511721\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:44,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  45.81000161182601\n","Test Loss:  21.68447725730948\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:43,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  41.560845158353914\n","Test Loss:  21.031361726520117\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:14<00:42,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.33970980544109\n","Test Loss:  19.43282808107324\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:16<00:40,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.394816057552816\n","Test Loss:  19.174288321839413\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:39,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.26422181283124\n","Test Loss:  18.39823426786461\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:38,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.53864392155083\n","Test Loss:  18.196392258512788\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:19<00:37,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.064280831604265\n","Test Loss:  17.3332814250316\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:20<00:36,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.782624053768814\n","Test Loss:  20.106412091641687\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:21<00:35,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.50502420854173\n","Test Loss:  16.97170155015192\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:22<00:34,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.962502970476635\n","Test Loss:  16.90666211838834\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:24<00:33,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.604532810044475\n","Test Loss:  17.194168235204415\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:25<00:31,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.035963939502835\n","Test Loss:  16.521189886436332\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:26<00:30,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.18452064754092\n","Test Loss:  16.60604815982515\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:27<00:29,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.09319328790298\n","Test Loss:  17.082155234733364\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:28<00:28,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.785243415040895\n","Test Loss:  17.04403746747994\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:29<00:27,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  32.33824140339857\n","Test Loss:  16.75190808949992\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:30<00:28,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  35.01786757865921\n","Test Loss:  18.558795479650144\n","Early stopping with best_loss:  16.521189886436332 and test_loss for this epoch:  18.558795479650144 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9931238630192302\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:05,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  296.24303623847663\n","Test Loss:  63.31312499719206\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:02,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  183.48100309586152\n","Test Loss:  55.75061789993197\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:00,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.38086227606982\n","Test Loss:  49.228130055824295\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:57,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.35974312818144\n","Test Loss:  42.87929122324567\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:56,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  113.83056810311973\n","Test Loss:  40.91216011415236\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:53,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  101.63177604431985\n","Test Loss:  30.723525074106874\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:50,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  90.33639539865544\n","Test Loss:  28.659971664717887\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:47,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  85.20752349315444\n","Test Loss:  27.21475182287395\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:44,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.61666402040282\n","Test Loss:  26.071769584086724\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:42,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.66594890176202\n","Test Loss:  24.177181450620992\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:40,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.09272375205182\n","Test Loss:  22.522076710825786\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:37,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.33543523417029\n","Test Loss:  22.24259366217302\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:34,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  72.34448093629908\n","Test Loss:  22.9946592785127\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:35<01:32,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.90265193904634\n","Test Loss:  21.446070705365855\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:38<01:29,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  68.33083052787697\n","Test Loss:  21.7756289220124\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:27,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.68866093535325\n","Test Loss:  20.471085298107937\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:43<01:25,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.61221889511216\n","Test Loss:  20.279927365772892\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:46<01:23,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  64.61198697047075\n","Test Loss:  20.41920652674162\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:48<01:20,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.1319788050314\n","Test Loss:  20.226640955428593\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:51<01:17,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  64.46273043836118\n","Test Loss:  20.877663986670086\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:54<01:14,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  63.039117657986935\n","Test Loss:  20.68431341194082\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:56<01:12,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.23955375206424\n","Test Loss:  20.216022981796414\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:59<01:09,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.42254222749034\n","Test Loss:  19.645291598222684\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:01<01:06,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.3578750215529\n","Test Loss:  19.015176549059106\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:04<01:03,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  61.23688798799412\n","Test Loss:  20.533521490702697\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:06<01:01,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.8151133578649\n","Test Loss:  18.701070294242527\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:09<00:58,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.467965620046016\n","Test Loss:  18.955659991144785\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:12<00:56,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  58.15049200359499\n","Test Loss:  18.652205061152927\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:14<00:53,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.767046735360054\n","Test Loss:  18.728852851563715\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:17<00:51,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  58.74121028414811\n","Test Loss:  19.473698041474563\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:19<00:48,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  56.17442551809654\n","Test Loss:  19.471681599505246\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:22<00:46,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  57.855684716661926\n","Test Loss:  19.31197384762345\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:24<00:43,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.82624592448701\n","Test Loss:  17.82691633401555\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:27<00:41,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.744460846093716\n","Test Loss:  18.696226258121897\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:29<00:38,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  56.97372255276423\n","Test Loss:  18.49902832819498\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:32<00:35,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.06717373660649\n","Test Loss:  17.53831251806696\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:35<00:33,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.73480124693015\n","Test Loss:  17.662981641071383\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:37<00:30,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  51.9279530463391\n","Test Loss:  18.54988396987028\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:40<00:28,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.857220865698764\n","Test Loss:  17.35784132160188\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:42<00:25,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.49831777397776\n","Test Loss:  17.315634906000923\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:45<00:23,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.90701319355867\n","Test Loss:  18.382860228652135\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [01:47<00:20,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  52.39870593091473\n","Test Loss:  17.980440126382746\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:50<00:17,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  53.17924492826569\n","Test Loss:  17.346015703311423\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [01:53<00:15,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.95019496192981\n","Test Loss:  16.703966496992507\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [01:55<00:12,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.318063080485445\n","Test Loss:  16.96659716666909\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [01:58<00:10,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  49.07955411646981\n","Test Loss:  19.98484801646555\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [02:00<00:07,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  51.47147434260114\n","Test Loss:  17.10084414028097\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [02:03<00:05,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.73052813456161\n","Test Loss:  16.645040887466166\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 49/50 [02:05<00:02,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.65650363531313\n","Test Loss:  16.607368423894513\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [02:08<00:00,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.39101164526073\n","Test Loss:  16.183815834869165\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.352759292686782\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:06,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  204.76975412480533\n","Test Loss:  63.22910710121505\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:04,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.43446420424152\n","Test Loss:  51.955295539228246\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:02,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  109.97651166142896\n","Test Loss:  40.204710936232004\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:59,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.53325316833798\n","Test Loss:  32.99787612410728\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<01:57,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  80.34536579891574\n","Test Loss:  42.00829466385767\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:54,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.35221500974149\n","Test Loss:  28.805692704423564\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:51,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  71.63166154548526\n","Test Loss:  28.44539779110346\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:48,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.72176470136037\n","Test Loss:  27.936916971346363\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:46,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.97130142623791\n","Test Loss:  27.59203447366599\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:44,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.30830318311928\n","Test Loss:  25.26443517311418\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:41,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.64838405273622\n","Test Loss:  25.21486137411557\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:31<01:38,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.09177187923342\n","Test Loss:  25.454372512409464\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:35,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.0251482364838\n","Test Loss:  24.311588392505655\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:36<01:33,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.889842751726974\n","Test Loss:  29.70100108148472\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:38<01:31,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.241075349389575\n","Test Loss:  23.083961758762598\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:28,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.569795106508536\n","Test Loss:  23.21143996322644\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:44<01:25,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.60407503935858\n","Test Loss:  22.54509759589564\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:46<01:23,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  59.5324747771665\n","Test Loss:  24.58029542499571\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:49<01:20,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  58.57610429330089\n","Test Loss:  21.754520910792053\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:51<01:17,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.62892797794484\n","Test Loss:  22.210466363554588\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:54<01:15,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  54.60515508186654\n","Test Loss:  24.598924884048756\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:57<01:12,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  54.9920752485632\n","Test Loss:  22.1221225362533\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:59<01:10,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  55.76404208724853\n","Test Loss:  22.020633907755837\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:02<01:07,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.49408663972281\n","Test Loss:  20.50679364198004\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:04<01:05,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.30091358436039\n","Test Loss:  20.0669884722156\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:07<01:02,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.36338624948985\n","Test Loss:  20.537188245769357\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:10<01:00,  2.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  52.73483862075955\n","Test Loss:  21.8091401130514\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:12<00:58,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  49.049296609155135\n","Test Loss:  20.370002035808284\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:15<00:55,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.1486654082546\n","Test Loss:  19.402829187980387\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:18<00:51,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.00918709015241\n","Test Loss:  20.438898761349265\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:20<00:49,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  48.110372268012725\n","Test Loss:  20.22111998188484\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:23<00:46,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  51.97402941607288\n","Test Loss:  23.11876493893942\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:25<00:44,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  49.309979922225466\n","Test Loss:  19.97050119265623\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:28<00:45,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  48.808371092309244\n","Test Loss:  21.230771505302982\n","Early stopping with best_loss:  19.402829187980387 and test_loss for this epoch:  21.230771505302982 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.42822939623119843\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:19,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  174.67867626575753\n","Test Loss:  58.64843455713708\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:17,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.98828153545037\n","Test Loss:  40.730315858265385\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:14,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  88.71203030459583\n","Test Loss:  32.932214624248445\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:12,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.6461825988954\n","Test Loss:  29.649671831401065\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:09,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  71.76129549031612\n","Test Loss:  27.478391927026678\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:06,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.85523689372349\n","Test Loss:  27.45641398357111\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:02,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.43734901407151\n","Test Loss:  26.560215957520995\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:22<02:00,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.63699778688897\n","Test Loss:  24.809260521054966\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:25<01:57,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.71505133790197\n","Test Loss:  23.38828972209012\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:28<01:54,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.67642746306956\n","Test Loss:  25.534691935696173\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:31<01:51,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.72702782790293\n","Test Loss:  22.988379400601843\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:34<01:48,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.06272767903283\n","Test Loss:  22.519797106127953\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:37<01:45,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.32600259920582\n","Test Loss:  22.724383483757265\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:40<01:43,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.820624605956255\n","Test Loss:  20.57892607236863\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:43<01:41,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.18732559934142\n","Test Loss:  24.24953400454251\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:45<01:37,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.788690978093655\n","Test Loss:  20.006885764130857\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:48<01:34,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.47287056015921\n","Test Loss:  20.029767832020298\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:51<01:32,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  51.82634550021612\n","Test Loss:  20.23525169050845\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:54<01:29,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  53.19851421027852\n","Test Loss:  20.067220748664113\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:57<01:25,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  51.317113972851075\n","Test Loss:  22.52544513446628\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:00<01:22,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.05426919004822\n","Test Loss:  19.4914844957093\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:03<01:21,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.3685156716092\n","Test Loss:  18.393361219757935\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:06<01:18,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.45782258543477\n","Test Loss:  18.12941892957315\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:08<01:15,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.82812787484727\n","Test Loss:  18.224681517778663\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:11<01:12,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  48.83599372090248\n","Test Loss:  18.94594039642834\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:14<01:09,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  47.98601888335543\n","Test Loss:  23.5514861589254\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:17<01:06,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  48.024870093446225\n","Test Loss:  19.188537368143443\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:20<01:08,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  49.44928124954458\n","Test Loss:  18.3654202951584\n","Early stopping with best_loss:  18.12941892957315 and test_loss for this epoch:  18.3654202951584 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.4035868466385379\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:34,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  501.1180178159848\n","Test Loss:  117.95186267443933\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:30,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  334.09961085626855\n","Test Loss:  98.05082109023351\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:26,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  269.9958553982433\n","Test Loss:  86.03131303389091\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:24,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  241.02575018268544\n","Test Loss:  74.88603820826393\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:22,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  219.7676219920395\n","Test Loss:  68.26285293337423\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:19,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  210.29903905355604\n","Test Loss:  64.44989800266922\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:15,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  198.14003586256877\n","Test Loss:  63.93061741976999\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:12,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  190.94168720464222\n","Test Loss:  58.861485259607434\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:28<02:09,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  185.0346956307767\n","Test Loss:  57.789147360716015\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:31<02:06,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  180.29380040749675\n","Test Loss:  59.20081026805565\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:34<02:03,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  177.91984951862833\n","Test Loss:  53.416620809119195\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:37<01:59,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.51699257592554\n","Test Loss:  51.409430297033396\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:41<01:57,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  168.59366915971623\n","Test Loss:  50.7853272248758\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:44<01:53,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  166.9306170917116\n","Test Loss:  52.25369087897707\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:47<01:50,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.03809705216554\n","Test Loss:  48.76498821750283\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:50<01:47,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.1120635747211\n","Test Loss:  48.52426912926603\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:53<01:44,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  157.33590433787322\n","Test Loss:  50.71684158401331\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:56<01:41,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.77937299956102\n","Test Loss:  48.46473319060169\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:00<01:38,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  157.14858066063607\n","Test Loss:  47.296788653184194\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:03<01:35,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  153.07200842630118\n","Test Loss:  49.59918507077964\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:06<01:31,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  148.28308286261745\n","Test Loss:  47.528260461986065\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:09<01:28,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  148.9712973643327\n","Test Loss:  49.19796826687525\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:12<01:25,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  150.91634389653336\n","Test Loss:  49.21558436364285\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:15<01:29,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  145.32179529540008\n","Test Loss:  49.82532836031169\n","Early stopping with best_loss:  47.296788653184194 and test_loss for this epoch:  49.82532836031169 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.059216875650681\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:35,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  421.60160241182894\n","Test Loss:  138.9165739857126\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:31,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  299.36343204183504\n","Test Loss:  113.00047493702732\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:30,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  245.96017472771928\n","Test Loss:  94.04304460401181\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:27,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  214.30465015023947\n","Test Loss:  85.26934987475397\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:23,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  201.29050841461867\n","Test Loss:  77.82424815991544\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:19,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  186.02403333853\n","Test Loss:  73.55397992406506\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:17,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  184.94003514933866\n","Test Loss:  73.07585606951034\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:14,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.95751639513765\n","Test Loss:  70.665690067166\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:28<02:10,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  168.66552916838555\n","Test Loss:  67.18500498324283\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:31<02:06,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  160.42032188148005\n","Test Loss:  63.095798351219855\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:35<02:04,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  160.05672860206687\n","Test Loss:  65.63453771584318\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:38<02:01,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.13468293321785\n","Test Loss:  59.288437233975856\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:41<01:58,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  153.48057421739213\n","Test Loss:  59.31639779070974\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:44<01:54,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.02060386742232\n","Test Loss:  56.72860055160709\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:47<01:51,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  148.1722479214659\n","Test Loss:  59.639869603473926\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:50<01:48,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  142.60150112418341\n","Test Loss:  58.21389739161532\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:54<01:45,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.5432095718279\n","Test Loss:  53.92466796869121\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:57<01:41,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  140.67175625939853\n","Test Loss:  54.2362106005603\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:00<01:38,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  142.12130644510034\n","Test Loss:  53.39771369675873\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:03<01:35,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.86042822917807\n","Test Loss:  59.088858407514635\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:06<01:32,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.34527973341756\n","Test Loss:  52.66808671672334\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:10<01:30,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  133.81588703225134\n","Test Loss:  53.25740140664857\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:13<01:26,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  133.28426948274137\n","Test Loss:  53.51752749941079\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:16<01:22,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.7740512950695\n","Test Loss:  51.530226420087274\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:19<01:20,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.06484768903465\n","Test Loss:  50.52637635337305\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:22<01:16,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  127.46695208875462\n","Test Loss:  50.794101661478635\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:26<01:13,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.80955737206386\n","Test Loss:  50.3568483669078\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:29<01:09,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  127.04217569262255\n","Test Loss:  54.1292692637071\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:32<01:06,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.87383694841992\n","Test Loss:  49.83691140206065\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:35<01:03,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  124.36119037106982\n","Test Loss:  48.89011630695313\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:38<01:00,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  118.06071127066389\n","Test Loss:  48.236586572544184\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:42<00:57,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  122.44600361981429\n","Test Loss:  51.21560730598867\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:45<00:54,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  120.28595240582945\n","Test Loss:  48.828214812936494\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:48<00:51,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  122.56794528738828\n","Test Loss:  48.586839270894416\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:51<00:47,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  117.47420769519522\n","Test Loss:  52.461193654846284\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:54<00:49,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  118.70627197856084\n","Test Loss:  55.92177446739515\n","Early stopping with best_loss:  48.236586572544184 and test_loss for this epoch:  55.92177446739515 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1681972813994486\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:50,  3.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  378.7794574741274\n","Test Loss:  128.95126769217313\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:07<02:48,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  263.8738473660778\n","Test Loss:  91.34608613833552\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:45,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  215.8743627462827\n","Test Loss:  79.56120067706797\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:14<02:41,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  190.5318120024167\n","Test Loss:  74.94603512494359\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:17<02:40,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  177.71423885709373\n","Test Loss:  64.39947260697954\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:21<02:35,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  169.6008471531677\n","Test Loss:  63.42590775174904\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:24<02:33,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  161.2907845316222\n","Test Loss:  59.050848254497396\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:28<02:28,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  158.44764379720436\n","Test Loss:  61.449659105797764\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:31<02:24,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  150.31617458944675\n","Test Loss:  56.26196676015388\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:35<02:20,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  150.7467496622994\n","Test Loss:  64.2700789187802\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:38<02:18,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.34296148241265\n","Test Loss:  53.969788522226736\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:42<02:15,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  142.2118856268935\n","Test Loss:  55.39101524735452\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:45<02:11,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  140.95214237296022\n","Test Loss:  57.59191612849827\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:49<02:07,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.60227453440893\n","Test Loss:  53.0307751144137\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:53<02:04,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.2824967756751\n","Test Loss:  51.407953633053694\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:56<01:59,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  135.764745291468\n","Test Loss:  59.00714907149086\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [01:00<01:55,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  127.63164519215934\n","Test Loss:  51.44777073501609\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:03<01:52,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  132.1397037235438\n","Test Loss:  52.34108872609795\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:07<01:49,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  126.4790720922174\n","Test Loss:  49.98732889792882\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:10<01:45,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.09912058210466\n","Test Loss:  48.79176854446996\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:14<01:41,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  126.97908383555477\n","Test Loss:  48.795887246436905\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:17<01:38,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  126.87895509018563\n","Test Loss:  48.529178342898376\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:21<01:35,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  126.12570900659193\n","Test Loss:  51.242019931203686\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:24<01:32,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  126.06310300825862\n","Test Loss:  50.68261449635611\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:28<01:28,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  127.85356805761694\n","Test Loss:  46.79633844594355\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:31<01:25,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  124.34845619113185\n","Test Loss:  50.81265277293278\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:35<01:21,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  117.48307588888565\n","Test Loss:  49.63877983286511\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:38<01:17,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  119.46090632933192\n","Test Loss:  49.924996557383565\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:42<01:13,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  118.61376200499944\n","Test Loss:  45.78422919934383\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:45<01:10,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  117.62608829510282\n","Test Loss:  49.50778271374293\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:49<01:07,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  116.95171643098001\n","Test Loss:  49.444704156921944\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:52<01:03,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  119.5245757130615\n","Test Loss:  47.70090330491075\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:56<00:59,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  117.52843091354589\n","Test Loss:  44.31463135915692\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:59<00:56,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  119.02332724243752\n","Test Loss:  45.516999688290525\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [02:03<00:52,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  115.91697172763816\n","Test Loss:  49.74701208161423\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [02:06<00:49,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  116.28293173646671\n","Test Loss:  45.48670641134959\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [02:10<00:45,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  114.57899469020776\n","Test Loss:  48.09581907012034\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [02:13<00:42,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  112.59643049453734\n","Test Loss:  44.07160196459154\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [02:17<00:38,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  111.87221326187137\n","Test Loss:  49.87596784118796\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [02:21<00:35,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  110.3665015479055\n","Test Loss:  42.46143901447067\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [02:24<00:31,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  112.64268748174072\n","Test Loss:  42.226615962572396\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:28<00:28,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  112.73958877517725\n","Test Loss:  42.77815741029917\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:31<00:24,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  107.62868265731959\n","Test Loss:  43.724883796763606\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [02:35<00:21,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  111.75636777540785\n","Test Loss:  50.549049030581955\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [02:38<00:17,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  113.85414863137703\n","Test Loss:  46.27608401188627\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [02:42<00:18,  3.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  109.77346633007983\n","Test Loss:  44.254488615028095\n","Early stopping with best_loss:  42.226615962572396 and test_loss for this epoch:  44.254488615028095 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8972499820714073\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:42,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.07553308829665\n","Test Loss:  48.88255197927356\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:41,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  134.38125794380903\n","Test Loss:  42.52040034905076\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:40,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  110.48313462734222\n","Test Loss:  34.337014763616025\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:39,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  87.70019783638418\n","Test Loss:  26.96532717271475\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:38,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.79900873173028\n","Test Loss:  26.34180022776127\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:37,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.68590672407299\n","Test Loss:  24.804287204984576\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:05<00:36,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.670109308324754\n","Test Loss:  21.782596717064735\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:35,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.22145961923525\n","Test Loss:  21.409566428745165\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:34,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.85147323086858\n","Test Loss:  21.52718813379761\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:34,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.437100388109684\n","Test Loss:  20.835245727095753\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:09<00:33,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.643718221457675\n","Test Loss:  20.444091186625883\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:10<00:32,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.09609274682589\n","Test Loss:  20.672061837860383\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:11<00:31,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.35559884668328\n","Test Loss:  21.299386199505534\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:11<00:30,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.56585916271433\n","Test Loss:  19.639584528515115\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:29,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.998190568294376\n","Test Loss:  19.43525057565421\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:13<00:28,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.09533043578267\n","Test Loss:  19.056015525362454\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:14<00:27,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.13045644236263\n","Test Loss:  20.580440154648386\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:15<00:27,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.57791790133342\n","Test Loss:  18.569569515180774\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:16<00:26,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.658501507597975\n","Test Loss:  18.72904975526035\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:16<00:25,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.45216452470049\n","Test Loss:  18.087639632751234\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:17<00:24,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.36408476042561\n","Test Loss:  17.988803497282788\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:18<00:23,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.700300228782\n","Test Loss:  17.76720320165623\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:19<00:23,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.314728128141724\n","Test Loss:  17.76118420989951\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:20<00:22,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.879101064405404\n","Test Loss:  17.565381846623495\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:21<00:21,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.65055285859853\n","Test Loss:  17.015176381682977\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:22<00:20,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.43747298361268\n","Test Loss:  16.687296299729496\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:22<00:19,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.11233396525495\n","Test Loss:  17.948794632859062\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:23<00:18,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.90216128400061\n","Test Loss:  17.075613678316586\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:24<00:17,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  37.99205454625189\n","Test Loss:  16.717885840451345\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:25<00:16,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  38.47158417990431\n","Test Loss:  17.331026372965425\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:26<00:15,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.48492094501853\n","Test Loss:  16.6564324850915\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:27<00:15,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.47692445048597\n","Test Loss:  16.5994055243209\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:27<00:14,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.08043484133668\n","Test Loss:  16.519395774346776\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:28<00:13,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.82225756032858\n","Test Loss:  17.166673243511468\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:29<00:12,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.369276687677484\n","Test Loss:  16.10827600141056\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:30<00:11,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.750768047524616\n","Test Loss:  16.184897075407207\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:31<00:10,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.95960877207108\n","Test Loss:  15.41278633940965\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:32<00:10,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.45360534195788\n","Test Loss:  15.862405302701518\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:32<00:09,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.71270454546902\n","Test Loss:  15.625556577695534\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:33<00:08,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  34.48683464899659\n","Test Loss:  15.83184114244068\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:34<00:07,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.47247945936397\n","Test Loss:  15.309894545469433\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:35<00:06,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.23706435831264\n","Test Loss:  15.799292403913569\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:36<00:05,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.71717778779566\n","Test Loss:  15.508933035598602\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:37<00:05,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.14168715546839\n","Test Loss:  16.734411690500565\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:38<00:04,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.16071175644174\n","Test Loss:  15.429206467757467\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:38<00:04,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  33.62168267159723\n","Test Loss:  15.832847386249341\n","Early stopping with best_loss:  15.309894545469433 and test_loss for this epoch:  15.832847386249341 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.391529336042367\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:40,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.9123801998794\n","Test Loss:  40.0994588136673\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:40,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  119.67298570461571\n","Test Loss:  32.349738812074065\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:39,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  90.98509034793824\n","Test Loss:  32.83037863764912\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:38,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.78331767674536\n","Test Loss:  17.4517706008628\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:37,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  64.53542471770197\n","Test Loss:  19.107888076337986\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:37,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.085783790331334\n","Test Loss:  16.72018574399408\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:05<00:36,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  58.520989081822336\n","Test Loss:  16.23845105082728\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:35,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.936586239608005\n","Test Loss:  16.071110689430498\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:35,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.376536089228466\n","Test Loss:  15.436987205059268\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:34,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.809916897211224\n","Test Loss:  16.383353793353308\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:09<00:33,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  50.422197982436046\n","Test Loss:  15.784414590219967\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:10<00:32,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  49.59378780168481\n","Test Loss:  15.77746060024947\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:11<00:31,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.19937301881146\n","Test Loss:  14.457097145495936\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:11<00:30,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.44496787851676\n","Test Loss:  14.043563447427005\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:29,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.958009002381004\n","Test Loss:  13.995176974334754\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:13<00:28,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.97508562868461\n","Test Loss:  13.810371207655407\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:14<00:27,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.43623924488202\n","Test Loss:  13.480565323901828\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:15<00:26,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.66038656618912\n","Test Loss:  13.562181464163586\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:16<00:26,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.57714815100189\n","Test Loss:  13.008514234563336\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:16<00:25,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.2185629166197\n","Test Loss:  13.498091804562137\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:17<00:24,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.3346852970717\n","Test Loss:  12.807142387144268\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:18<00:23,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.8368569330778\n","Test Loss:  12.713662471011048\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:19<00:22,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.262704647378996\n","Test Loss:  12.648337085032836\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:20<00:22,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.039788636844605\n","Test Loss:  13.33396770292893\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:21<00:21,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.78720029897522\n","Test Loss:  12.340170206385665\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:22<00:20,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.294603248359635\n","Test Loss:  11.870619437715504\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:22<00:19,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.51480378431734\n","Test Loss:  11.860990875400603\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:23<00:18,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.284216422820464\n","Test Loss:  11.961787724867463\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:24<00:17,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.92212840938009\n","Test Loss:  11.57499923335854\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:25<00:16,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.71130556066055\n","Test Loss:  11.784495498402975\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:26<00:16,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.03069441328989\n","Test Loss:  11.291268775064964\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:27<00:15,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.70560864836443\n","Test Loss:  10.867790359072387\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:27<00:14,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.46955293067731\n","Test Loss:  12.314912089146674\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:28<00:13,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.979722289252095\n","Test Loss:  10.857883855176624\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:29<00:12,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.37426296749618\n","Test Loss:  10.971166258386802\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:30<00:12,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.482277943519875\n","Test Loss:  10.90989439439727\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:31<00:11,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.617538950406015\n","Test Loss:  11.657474790816195\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:32<00:10,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  37.45083790482022\n","Test Loss:  11.468720017001033\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:33<00:10,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  38.60564588662237\n","Test Loss:  11.261499700602144\n","Early stopping with best_loss:  10.857883855176624 and test_loss for this epoch:  11.261499700602144 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7339979463074063\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:46,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.26823871769011\n","Test Loss:  35.92344758566469\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:46,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  85.11281708721071\n","Test Loss:  25.60844452260062\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:45,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.42735357536003\n","Test Loss:  25.098666660953313\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:44,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.36894471314736\n","Test Loss:  19.749909110134467\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:43,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.785811284324154\n","Test Loss:  22.022402900038287\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:42,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  53.01388129685074\n","Test Loss:  20.293636943679303\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:41,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.98421664291527\n","Test Loss:  18.816404919838533\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:07<00:40,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.005559370154515\n","Test Loss:  17.2850595084019\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:08<00:38,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.50305236922577\n","Test Loss:  17.40966729441425\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:09<00:38,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  45.734387079719454\n","Test Loss:  20.165515480795875\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:10<00:37,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.86857895273715\n","Test Loss:  16.10180356889032\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:11<00:35,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.68216867791489\n","Test Loss:  17.6508691792842\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:12<00:34,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.27948078967165\n","Test Loss:  15.903424973483197\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:13<00:34,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.60287833074108\n","Test Loss:  15.481534145103069\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:14<00:33,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.212230562698096\n","Test Loss:  15.521756139351055\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:15<00:32,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.98969567194581\n","Test Loss:  16.1563956476748\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:16<00:31,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.79930233187042\n","Test Loss:  14.652969958959147\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:17<00:30,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.77077701804228\n","Test Loss:  14.286861198139377\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:18<00:29,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.569594487780705\n","Test Loss:  14.52397170336917\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:19<00:28,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.23179013316985\n","Test Loss:  14.556310261948965\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:20<00:27,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.77395002276171\n","Test Loss:  14.372001536656171\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:20<00:26,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.66989362286404\n","Test Loss:  13.735941026825458\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:21<00:25,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.23847762052901\n","Test Loss:  13.36071614571847\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:22<00:24,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.54807125951629\n","Test Loss:  14.009572036215104\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:23<00:23,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.58858711353969\n","Test Loss:  12.878071164654102\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:24<00:22,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.295293292962015\n","Test Loss:  12.56540022965055\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:25<00:21,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.30090426537208\n","Test Loss:  13.114949634764344\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:26<00:20,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.95001296582632\n","Test Loss:  12.258967733592726\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:27<00:20,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.36431027663639\n","Test Loss:  12.798228841042146\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:28<00:19,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  33.95818384713493\n","Test Loss:  12.723020704230294\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:29<00:18,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.415969757712446\n","Test Loss:  12.20455954069621\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:30<00:17,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.09309300535824\n","Test Loss:  12.480118684121408\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:31<00:16,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.67807696433738\n","Test Loss:  12.659712038264843\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:32<00:15,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  31.888173193088733\n","Test Loss:  12.161183161952067\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:33<00:14,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  31.90247741783969\n","Test Loss:  12.320718660135753\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:34<00:13,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.26627664716216\n","Test Loss:  11.306639734480996\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:35<00:12,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  31.05916483985493\n","Test Loss:  11.119195761857554\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:36<00:11,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  30.22803563682828\n","Test Loss:  12.06858916656347\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:37<00:10,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  31.092753165052272\n","Test Loss:  12.721121701761149\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:38<00:09,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  30.699205125449225\n","Test Loss:  11.858463708893396\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:39<00:08,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  30.072928072419018\n","Test Loss:  14.139452580362558\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:40<00:08,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  30.10517005622387\n","Test Loss:  11.163424875587225\n","Early stopping with best_loss:  11.119195761857554 and test_loss for this epoch:  11.163424875587225 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.941749672701297\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:55,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  257.22432804852724\n","Test Loss:  48.92025061510503\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:56,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.16883703367785\n","Test Loss:  42.39623116166331\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:54,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  103.85263807198498\n","Test Loss:  30.166668176010717\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:52,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.25779717124533\n","Test Loss:  26.28845660344814\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:49,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  68.79712279082742\n","Test Loss:  30.35947748174658\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:46,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.91640257259132\n","Test Loss:  24.08205300825648\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:16<01:44,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.08150756404211\n","Test Loss:  21.728147498710314\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:19<01:42,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.01295430632308\n","Test Loss:  20.796888331562513\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:21<01:40,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.196003092307365\n","Test Loss:  20.25899621951976\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:24<01:36,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.6000975225179\n","Test Loss:  19.615958506707102\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:26<01:33,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.46188125299523\n","Test Loss:  18.841246834505\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:28<01:30,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.43180493239197\n","Test Loss:  19.245608133933274\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:31<01:28,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.27297496859683\n","Test Loss:  17.99511493515456\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:33<01:26,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.833872194751166\n","Test Loss:  18.766934541403316\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:36<01:24,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.688860590715194\n","Test Loss:  17.467781454557553\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:38<01:21,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.44121000923042\n","Test Loss:  19.175466443004552\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:40<01:18,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  48.09032760717673\n","Test Loss:  18.104676276649116\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:43<01:16,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  46.52105028316146\n","Test Loss:  17.66338845936116\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:45<01:14,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  46.454336016046\n","Test Loss:  17.6330141389044\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:48<01:12,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.89020172096207\n","Test Loss:  17.015906497326796\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:50<01:10,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.661880969724734\n","Test Loss:  16.211350286801462\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:53<01:08,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.59015078714583\n","Test Loss:  15.954987480654381\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:55<01:05,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.7044061224442\n","Test Loss:  16.071302537660813\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:58<01:03,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  44.180507108423626\n","Test Loss:  16.363729275937658\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:00<01:00,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.60180261325149\n","Test Loss:  15.660320776805747\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.815342036104994\n","Test Loss:  15.575660262315068\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:05<00:55,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.54664365226927\n","Test Loss:  18.49606104986742\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:07<00:52,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.88198693632148\n","Test Loss:  15.577775239100447\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:09<00:50,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.671183007681975\n","Test Loss:  14.970417084405199\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:12<00:47,  2.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.0993960860651\n","Test Loss:  15.333282514853636\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:14<00:45,  2.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.870971990108956\n","Test Loss:  14.776825481239939\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:17<00:43,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.9605222158425\n","Test Loss:  15.551905818283558\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:19<00:40,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.98991669561656\n","Test Loss:  15.64784399914788\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:21<00:38,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.997570431594795\n","Test Loss:  14.697659313329495\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:24<00:35,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.03861210263858\n","Test Loss:  13.998017388687003\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:26<00:33,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.86214388621738\n","Test Loss:  14.26255420835514\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:29<00:31,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.27479503588984\n","Test Loss:  14.649610623513581\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:31<00:28,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  39.38030967520899\n","Test Loss:  14.711654368016752\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:33<00:26,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.266920871130424\n","Test Loss:  13.898484978373745\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:36<00:24,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.959668365641846\n","Test Loss:  13.850092043023324\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:38<00:21,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.66296503857302\n","Test Loss:  13.457518552764668\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [01:41<00:19,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.70279752969509\n","Test Loss:  14.199164000398014\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:43<00:16,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.34449761515134\n","Test Loss:  13.739066032343544\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [01:46<00:14,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.981392756832065\n","Test Loss:  13.198018438299187\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [01:48<00:12,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.045468613214325\n","Test Loss:  13.395057628891664\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [01:50<00:09,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.371660351287574\n","Test Loss:  13.633857845867169\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [01:53<00:07,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.6839678408287\n","Test Loss:  14.169230223225895\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [01:55<00:04,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  38.198266191160656\n","Test Loss:  13.625328156762407\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [01:58<00:04,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  36.36928764876211\n","Test Loss:  13.801823272951879\n","Early stopping with best_loss:  13.198018438299187 and test_loss for this epoch:  13.801823272951879 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.3256037889928122\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:01,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.31689697876573\n","Test Loss:  53.63943093660055\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:57,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  122.57273741462268\n","Test Loss:  43.43855849877582\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:53,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.73565251781838\n","Test Loss:  26.047860505379504\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:51,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.8281691633747\n","Test Loss:  25.967423860682175\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:48,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.729257719998714\n","Test Loss:  23.227707740064943\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:47,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.43554473930271\n","Test Loss:  21.34079556548386\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:44,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.7475726113189\n","Test Loss:  20.065282064431813\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:19<01:41,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.413343350577634\n","Test Loss:  19.390587663918268\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:21<01:39,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.339587607217254\n","Test Loss:  19.724564937583636\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:24<01:37,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.50893809803529\n","Test Loss:  18.6748688298685\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:26<01:35,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.18491553218337\n","Test Loss:  17.533360460220138\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:29<01:32,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.9134769057564\n","Test Loss:  17.690561903524213\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:31<01:29,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  47.33461923536379\n","Test Loss:  21.693890750175342\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:33<01:27,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.106429764593486\n","Test Loss:  17.408287789381575\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:36<01:24,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.261625941609964\n","Test Loss:  16.889518462237902\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:38<01:22,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.494440945913084\n","Test Loss:  16.982799670513486\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:41<01:19,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.99227836568025\n","Test Loss:  16.204409030557144\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:43<01:17,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.30783036380308\n","Test Loss:  16.022012551125954\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:46<01:14,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.51065732544521\n","Test Loss:  20.582163065031637\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:48<01:12,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  45.82052191023831\n","Test Loss:  16.646572326048044\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:50<01:10,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  41.54546206034138\n","Test Loss:  18.32823873506277\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:53<01:07,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.53862015748746\n","Test Loss:  15.743483922851738\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:55<01:05,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.9565031240636\n","Test Loss:  15.07555214560125\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:58<01:03,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.69679472166172\n","Test Loss:  14.28383631867473\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:00<01:01,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.21506620920263\n","Test Loss:  15.358547906245803\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:03<00:58,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.89879701190512\n","Test Loss:  16.04969509333023\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:05<00:55,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  39.89153294613061\n","Test Loss:  14.88963264063932\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:07<00:53,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  40.346459914173465\n","Test Loss:  15.77450764819514\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:10<00:55,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  42.60762468131725\n","Test Loss:  14.580152241673204\n","Early stopping with best_loss:  14.28383631867473 and test_loss for this epoch:  14.580152241673204 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.38395678324545535\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:14,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.36627417523414\n","Test Loss:  51.18778959219344\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:10,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  109.44032514817081\n","Test Loss:  31.25639794007293\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:07,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  71.22327045782004\n","Test Loss:  22.500251561461482\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:04,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.92976837710012\n","Test Loss:  21.267570815980434\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:02,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.64147296769079\n","Test Loss:  25.149097229674226\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<02:00,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.91547179703775\n","Test Loss:  17.974321951682214\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<01:57,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.443339593184646\n","Test Loss:  17.70742603961844\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:54,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.56052644671581\n","Test Loss:  34.98476899508387\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:51,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  50.12626363078016\n","Test Loss:  18.309859162545763\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:49,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.17876114360115\n","Test Loss:  16.54326620651409\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:29<01:46,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.77156036585802\n","Test Loss:  16.950475905963685\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:43,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.4808644222212\n","Test Loss:  14.648109841407859\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:35<01:40,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.252537896012655\n","Test Loss:  14.223976811190369\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:37,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.879495867775404\n","Test Loss:  17.606196887179976\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:40<01:34,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.402944999485044\n","Test Loss:  14.391178021440282\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:43<01:31,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.48704958934104\n","Test Loss:  13.878397512016818\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:46<01:29,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.61165154336777\n","Test Loss:  14.610835660423618\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:49<01:28,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.57771733845584\n","Test Loss:  13.345603950459918\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:51<01:24,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.40411140298238\n","Test Loss:  14.055101280042436\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:54<01:21,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.05152581384755\n","Test Loss:  16.55939281565952\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:57<01:18,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.0956985555531\n","Test Loss:  13.092724281945266\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:59<01:16,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.797588380926754\n","Test Loss:  13.190443118553958\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:02<01:13,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.8384897132637\n","Test Loss:  15.530152902880218\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:05<01:10,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.33439415889734\n","Test Loss:  12.73660215860582\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:08<01:07,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.08295556626399\n","Test Loss:  15.725664479628904\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:10<01:05,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.59970959412749\n","Test Loss:  12.136373586967238\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:13<01:02,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.55248463636963\n","Test Loss:  12.80981239603716\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:16<01:00,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.779394802753814\n","Test Loss:  12.7084591841558\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:18<00:57,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.122413037897786\n","Test Loss:  12.53902765805833\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:21<00:54,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.72094895118789\n","Test Loss:  11.369343809128623\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:24<00:51,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.147491578783956\n","Test Loss:  11.264984877983807\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:27<00:48,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.33276720449794\n","Test Loss:  11.990908518288052\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:29<00:46,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.36578617221676\n","Test Loss:  11.923486551037058\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:32<00:43,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.703188929124735\n","Test Loss:  14.121936743875267\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:35<00:40,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.4485465537291\n","Test Loss:  12.450350471379352\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:37<00:41,  2.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  34.6875219916401\n","Test Loss:  12.304073255276307\n","Early stopping with best_loss:  11.264984877983807 and test_loss for this epoch:  12.304073255276307 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.25589851607532266\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:25,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  470.5709586655721\n","Test Loss:  137.84450170164928\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:24,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  321.9866275093518\n","Test Loss:  107.90430934424512\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:21,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  255.29212746256962\n","Test Loss:  91.96688413486117\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:17,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  222.52138156152796\n","Test Loss:  83.48248762974981\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:14,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  198.18880732770776\n","Test Loss:  73.58058658981463\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:11,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  187.36092671449296\n","Test Loss:  70.31870275983238\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:09,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  178.89277676085476\n","Test Loss:  71.37255740648834\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:23<02:05,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.28073087433586\n","Test Loss:  65.3930604350171\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:26<02:01,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  165.2837747123558\n","Test Loss:  67.62453090079362\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:29<01:58,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  166.30322161276126\n","Test Loss:  71.19319616694702\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:32<01:57,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.12914143956732\n","Test Loss:  59.853891221340746\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:35<01:53,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  153.94326925289351\n","Test Loss:  59.90185477526393\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:38<01:50,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.5108070067945\n","Test Loss:  57.7346680292394\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:41<01:47,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  145.76709282855154\n","Test Loss:  55.768813307309756\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:44<01:45,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.22522559494246\n","Test Loss:  54.31669847361627\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:47<01:42,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  146.92414745304268\n","Test Loss:  55.01483391894726\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:50<01:38,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  143.13267726782942\n","Test Loss:  54.83684737345902\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:53<01:35,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  142.58875524130417\n","Test Loss:  56.794041456480045\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:56<01:32,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  136.0484208786802\n","Test Loss:  56.13070257630898\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:59<01:29,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.79442896330147\n","Test Loss:  52.50578613692778\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:02<01:26,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.304648271529\n","Test Loss:  51.51225987356156\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:05<01:23,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  135.9062596669828\n","Test Loss:  53.90548703627428\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:08<01:20,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.2427092124999\n","Test Loss:  50.39096733665792\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:11<01:18,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  137.36286800089874\n","Test Loss:  50.9029621250811\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:14<01:15,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  131.2180186601181\n","Test Loss:  53.23190949828131\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:17<01:12,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  131.92934245383367\n","Test Loss:  53.09849253746506\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:20<01:09,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  134.2316929287772\n","Test Loss:  47.97362611891003\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:23<01:05,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  129.78761419208604\n","Test Loss:  48.24218645610381\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:26<01:02,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  127.67060699159629\n","Test Loss:  48.43552626575547\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:29<01:00,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  127.44752429978689\n","Test Loss:  46.545655217953026\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:32<00:57,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  123.7130195654754\n","Test Loss:  48.32026638116804\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:35<00:53,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  126.16060371679487\n","Test Loss:  51.01410872064298\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:38<00:50,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.31568729691207\n","Test Loss:  46.06003359782335\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:41<00:47,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  121.5203229583567\n","Test Loss:  45.054990810429445\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:44<00:45,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  119.32777264673496\n","Test Loss:  55.31430787668796\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:47<00:41,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  114.13901623524725\n","Test Loss:  48.357199686579406\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:50<00:38,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  122.7125229096855\n","Test Loss:  49.4088802508777\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:53<00:35,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  125.85379359824583\n","Test Loss:  45.12797076551942\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:56<00:36,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  118.13531946431613\n","Test Loss:  51.38894135909504\n","Early stopping with best_loss:  45.054990810429445 and test_loss for this epoch:  51.38894135909504 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.201923049028089\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:29,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  403.11144104320556\n","Test Loss:  127.54938114155084\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:25,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  286.49390903220046\n","Test Loss:  91.8869175023865\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:22,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  237.11393885116559\n","Test Loss:  77.1769476798363\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:20,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  204.19729997008108\n","Test Loss:  68.60277610115008\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:17,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  189.21218405256514\n","Test Loss:  65.29218729853164\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:15,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.44292480300646\n","Test Loss:  63.89415599114727\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:11,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  172.16375708801206\n","Test Loss:  60.019032417447306\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:24<02:07,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  167.50134401925607\n","Test Loss:  57.5175079399487\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:27<02:03,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  161.46577119803987\n","Test Loss:  61.177863878489006\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:30<02:01,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.64967188204173\n","Test Loss:  54.01515789687983\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:33<01:58,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  154.83949925063644\n","Test Loss:  55.52342163346475\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:36<01:54,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  155.73232445359463\n","Test Loss:  56.333228504285216\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:39<01:51,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.2880604871898\n","Test Loss:  50.7849381712731\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:42<01:48,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.83215522725368\n","Test Loss:  53.219661680137506\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:45<01:45,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.66937815095298\n","Test Loss:  49.943309505295474\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:48<01:42,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  138.09741964994464\n","Test Loss:  49.025196566275554\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:51<01:39,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.18167305864336\n","Test Loss:  48.145582596887834\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:54<01:36,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.8900634746824\n","Test Loss:  46.67471461603418\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:57<01:33,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  126.03178124580882\n","Test Loss:  48.18968267051969\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:00<01:30,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  134.11024908407126\n","Test Loss:  50.04312446660333\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:03<01:27,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  130.39922593176016\n","Test Loss:  48.13360052584903\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:06<01:25,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  126.76243851770414\n","Test Loss:  47.226396511425264\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:09<01:21,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.41892971424386\n","Test Loss:  44.09987386720604\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:12<01:18,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  125.99482634325977\n","Test Loss:  47.00332114833873\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:15<01:15,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  123.88017433020286\n","Test Loss:  46.27775047934847\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:18<01:13,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  126.74835919891484\n","Test Loss:  44.76357561349869\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:21<01:09,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  125.42350835126126\n","Test Loss:  42.4179587464896\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:24<01:06,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  122.29855486089946\n","Test Loss:  51.04706997604808\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:27<01:03,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  118.29953302332433\n","Test Loss:  47.38347534681088\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:30<01:00,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  118.91654482122976\n","Test Loss:  45.22789428885153\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:33<00:57,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  122.0687390404637\n","Test Loss:  44.211745923457784\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:36<00:54,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  119.04355174250668\n","Test Loss:  41.67414567231026\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:39<00:51,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  113.72531512420392\n","Test Loss:  45.282250197720714\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:42<00:48,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  115.5052787970344\n","Test Loss:  42.61728278020746\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:45<00:45,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  115.88055054922006\n","Test Loss:  42.506104220985435\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:48<00:42,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  113.55870614416199\n","Test Loss:  41.793020225304645\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:51<00:43,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  113.71742557527614\n","Test Loss:  42.190251849999186\n","Early stopping with best_loss:  41.67414567231026 and test_loss for this epoch:  42.190251849999186 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0351268210221192\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:46,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  361.10304180230014\n","Test Loss:  110.82955687027425\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:42,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  242.47147684823722\n","Test Loss:  87.29366943746572\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:38,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  197.8867704841541\n","Test Loss:  70.82869343511993\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:35,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  184.45719160314184\n","Test Loss:  65.9877079326543\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:31,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.59836708876537\n","Test Loss:  62.40214882596047\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:20<02:29,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  163.98743259345065\n","Test Loss:  59.53171765463776\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:25,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.84925965376897\n","Test Loss:  58.03331475571031\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:27<02:22,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.430946394481\n","Test Loss:  56.74653483694419\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:30<02:19,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.8316599993268\n","Test Loss:  53.62455319066066\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:33<02:15,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.33368666755268\n","Test Loss:  53.96548297375557\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:37<02:12,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.2133802261087\n","Test Loss:  52.19368320945068\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:40<02:08,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  134.47839006065624\n","Test Loss:  48.6599438606936\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:44<02:04,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  127.93174555088626\n","Test Loss:  49.852741860202514\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:47<02:02,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  130.33586738744634\n","Test Loss:  49.83027459096047\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:50<01:59,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  128.09221964256722\n","Test Loss:  52.1382492488483\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:54<01:55,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  124.86928874399746\n","Test Loss:  46.55120499707118\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:57<01:51,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  127.37501924665412\n","Test Loss:  48.950405523064546\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:01<01:49,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  126.6893271341105\n","Test Loss:  49.22904386368464\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:04<01:45,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  121.05475439672591\n","Test Loss:  49.136865115433466\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:07<01:41,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  117.15622738127422\n","Test Loss:  45.586285289085936\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:11<01:38,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  119.85184233397013\n","Test Loss:  44.34368664593785\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:14<01:35,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  117.80998798192013\n","Test Loss:  44.10229681711644\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:18<01:31,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  120.88928994891467\n","Test Loss:  43.08747125027003\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:21<01:27,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  113.32280743187584\n","Test Loss:  43.39951667728019\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:24<01:24,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  120.60986072703963\n","Test Loss:  44.34155382942117\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:28<01:21,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  115.49425063288072\n","Test Loss:  44.520348397491034\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:31<01:18,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  111.48900265770499\n","Test Loss:  43.42119129473576\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:35<01:15,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  112.8836733516655\n","Test Loss:  42.88288798020221\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:38<01:11,  3.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  110.18494632342481\n","Test Loss:  44.77941225559334\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:42<01:08,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  113.31035362149123\n","Test Loss:  41.96776373984176\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:45<01:04,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  114.56826884843758\n","Test Loss:  42.17486059095245\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:48<01:01,  3.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  114.22691629157634\n","Test Loss:  41.75322067698289\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:52<00:57,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  108.85394767927937\n","Test Loss:  41.28224647627212\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:55<00:54,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  108.13631452151458\n","Test Loss:  41.780784154398134\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:58<00:50,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  104.47630441153888\n","Test Loss:  40.79208868427668\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [02:02<00:47,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  114.98876701889094\n","Test Loss:  40.45233581753564\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [02:05<00:44,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  106.64642741144053\n","Test Loss:  47.50022723688744\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [02:09<00:40,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  109.22549499908928\n","Test Loss:  42.0423256265567\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [02:12<00:37,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  107.99695736324793\n","Test Loss:  40.28230781003367\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [02:15<00:33,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  106.02382402232615\n","Test Loss:  53.771624850225635\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [02:19<00:30,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  104.52304768486647\n","Test Loss:  40.307121496181935\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:22<00:27,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  105.48660692217527\n","Test Loss:  48.07996885239845\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:25<00:23,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  103.10471934714587\n","Test Loss:  44.263865285232896\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:29<00:24,  3.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  104.54950835788622\n","Test Loss:  44.81636317781522\n","Early stopping with best_loss:  40.28230781003367 and test_loss for this epoch:  44.81636317781522 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0050361015124258\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:54,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.50389786064625\n","Test Loss:  41.58541419170797\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:54,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  93.8728274567984\n","Test Loss:  29.192517917603254\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:53,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.09166231635027\n","Test Loss:  27.950040127616376\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:53,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.37870214181021\n","Test Loss:  22.79174717856222\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:51,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  54.51615863468032\n","Test Loss:  23.62137223884929\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:50,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.91529393650126\n","Test Loss:  22.049024450592697\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:49,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.864439509401564\n","Test Loss:  21.378371697675902\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:47,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.25702945841476\n","Test Loss:  20.464803267386742\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:46,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.09391512395814\n","Test Loss:  19.94222461269237\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:45,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.05962534673745\n","Test Loss:  20.423194783797953\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:44,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  45.94173159010825\n","Test Loss:  20.72658805223182\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:43,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.08673359407112\n","Test Loss:  18.626752461248543\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:14<00:42,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.55544161214493\n","Test Loss:  20.731488205026835\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:15<00:40,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.80025658046361\n","Test Loss:  18.373996912996517\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:39,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.98745528428117\n","Test Loss:  20.547089771251194\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:38,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.74370152386837\n","Test Loss:  16.922681856842246\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:19<00:37,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.12709979910869\n","Test Loss:  18.31713764218148\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:20<00:35,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.06740828434704\n","Test Loss:  16.023439384181984\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:21<00:34,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.326165960752405\n","Test Loss:  18.51202886644751\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:22<00:33,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.25434686749941\n","Test Loss:  16.92896635364741\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:23<00:32,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.26785711519187\n","Test Loss:  17.563975912256865\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:24<00:31,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  40.33495586851495\n","Test Loss:  16.618355561280623\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:26<00:33,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  39.840817176154815\n","Test Loss:  16.97101990377996\n","Early stopping with best_loss:  16.023439384181984 and test_loss for this epoch:  16.97101990377996 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9433293489835203\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:57,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  134.19740084838122\n","Test Loss:  33.983348129782826\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:55,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.81822743453085\n","Test Loss:  22.665187299018726\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:53,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  61.33726742351428\n","Test Loss:  25.879711809539003\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:51,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  57.643365816096775\n","Test Loss:  25.37995255982969\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:50,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.54869618313387\n","Test Loss:  18.25107383262366\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:50,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.37482043413911\n","Test Loss:  17.00357080018148\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:49,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.170877176045906\n","Test Loss:  18.846409326914\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:47,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.654604556271806\n","Test Loss:  24.818403209297685\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:46,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.554503390565515\n","Test Loss:  15.394446820078883\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:45,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.88665621052496\n","Test Loss:  15.636568500456633\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:44,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.6378009156324\n","Test Loss:  15.308255364652723\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:43,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.486837719974574\n","Test Loss:  14.249009687453508\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:14<00:41,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.43829046579776\n","Test Loss:  14.386801710294094\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:15<00:40,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.075557149306405\n","Test Loss:  14.073500295053236\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:39,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.17809947079513\n","Test Loss:  16.446105998766143\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:38,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.69974757055752\n","Test Loss:  14.612232290906832\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:19<00:37,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.388617585238535\n","Test Loss:  13.751570515683852\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:20<00:36,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.95721660554409\n","Test Loss:  13.132265679654665\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:21<00:35,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.92422057973454\n","Test Loss:  14.990789327537641\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:22<00:34,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.28336663567461\n","Test Loss:  14.127263119851705\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:23<00:33,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  39.293916349997744\n","Test Loss:  14.544403147185221\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:25<00:32,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.16337031533476\n","Test Loss:  14.78404516124283\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:26<00:33,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  36.29892026167363\n","Test Loss:  14.411394288996235\n","Early stopping with best_loss:  13.132265679654665 and test_loss for this epoch:  14.411394288996235 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7394787905060137\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<01:00,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  107.74364583566785\n","Test Loss:  24.260579055640846\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:59,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.20307979476638\n","Test Loss:  22.886435291613452\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:57,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.63693118747324\n","Test Loss:  21.048612063168548\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:56,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.87217329221312\n","Test Loss:  16.90727216261439\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:06<00:55,  1.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.97499659319874\n","Test Loss:  16.25416659237817\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:07<00:54,  1.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.558022109325975\n","Test Loss:  18.673448358429596\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:53,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.905001011735294\n","Test Loss:  16.16669858142268\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:52,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.27617927786196\n","Test Loss:  16.57544774384587\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:11<00:51,  1.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.68236683966825\n","Test Loss:  14.612991704954766\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:12<00:50,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.50722944090376\n","Test Loss:  14.723357969895005\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:13<00:48,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.95153858704725\n","Test Loss:  14.089152068132535\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:14<00:47,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.96142957912525\n","Test Loss:  14.456880438541702\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:16<00:46,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.94645790802315\n","Test Loss:  13.348812158685178\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:17<00:44,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.4602612555027\n","Test Loss:  14.150300937035354\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:18<00:43,  1.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.20156553987181\n","Test Loss:  13.332132850773633\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:19<00:41,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.9674516877858\n","Test Loss:  13.63014895276865\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:21<00:40,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.521001552115194\n","Test Loss:  14.807528272023774\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:22<00:39,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.66873799462337\n","Test Loss:  13.193219813110773\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:23<00:38,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.67614019528264\n","Test Loss:  14.713914463296533\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:24<00:36,  1.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.72289052371343\n","Test Loss:  13.51534638600424\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:25<00:35,  1.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.38357580144657\n","Test Loss:  13.260175713687204\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:27<00:33,  1.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.831765975104645\n","Test Loss:  13.397346484707668\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:28<00:32,  1.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.186021844041534\n","Test Loss:  13.038884794688784\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:29<00:31,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.38259948097402\n","Test Loss:  13.28549562569242\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:30<00:30,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.28709899660316\n","Test Loss:  16.55158390419092\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:32<00:29,  1.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.189555458840914\n","Test Loss:  12.022864006692544\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:33<00:28,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.695322841522284\n","Test Loss:  14.584639812237583\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:34<00:26,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.05599228141364\n","Test Loss:  14.148487722442951\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:35<00:25,  1.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.8190933483711\n","Test Loss:  13.073498036246747\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:36<00:24,  1.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  34.194487062399276\n","Test Loss:  14.495877669891343\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:38<00:25,  1.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  35.61578443762846\n","Test Loss:  13.326006596325897\n","Early stopping with best_loss:  12.022864006692544 and test_loss for this epoch:  13.326006596325897 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5604496909426683\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:12,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  255.03620704170316\n","Test Loss:  80.5960780828027\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:10,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  136.9909701560391\n","Test Loss:  55.74606998206582\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:06,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  108.44016046344768\n","Test Loss:  45.28096096531954\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:03,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  99.35538907209411\n","Test Loss:  40.43891099485336\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<01:59,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  95.53238257375779\n","Test Loss:  41.115688364370726\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<01:57,  2.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  88.58485440147342\n","Test Loss:  41.161599573504645\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:56,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  84.92497797528631\n","Test Loss:  35.258171060471795\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:52,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  82.2702727773576\n","Test Loss:  35.54026375035755\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:49,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  80.25872587857884\n","Test Loss:  34.36050643923227\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:26<01:46,  2.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.25272793875774\n","Test Loss:  31.99652777740266\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:29<01:43,  2.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.58709060665569\n","Test Loss:  31.063491754466668\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:40,  2.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.2222861056216\n","Test Loss:  29.832339726752252\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:34<01:38,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  73.8705559213995\n","Test Loss:  33.012715468066745\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:37<01:36,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  72.93324068255606\n","Test Loss:  34.71680500160437\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:40<01:33,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  69.83755203380133\n","Test Loss:  35.531247450446244\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:42<01:30,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  67.44332793165813\n","Test Loss:  31.52113952639047\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:45<01:28,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.76169027067954\n","Test Loss:  28.644524304836523\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:48<01:26,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  70.09632074419642\n","Test Loss:  32.64305184604018\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:51<01:25,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.04260033465107\n","Test Loss:  28.224624374619452\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:53<01:23,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  66.69478581380099\n","Test Loss:  29.83779055197374\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:56<01:19,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  63.68764963137801\n","Test Loss:  30.57466718321666\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:59<01:16,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  66.58096821029903\n","Test Loss:  28.78685851235059\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:02<01:14,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  62.02309427905129\n","Test Loss:  28.840412661476876\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:04<01:16,  2.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  64.88122369235498\n","Test Loss:  28.999611316656228\n","Early stopping with best_loss:  28.224624374619452 and test_loss for this epoch:  28.999611316656228 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6279429179773778\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:15,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  227.02051075175405\n","Test Loss:  55.18602484167786\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:11,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  126.70815515448339\n","Test Loss:  38.28811426903121\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:08,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  106.12745923688635\n","Test Loss:  37.640279401966836\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:07,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  99.01844533981057\n","Test Loss:  31.301421236246824\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:04,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  89.59480401413748\n","Test Loss:  30.031581364222802\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<02:01,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  87.67636868666159\n","Test Loss:  27.354077790805604\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<01:59,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  84.31564681007876\n","Test Loss:  31.173913761158474\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:22<01:56,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  83.15276105780504\n","Test Loss:  32.93715271737892\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:53,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.65080636212952\n","Test Loss:  25.369441365764942\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:51,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.01175080559915\n","Test Loss:  24.686069602001226\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:30<01:48,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  77.23287261388032\n","Test Loss:  25.641851757769473\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:33<01:44,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  77.3021842125745\n","Test Loss:  26.70642793137813\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  76.14125052379677\n","Test Loss:  30.64063337672269\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:37,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  73.85549091311987\n","Test Loss:  25.906762926490046\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:41<01:45,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  72.61804479744751\n","Test Loss:  29.12340094175306\n","Early stopping with best_loss:  24.686069602001226 and test_loss for this epoch:  29.12340094175306 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5340137407078862\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:25,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  199.87654241733253\n","Test Loss:  49.622200430661906\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:21,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  115.03736627672333\n","Test Loss:  38.85484522001934\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:17,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  95.33581684017554\n","Test Loss:  34.98796750768088\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:14,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.99559411953669\n","Test Loss:  33.74565133091528\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:13,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  88.88947360313614\n","Test Loss:  30.74903886995162\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:10,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.76229227636941\n","Test Loss:  29.824047101894394\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:07,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  80.16442563274177\n","Test Loss:  37.441074570524506\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:23<02:03,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.62981688430591\n","Test Loss:  29.15944805170875\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:26<02:01,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.73556216139696\n","Test Loss:  27.212189155456144\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:29<01:58,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  73.17420583619969\n","Test Loss:  29.140150161547353\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:32<01:54,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  72.538281934103\n","Test Loss:  28.257864259416237\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:35<01:52,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.82365238963393\n","Test Loss:  26.691402761178324\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:38<01:49,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  72.72099856825662\n","Test Loss:  28.246323300154472\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:41<01:46,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  73.50573999047629\n","Test Loss:  28.505641547992127\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:44<01:43,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.43195642629871\n","Test Loss:  26.16247774125077\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:47<01:40,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.10859045817051\n","Test Loss:  24.41088119498454\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:50<01:37,  2.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  69.59421551343985\n","Test Loss:  27.162185919383774\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:53<01:34,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  70.24207444593776\n","Test Loss:  26.246382606914267\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:56<01:31,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  68.50539022745215\n","Test Loss:  27.769717824892723\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:59<01:28,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  68.98095646391448\n","Test Loss:  27.821307320322376\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:01<01:32,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  65.21349115602789\n","Test Loss:  24.412158180726692\n","Early stopping with best_loss:  24.41088119498454 and test_loss for this epoch:  24.412158180726692 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6112681440282144\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:40,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  401.17380201723427\n","Test Loss:  127.28392953355797\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:36,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  251.7363730785437\n","Test Loss:  94.95691518083913\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:33,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  202.90489261050243\n","Test Loss:  80.22322553617414\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:30,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  187.85339732735883\n","Test Loss:  78.2758566190023\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:26,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  175.26937613711925\n","Test Loss:  70.32563732448034\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:24,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  166.70020090107573\n","Test Loss:  66.81839953077724\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:20,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  163.23565710068215\n","Test Loss:  69.2978714996716\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:26<02:17,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  161.44731018634047\n","Test Loss:  65.13613432471175\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:13,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  155.3062067059218\n","Test Loss:  65.72649663162883\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:32<02:09,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.41589280584594\n","Test Loss:  58.42373299028259\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:35<02:06,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.89773673104355\n","Test Loss:  61.98653949203435\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:39<02:03,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  147.0206052484573\n","Test Loss:  59.405285697226645\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:42<01:59,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  146.54449698890676\n","Test Loss:  59.916660543647595\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:45<01:56,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  144.35823674142011\n","Test Loss:  65.47127949050628\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:48<01:53,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  138.3403475236264\n","Test Loss:  56.32772627787199\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:52<01:50,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  135.1469396498287\n","Test Loss:  59.38883727299981\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:55<01:47,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  136.64398450090084\n","Test Loss:  59.87413713580463\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:58<01:44,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  136.30514689040137\n","Test Loss:  54.44523477781331\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:01<01:41,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  132.67857310330146\n","Test Loss:  63.55293659464223\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:05<01:37,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  133.87595769573818\n","Test Loss:  59.75567181214865\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:08<01:34,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.4514194445219\n","Test Loss:  53.989545464894036\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:11<01:30,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  128.99996054981602\n","Test Loss:  56.20959443907486\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:14<01:27,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  129.08837066602428\n","Test Loss:  61.36819864733843\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:17<01:23,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  131.8698414026876\n","Test Loss:  56.552461521467194\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:21<01:22,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  126.92106735339621\n","Test Loss:  54.47133974224562\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:24<01:19,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  125.94693784773699\n","Test Loss:  51.79226170579204\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:28<01:15,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  125.91991431533825\n","Test Loss:  52.621875730808824\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:31<01:11,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  127.68185787196853\n","Test Loss:  53.79477409584797\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:34<01:08,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.93146671527938\n","Test Loss:  50.49680199698196\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:37<01:05,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  126.11588608520105\n","Test Loss:  51.87510283465963\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:41<01:02,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  122.48487267782912\n","Test Loss:  50.11797624446626\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:44<00:58,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  126.226532202214\n","Test Loss:  49.87246207270073\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:47<00:55,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  121.95423333227518\n","Test Loss:  52.32674036145909\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:50<00:52,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  122.665153106238\n","Test Loss:  51.203084381704684\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:54<00:49,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  120.333357796364\n","Test Loss:  53.9643323571363\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:57<00:45,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  121.2337097832351\n","Test Loss:  52.040853537924704\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [02:00<00:46,  3.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  120.74584695120575\n","Test Loss:  59.86183993285522\n","Early stopping with best_loss:  49.87246207270073 and test_loss for this epoch:  59.86183993285522 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1242180741556094\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:41,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  364.0212547266856\n","Test Loss:  102.43822971312329\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:38,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  233.08601051580627\n","Test Loss:  88.78719650919084\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:34,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  199.03532431460917\n","Test Loss:  69.5923822275945\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:31,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  180.51468437130097\n","Test Loss:  66.30467358047463\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:27,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  172.7437888715649\n","Test Loss:  59.208701033261605\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:25,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.6105908783502\n","Test Loss:  58.85074571662699\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:21,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  163.70660496363416\n","Test Loss:  57.12004741735291\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:26<02:17,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.0311690241797\n","Test Loss:  56.957693528878735\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:13,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  159.29553802247392\n","Test Loss:  62.14905996568268\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:32<02:11,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  153.87378786090994\n","Test Loss:  57.28370535535214\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:36<02:08,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.96889649145305\n","Test Loss:  51.42970681953739\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:39<02:04,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.63323878339725\n","Test Loss:  50.42159417207586\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:42<02:04,  3.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  142.27010134991724\n","Test Loss:  55.314636946539395\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:46<02:02,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.82876454963116\n","Test Loss:  49.36091860051965\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:49<01:59,  3.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.99984830099856\n","Test Loss:  52.607779437996214\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:53<01:56,  3.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  132.0477031391929\n","Test Loss:  49.388928378539276\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:56<01:53,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.28205759369303\n","Test Loss:  48.65167815343011\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:00<01:49,  3.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  138.8402233736124\n","Test Loss:  48.43021504385979\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:03<01:44,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  130.46755254809977\n","Test Loss:  53.6665828305413\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:06<01:41,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  131.40896059342776\n","Test Loss:  47.9049922968552\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:10<01:36,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  130.72232721399632\n","Test Loss:  52.43606504856143\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:13<01:33,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.37204763750196\n","Test Loss:  49.8545639658696\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:16<01:29,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  127.81578906654613\n","Test Loss:  47.704770763608394\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:20<01:26,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  128.96583644213388\n","Test Loss:  53.40095073453267\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:23<01:23,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  124.66449114773422\n","Test Loss:  47.863999477238394\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:26<01:19,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  122.29637293462292\n","Test Loss:  47.096892463450786\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:30<01:16,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  124.58780886585009\n","Test Loss:  45.638112469314365\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:33<01:13,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  123.1801130209351\n","Test Loss:  53.14659442345146\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:36<01:09,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  126.78840526184649\n","Test Loss:  51.09590046049561\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:40<01:06,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  129.26441554541816\n","Test Loss:  49.14685031701811\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:43<01:03,  3.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  121.47134694035049\n","Test Loss:  54.015759054687805\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:46<01:05,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  119.10869092593202\n","Test Loss:  46.828386174252955\n","Early stopping with best_loss:  45.638112469314365 and test_loss for this epoch:  46.828386174252955 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0771776129286947\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:54,  3.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  326.8760151350871\n","Test Loss:  99.60570988804102\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:07<02:53,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  208.70192509779008\n","Test Loss:  78.87204570311587\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:53,  3.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  183.24055170323118\n","Test Loss:  69.35830724082189\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:14<02:48,  3.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  174.39419904671377\n","Test Loss:  60.515403145866\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:18<02:43,  3.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  172.7383839476388\n","Test Loss:  59.917425673949765\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:21<02:38,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  162.8849541154923\n","Test Loss:  62.791142311820295\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:25<02:34,  3.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.6975483467686\n","Test Loss:  59.27179769612849\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:28<02:31,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  152.97707203391474\n","Test Loss:  68.04793289164081\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:32<02:27,  3.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.0919096331054\n","Test Loss:  52.22585580943269\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:36<02:23,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  147.735668944777\n","Test Loss:  55.55554761175881\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:39<02:21,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  144.96496215838124\n","Test Loss:  54.77797341358382\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:43<02:17,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  146.7563173949893\n","Test Loss:  61.232445849105716\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:46<02:13,  3.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.275264529977\n","Test Loss:  51.17439312650822\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:50<02:09,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  143.7338279368705\n","Test Loss:  53.324668149231\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:54<02:05,  3.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.80911074083997\n","Test Loss:  54.08302700764034\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:57<02:01,  3.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  137.49340094882064\n","Test Loss:  51.276289817120414\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [01:01<01:58,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.09816864921595\n","Test Loss:  51.02933574539202\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:04<01:55,  3.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  134.84234020223084\n","Test Loss:  45.75901769133634\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:08<01:52,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  130.87447811546735\n","Test Loss:  52.31320281687658\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:12<01:49,  3.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  132.27944656356703\n","Test Loss:  47.19042562236427\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:15<01:44,  3.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  129.5191780035384\n","Test Loss:  51.52760169369867\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:19<01:40,  3.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  129.84267264987284\n","Test Loss:  46.28786024302826\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:22<01:45,  3.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  136.28066175876302\n","Test Loss:  51.9351884235075\n","Early stopping with best_loss:  45.75901769133634 and test_loss for this epoch:  51.9351884235075 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9843356926044985\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:50,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  161.9389044754207\n","Test Loss:  32.627423618454486\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:48,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  98.70523053687066\n","Test Loss:  25.032786248251796\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:48,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.45907104946673\n","Test Loss:  18.33956036780728\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:46,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  61.47783169406466\n","Test Loss:  19.353043402545154\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:45,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.86606566829141\n","Test Loss:  17.054372598417103\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:45,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.91126679372974\n","Test Loss:  15.777692350675352\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:43,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.627942798601\n","Test Loss:  14.615903111698572\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:43,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.0060275204014\n","Test Loss:  14.450034594978206\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:42,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.9286903339671\n","Test Loss:  13.792640933766961\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:41,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.12429002998397\n","Test Loss:  14.006974914576858\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:39,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  45.17139151250012\n","Test Loss:  13.984745526104234\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:12<00:38,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.95937849394977\n","Test Loss:  13.3982361756498\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:13<00:38,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.726969382259995\n","Test Loss:  13.379045794485137\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:14<00:37,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.48799241275992\n","Test Loss:  12.745260518509895\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:15<00:36,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.27328513178509\n","Test Loss:  12.909059446537867\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:16<00:35,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.47719042538665\n","Test Loss:  12.481806392257567\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:17<00:34,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.85446651594248\n","Test Loss:  12.613364340300905\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:18<00:33,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.11794709894457\n","Test Loss:  13.038318908424117\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:19<00:32,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.75569390482269\n","Test Loss:  12.422065761580598\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:20<00:31,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.209405921632424\n","Test Loss:  12.419184536556713\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:21<00:29,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.80033724292298\n","Test Loss:  12.318936307332478\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:22<00:28,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.37894932780182\n","Test Loss:  13.243382072396344\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:23<00:27,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.5527454460389\n","Test Loss:  12.242437289038207\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:24<00:27,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.490878080541734\n","Test Loss:  12.935545965097845\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:25<00:26,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.363729943404905\n","Test Loss:  12.5425209722016\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:26<00:25,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  39.46349664925947\n","Test Loss:  13.28361457574647\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:28<00:24,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.1832558036549\n","Test Loss:  11.963342888106126\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:29<00:22,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.84574761695694\n","Test Loss:  14.350598669610918\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:30<00:21,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.770040324132424\n","Test Loss:  12.466420357086463\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:31<00:20,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.590606714366004\n","Test Loss:  13.331238032318652\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:32<00:19,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  37.2565616046777\n","Test Loss:  12.039338170623523\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:33<00:20,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  35.571219097299036\n","Test Loss:  12.135637161845807\n","Early stopping with best_loss:  11.963342888106126 and test_loss for this epoch:  12.135637161845807 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6492604633132026\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:51,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.61746715847403\n","Test Loss:  29.35782414767891\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:51,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.16906676162034\n","Test Loss:  21.402818354021292\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:50,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.98229985684156\n","Test Loss:  18.48716207232792\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:48,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.74990263499785\n","Test Loss:  19.091054528136738\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:47,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.31372769852169\n","Test Loss:  16.289486115216278\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:46,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.8375556000974\n","Test Loss:  15.584895088686608\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:45,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.94420675805304\n","Test Loss:  15.472549903846812\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:44,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.453278296859935\n","Test Loss:  14.552930757403374\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:43,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.74759171594633\n","Test Loss:  19.198808357003145\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:42,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  44.50402704279986\n","Test Loss:  14.935392052284442\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:40,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  43.76875098620076\n","Test Loss:  15.96734936098801\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:12<00:40,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.924769778735936\n","Test Loss:  14.165927301393822\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:13<00:39,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.37913626793306\n","Test Loss:  14.398656821809709\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:14<00:38,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.654444128856994\n","Test Loss:  14.309723590617068\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:15<00:37,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.6144516778877\n","Test Loss:  12.963347126846202\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:17<00:37,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.361535048577935\n","Test Loss:  13.556781036255416\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:18<00:35,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.641785223269835\n","Test Loss:  13.572433114692103\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:19<00:34,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.004407973610796\n","Test Loss:  12.933773959521204\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:20<00:32,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.206342872348614\n","Test Loss:  12.762603692477569\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:21<00:32,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.22350567311514\n","Test Loss:  13.482713000499643\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:22<00:30,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.46295379672665\n","Test Loss:  13.243007467070129\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:23<00:29,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.7639355531428\n","Test Loss:  12.939769443968544\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:24<00:28,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  39.19011689920444\n","Test Loss:  12.793920969823375\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:25<00:27,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.9306654506363\n","Test Loss:  12.047645429265685\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:26<00:26,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.14743425010238\n","Test Loss:  12.960166635777568\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:27<00:25,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.39942407020135\n","Test Loss:  14.583307926543057\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:28<00:24,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.338166194502264\n","Test Loss:  11.883603176334873\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:29<00:23,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.06974656949751\n","Test Loss:  11.647835498675704\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:30<00:22,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.204475109814666\n","Test Loss:  13.578643230779562\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:31<00:21,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.693089397856966\n","Test Loss:  11.532628846238367\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:32<00:19,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.61026480572764\n","Test Loss:  12.109350639977492\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:33<00:18,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.17911847162759\n","Test Loss:  13.397730260156095\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:34<00:17,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.48002740833908\n","Test Loss:  12.142993563669734\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:36<00:16,  1.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.005038910661824\n","Test Loss:  11.422638563963119\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:37<00:15,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.09080546381301\n","Test Loss:  10.811195865564514\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:38<00:14,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.49918245623121\n","Test Loss:  11.461986677692039\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:39<00:13,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  33.34413461649092\n","Test Loss:  12.827479342930019\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:40<00:12,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.358417616807856\n","Test Loss:  11.242474346829113\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:41<00:11,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  33.25566088827327\n","Test Loss:  10.98997207696084\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:42<00:11,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  33.6191847891896\n","Test Loss:  13.104888903908432\n","Early stopping with best_loss:  10.811195865564514 and test_loss for this epoch:  13.104888903908432 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5985734826078895\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:56,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  111.43589869886637\n","Test Loss:  29.38281875103712\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:55,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.16240807040595\n","Test Loss:  24.941586104105227\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:54,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.15464318951126\n","Test Loss:  20.613541122642346\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:53,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.64271092682611\n","Test Loss:  18.806429139338434\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:52,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.645418231375515\n","Test Loss:  19.06469623965677\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:50,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.85188909014687\n","Test Loss:  16.406732817995362\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:50,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.46898534864886\n","Test Loss:  17.704093905864283\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:48,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.00810165342409\n","Test Loss:  20.10127491829917\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:48,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.68115832959302\n","Test Loss:  17.70896353169519\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:46,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.74921179073863\n","Test Loss:  15.537798106786795\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:45,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.3817055519321\n","Test Loss:  16.69479479966685\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:43,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.182522734161466\n","Test Loss:  15.0772355098743\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:15<00:42,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.32718153795577\n","Test Loss:  15.550247322651558\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:16<00:41,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.23967677069595\n","Test Loss:  16.37002675840631\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:40,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.59667582681868\n","Test Loss:  15.851269736886024\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:39,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.94924691331107\n","Test Loss:  15.071829830936622\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:19<00:37,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.3146305224509\n","Test Loss:  16.125468506361358\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:20<00:36,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.90954820450861\n","Test Loss:  14.528975054621696\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:21<00:35,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.13688476837706\n","Test Loss:  15.812375030713156\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:23<00:34,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.34240559709724\n","Test Loss:  14.808937844150933\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:24<00:33,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  31.901317011681385\n","Test Loss:  14.454164202325046\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:25<00:32,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.13147314428352\n","Test Loss:  15.008473663590848\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:26<00:30,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.029363318783\n","Test Loss:  14.597225958481431\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:27<00:29,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  32.25603687798139\n","Test Loss:  15.519463716074824\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:28<00:28,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  32.94282518979162\n","Test Loss:  14.745165101485327\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:29<00:29,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  34.32409496064065\n","Test Loss:  15.0809149320703\n","Early stopping with best_loss:  14.454164202325046 and test_loss for this epoch:  15.0809149320703 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8888625210130765\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:05,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  214.01421170774847\n","Test Loss:  54.922614168783184\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:05,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  100.333478852408\n","Test Loss:  37.105790104862535\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:02,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  82.08465526840882\n","Test Loss:  33.77624120336259\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:59,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.66772097896319\n","Test Loss:  31.46341061242856\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:55,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.8116566548415\n","Test Loss:  30.306119362125173\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:53,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.33360776555492\n","Test Loss:  28.5290281624184\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:50,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  68.58803006709786\n","Test Loss:  29.897409498749766\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:47,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.0561040265602\n","Test Loss:  28.337969233863987\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:45,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.60536060389131\n","Test Loss:  25.4087915791024\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:43,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  64.88609719098895\n","Test Loss:  26.040960306851048\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:40,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.667101211700356\n","Test Loss:  24.762575550586917\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:37,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.71100261333049\n","Test Loss:  32.197631151022506\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:34,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  60.593393754039425\n","Test Loss:  25.266544827565667\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:36<01:32,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  60.57013598259073\n","Test Loss:  27.193504404945998\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:38<01:30,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.03234510857146\n","Test Loss:  23.470395011172513\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:28,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.797438171866816\n","Test Loss:  26.391667314892402\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:43<01:25,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  58.06108022891567\n","Test Loss:  22.79164661516552\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:46<01:22,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.34807548779645\n","Test Loss:  22.492221319989767\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:48<01:19,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.76889770611888\n","Test Loss:  21.391784664971055\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:51<01:17,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.694910271966364\n","Test Loss:  22.032751877530245\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:54<01:14,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  55.585009672737215\n","Test Loss:  23.171493229805492\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:56<01:12,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  50.08571871742606\n","Test Loss:  22.498942115460522\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:59<01:09,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.170594248513225\n","Test Loss:  21.33338647399796\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:01<01:07,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.56955833816028\n","Test Loss:  22.119336680858396\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:04<01:04,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  49.297037133190315\n","Test Loss:  21.766196620694245\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:07<01:02,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  50.520890836196486\n","Test Loss:  22.257401709794067\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:09<00:59,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.733719388605095\n","Test Loss:  21.079848333916743\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:12<00:56,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.357766342989635\n","Test Loss:  25.671564495947678\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:14<00:54,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  49.15696377042332\n","Test Loss:  22.40205988881644\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:17<00:51,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  46.92287888831925\n","Test Loss:  22.632446818781318\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:19<00:48,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  49.01045731708291\n","Test Loss:  23.05596495428472\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:22<00:46,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.21563447947847\n","Test Loss:  20.81224650707736\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:25<00:43,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.01703134752461\n","Test Loss:  23.12528041790938\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:27<00:41,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  44.81138882943196\n","Test Loss:  25.19371590355877\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:30<00:38,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  46.21065980568528\n","Test Loss:  20.81568479796988\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:32<00:35,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  47.012375828810036\n","Test Loss:  21.945394644862972\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:35<00:33,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.637667605507886\n","Test Loss:  20.34835255978396\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:37<00:31,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.11033636049251\n","Test Loss:  20.74393363285344\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:40<00:28,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  47.15864029165823\n","Test Loss:  21.42512640717905\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:43<00:25,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  46.71711175265955\n","Test Loss:  20.813542329968186\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:45<00:23,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  44.96415198115574\n","Test Loss:  20.722933624725556\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:48<00:23,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  45.254447968443856\n","Test Loss:  21.227429586579092\n","Early stopping with best_loss:  20.34835255978396 and test_loss for this epoch:  21.227429586579092 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5408131843773027\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:06,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.68539231899194\n","Test Loss:  64.4700649643055\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:03,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  100.22528570203576\n","Test Loss:  36.8027151307906\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:01,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.42690119048348\n","Test Loss:  35.85286006183014\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:59,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.4388621081016\n","Test Loss:  33.678293792298064\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<01:57,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.3730680939334\n","Test Loss:  27.412913706328254\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:55,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  66.61365626580664\n","Test Loss:  27.454127906123176\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:52,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.95936842064839\n","Test Loss:  26.18519185396144\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:50,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  67.01231941697188\n","Test Loss:  27.80232164746849\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:46,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  63.1637359217566\n","Test Loss:  26.845544153184164\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:26<01:43,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  58.625838639680296\n","Test Loss:  29.22785206194385\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:41,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  58.55990678060334\n","Test Loss:  24.567453358497005\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:31<01:38,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  57.99854471790604\n","Test Loss:  24.778462693095207\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:36,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.64626309211599\n","Test Loss:  23.84361968099256\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:36<01:33,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  57.69760521574062\n","Test Loss:  23.889659580541775\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:38<01:29,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  54.54728415989666\n","Test Loss:  30.613324594916776\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:27,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  54.272606155485846\n","Test Loss:  28.399207981972722\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:44<01:24,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.82099127411493\n","Test Loss:  23.733155275695026\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:46<01:23,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.67196038446855\n","Test Loss:  22.947609103575815\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:49<01:20,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.01310395792825\n","Test Loss:  24.79728775494732\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:51<01:18,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.41824624777655\n","Test Loss:  20.70993771814392\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:54<01:15,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.94298379361862\n","Test Loss:  25.7280043271021\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:57<01:13,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.559723580343416\n","Test Loss:  19.783894872671226\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:59<01:10,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.918008421736886\n","Test Loss:  23.691936778835952\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:02<01:07,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  50.335995095418184\n","Test Loss:  21.20539445526083\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:04<01:05,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  48.440672036784235\n","Test Loss:  20.996505571645685\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:07<01:02,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  48.49522325702128\n","Test Loss:  19.988292635884136\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:10<01:04,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  45.478944658709224\n","Test Loss:  24.37476276565576\n","Early stopping with best_loss:  19.783894872671226 and test_loss for this epoch:  24.37476276565576 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.44140970416386077\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:22,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.69328094902448\n","Test Loss:  42.448399825021625\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:18,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  88.94911203533411\n","Test Loss:  32.47428369557019\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:14,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.30243276827969\n","Test Loss:  27.594404806295643\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:13,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  73.56951786065474\n","Test Loss:  27.92313854454551\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:10,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.56459959089989\n","Test Loss:  24.315813896944746\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:07,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  67.6992711974599\n","Test Loss:  27.54345087663387\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:04,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  63.91069525157218\n","Test Loss:  24.486974235391244\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:23<02:01,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.12394716072595\n","Test Loss:  20.20419294567546\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:26<01:58,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.74027818022296\n","Test Loss:  20.48718794286833\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:28<01:55,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.95185345594655\n","Test Loss:  19.28132016392192\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:31<01:52,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.74524292923161\n","Test Loss:  21.9144574701495\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:34<01:49,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  56.574945921383915\n","Test Loss:  22.390364223974757\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:37<01:46,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  55.77461844636127\n","Test Loss:  20.014199884259142\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:40<01:43,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.77199446759187\n","Test Loss:  17.562642721051816\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:43<01:41,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.10311350150732\n","Test Loss:  19.46920993528329\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:46<01:39,  2.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  53.18572577252053\n","Test Loss:  22.016784757724963\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:49<01:35,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.78657172364183\n","Test Loss:  16.956668237777194\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:52<01:32,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.750882020627614\n","Test Loss:  20.628534592688084\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:54<01:29,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  53.84778224362526\n","Test Loss:  18.509800180545426\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:57<01:27,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  53.77187027607579\n","Test Loss:  17.99513096307055\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:00<01:24,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  50.400389084476046\n","Test Loss:  19.306377925007837\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:03<01:27,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  53.029945469796075\n","Test Loss:  18.00714503848576\n","Early stopping with best_loss:  16.956668237777194 and test_loss for this epoch:  18.00714503848576 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.36238335085311235\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:36,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  413.6068411129527\n","Test Loss:  127.72805221262388\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:33,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  263.6549120147247\n","Test Loss:  88.13066962710582\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:34,  3.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  205.83185079763643\n","Test Loss:  80.94182066450594\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:30,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  188.28111835260643\n","Test Loss:  75.24609397235326\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:27,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.93488034664188\n","Test Loss:  74.0531207510503\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:22,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  175.36420850915601\n","Test Loss:  70.23647873906884\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:19,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  164.01763822842622\n","Test Loss:  69.24797568103531\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:26<02:16,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  161.61133745731786\n","Test Loss:  62.22293849932612\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:12,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  158.9607914564549\n","Test Loss:  64.30629289423814\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:32<02:08,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.9712452350068\n","Test Loss:  57.67216790188104\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:35<02:04,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  152.51904329564422\n","Test Loss:  57.97008534579072\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:38<02:02,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  146.43784119433258\n","Test Loss:  64.78820203972282\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:42<02:00,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  151.6756782104494\n","Test Loss:  57.725225228699856\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:45<01:56,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  142.72644097189186\n","Test Loss:  56.56001060002018\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:48<01:52,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.5922651723813\n","Test Loss:  55.172058660769835\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:51<01:49,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  146.75525908230338\n","Test Loss:  57.33885483077029\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:54<01:46,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.19779584661592\n","Test Loss:  54.11155329426401\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:58<01:42,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.35484065598575\n","Test Loss:  53.72406152711483\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:01<01:38,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  137.7816073424765\n","Test Loss:  55.77896376335411\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:04<01:35,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  137.64459748164518\n","Test Loss:  55.85881741635967\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:07<01:32,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  142.0282412096858\n","Test Loss:  53.513217905696365\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:10<01:30,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.4187002472463\n","Test Loss:  51.7606909017486\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:14<01:26,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  132.74119891354349\n","Test Loss:  60.11150243275915\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:17<01:23,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  130.60696296105743\n","Test Loss:  53.61292303551454\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:20<01:20,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.00548417965183\n","Test Loss:  48.78563339315588\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:23<01:16,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.4880448464828\n","Test Loss:  48.6349976156489\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:26<01:13,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  131.1478893335443\n","Test Loss:  51.971584048413206\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:30<01:10,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  126.60231505174306\n","Test Loss:  47.684388875277364\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:33<01:07,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  127.56020439782878\n","Test Loss:  50.69009370994172\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:36<01:04,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  126.19881578462082\n","Test Loss:  52.20118336327141\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:39<01:00,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  123.07006327144336\n","Test Loss:  49.12124539116485\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:42<00:57,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  127.74490782490466\n","Test Loss:  48.65470237471163\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:46<00:59,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  123.1814227658324\n","Test Loss:  51.443034185358556\n","Early stopping with best_loss:  47.684388875277364 and test_loss for this epoch:  51.443034185358556 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0964512024748685\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:43,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  341.4082931075245\n","Test Loss:  98.4088776006829\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:36,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  221.1002960295882\n","Test Loss:  79.18446290271822\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:32,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  192.39292012760416\n","Test Loss:  70.4851280519506\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:28,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  174.1561623836751\n","Test Loss:  68.76069022738375\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:25,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.28208552591968\n","Test Loss:  66.35007375275018\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:22,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.22275071335025\n","Test Loss:  63.18003607876017\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:17,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  152.6081073555979\n","Test Loss:  69.15648108674213\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:15,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.71064405562356\n","Test Loss:  59.504724156984594\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:11,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.7550075640902\n","Test Loss:  59.29245616472326\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:32<02:08,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.2034334950149\n","Test Loss:  54.817882148287026\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:35<02:04,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.06394988569082\n","Test Loss:  59.13512064721726\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:38<02:01,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.6914150113589\n","Test Loss:  55.34496395068709\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:41<01:58,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  132.0598661438271\n","Test Loss:  56.992092745611444\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:44<01:54,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  130.4847101419582\n","Test Loss:  58.55277131637558\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:48<02:03,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  129.92993007175392\n","Test Loss:  66.22393448234652\n","Early stopping with best_loss:  54.817882148287026 and test_loss for this epoch:  66.22393448234652 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.2959580727758149\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:53,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  330.055317157181\n","Test Loss:  96.13922415394336\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:07<02:50,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  208.38817049073987\n","Test Loss:  69.43163490050938\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:47,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  186.71597943405504\n","Test Loss:  64.06537780040526\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:14<02:44,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.322245684074\n","Test Loss:  54.52961391577264\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:17<02:38,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  169.1454488564923\n","Test Loss:  56.611588717554696\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:21<02:34,  3.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  161.50927556608804\n","Test Loss:  55.64130363648292\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:24<02:31,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  163.97952508635353\n","Test Loss:  49.70548444479937\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:28<02:28,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  153.09872657901724\n","Test Loss:  53.86840447419672\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:31<02:23,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  150.26943552849116\n","Test Loss:  52.591016300430056\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:35<02:19,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  150.70198387510027\n","Test Loss:  54.12276662734803\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:38<02:18,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.12333338713506\n","Test Loss:  46.858815526240505\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:42<02:14,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  150.60610493004788\n","Test Loss:  49.12936958268983\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:45<02:10,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.8783266385435\n","Test Loss:  45.06710899955942\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:49<02:08,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.76677353749983\n","Test Loss:  54.596067369682714\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:53<02:04,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  142.3413453422254\n","Test Loss:  46.8565206839703\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:56<02:00,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  136.90283022038057\n","Test Loss:  45.84732954693027\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [01:00<01:56,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.98055724977166\n","Test Loss:  42.6941643434111\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:03<01:53,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  137.31855874450412\n","Test Loss:  45.96697960153688\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:07<01:48,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  131.80408268625615\n","Test Loss:  45.73532506680931\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:10<01:45,  3.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  128.49045853642747\n","Test Loss:  43.29502896532358\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:14<01:43,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  130.4136267505819\n","Test Loss:  44.29080231083208\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:17<01:47,  3.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  131.9010829537292\n","Test Loss:  51.08008314768085\n","Early stopping with best_loss:  42.6941643434111 and test_loss for this epoch:  51.08008314768085 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8827361253744289\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:40,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.381128706038\n","Test Loss:  32.49326773127541\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:40,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  103.97577084228396\n","Test Loss:  22.221111429855227\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:39,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  71.46175695210695\n","Test Loss:  19.372552658431232\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:39,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.06138542341068\n","Test Loss:  18.112922752683517\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:38,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.11200263397768\n","Test Loss:  19.190265408717096\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:38,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  52.74345532222651\n","Test Loss:  21.329848782741465\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:37,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.83497113897465\n","Test Loss:  15.350898155884352\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:36,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.99351131496951\n","Test Loss:  17.404668489471078\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:35,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.49499352299608\n","Test Loss:  14.80580744263716\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:33,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.13868666626513\n","Test Loss:  16.099483970203437\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:09<00:32,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  47.72413088520989\n","Test Loss:  15.80960229667835\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:10<00:32,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.68422642443329\n","Test Loss:  14.407690140302293\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:11<00:31,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.618007466429844\n","Test Loss:  15.951078749378212\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:11<00:30,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  45.41262902820017\n","Test Loss:  14.708384939352982\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:29,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.05359246046282\n","Test Loss:  13.221850061032455\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:13<00:28,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.61966826405842\n","Test Loss:  13.68858955334872\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:14<00:27,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.56439620029414\n","Test Loss:  13.779401377076283\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:15<00:26,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  41.698114261147566\n","Test Loss:  13.325840442441404\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:16<00:25,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  41.09499664849136\n","Test Loss:  14.543164043687284\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:16<00:27,  1.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  42.39158196654171\n","Test Loss:  14.590453962795436\n","Early stopping with best_loss:  13.221850061032455 and test_loss for this epoch:  14.590453962795436 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0170887979245473\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:42,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  124.0877326587215\n","Test Loss:  34.92059633042663\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:41,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.93802466057241\n","Test Loss:  21.13726315042004\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:40,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.78890993213281\n","Test Loss:  20.573064895463176\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:39,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.42260723630898\n","Test Loss:  19.599698795937\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:38,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.304016400594264\n","Test Loss:  17.955741517827846\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:37,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.949684630613774\n","Test Loss:  18.108101802063175\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:37,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.00863226177171\n","Test Loss:  17.008275862317532\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:36,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.48017755791079\n","Test Loss:  16.08287027478218\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:34,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.78535648621619\n","Test Loss:  16.488758788327686\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:34,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.04289620509371\n","Test Loss:  14.138669562526047\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:09<00:33,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.24600430333521\n","Test Loss:  16.371781813330017\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:10<00:32,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.860897455364466\n","Test Loss:  14.969304321799427\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:11<00:31,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  42.26322344306391\n","Test Loss:  14.381853061844595\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:12<00:30,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.618679115665145\n","Test Loss:  13.767474109889008\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:29,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.38822639686987\n","Test Loss:  14.056355274398811\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:13<00:29,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.38510297809262\n","Test Loss:  13.48242904478684\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:14<00:28,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.15323198912665\n","Test Loss:  12.98213957855478\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:15<00:27,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.07673045707634\n","Test Loss:  13.134811186231673\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:16<00:26,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.8165588977281\n","Test Loss:  12.961240549222566\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:17<00:25,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.578549589030445\n","Test Loss:  12.22802766202949\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:17<00:24,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.42851632623933\n","Test Loss:  13.169452974223532\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:18<00:23,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.69696418510284\n","Test Loss:  12.505719149950892\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:19<00:22,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.04684430907946\n","Test Loss:  12.736586213577539\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:20<00:21,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.13340572826564\n","Test Loss:  12.417251167120412\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:21<00:21,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.9554199797567\n","Test Loss:  11.977704569580965\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:22<00:20,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.42674702149816\n","Test Loss:  11.53534066886641\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:23<00:19,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.6250366413733\n","Test Loss:  12.250416515162215\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:23<00:18,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.0229017988313\n","Test Loss:  12.023496745096054\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:24<00:17,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  32.78427095594816\n","Test Loss:  13.291927533922717\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:25<00:17,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.98862719198223\n","Test Loss:  11.496041030972265\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:26<00:16,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.731959854019806\n","Test Loss:  12.412030372652225\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:27<00:15,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  31.663855545572005\n","Test Loss:  10.946014015295077\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:28<00:14,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.44794436672237\n","Test Loss:  10.65046391580836\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:28<00:13,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  31.02152604528237\n","Test Loss:  11.479999758535996\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:29<00:12,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  32.57453161821468\n","Test Loss:  11.552959942026064\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:30<00:11,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.99959467886947\n","Test Loss:  11.468963341903873\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:31<00:11,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  33.07785545149818\n","Test Loss:  10.94551603787113\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:32<00:11,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  33.67647830990609\n","Test Loss:  10.78580681909807\n","Early stopping with best_loss:  10.65046391580836 and test_loss for this epoch:  10.78580681909807 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7562361118456772\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:46,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  111.83231677301228\n","Test Loss:  23.357955551124178\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:46,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.36435309331864\n","Test Loss:  21.017506210366264\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:45,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.33297571190633\n","Test Loss:  18.137057457410265\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:44,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.50055445777252\n","Test Loss:  19.814886574284174\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:44,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.587028675712645\n","Test Loss:  17.018932568840683\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:42,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.60971078486182\n","Test Loss:  15.31373250624165\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:41,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.3593967607012\n","Test Loss:  16.22534302715212\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:07<00:40,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.98871646262705\n","Test Loss:  14.461094310274348\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:08<00:38,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.215618810849264\n","Test Loss:  13.646292889490724\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:09<00:37,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.95680961140897\n","Test Loss:  13.947057851706631\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:10<00:37,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.68501784070395\n","Test Loss:  13.349529931816505\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:11<00:36,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.686471397290006\n","Test Loss:  15.607790178619325\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:12<00:35,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.326673000934534\n","Test Loss:  12.096701752976514\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:13<00:34,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.963519744807854\n","Test Loss:  12.115419424895663\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:14<00:33,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.94269570312463\n","Test Loss:  13.763393791625276\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:15<00:32,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.28009256126825\n","Test Loss:  12.155514364712872\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:16<00:31,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.960305008105934\n","Test Loss:  12.227237569284625\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:17<00:30,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.46325809881091\n","Test Loss:  11.577194165321998\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:18<00:29,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.94745256716851\n","Test Loss:  12.967687564669177\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:19<00:28,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.32613398425747\n","Test Loss:  12.449219330213964\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:20<00:27,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.55311385693494\n","Test Loss:  11.33455270587001\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:21<00:26,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.69209792360198\n","Test Loss:  11.515011434210464\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:21<00:25,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.29610968608176\n","Test Loss:  11.186766825034283\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:22<00:24,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.40357240685262\n","Test Loss:  10.207744070095941\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:23<00:23,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.91624708066229\n","Test Loss:  9.872651249286719\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:24<00:23,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  31.288120628683828\n","Test Loss:  10.099128642352298\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:25<00:22,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  31.019561939465348\n","Test Loss:  10.277207479346544\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:26<00:21,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  32.14018687896896\n","Test Loss:  11.498808639473282\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:27<00:20,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  30.363979332265444\n","Test Loss:  10.651840310543776\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:28<00:20,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  29.10810787801165\n","Test Loss:  10.017961882171221\n","Early stopping with best_loss:  9.872651249286719 and test_loss for this epoch:  10.017961882171221 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6685184687414777\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:55,  2.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  202.16016618488356\n","Test Loss:  43.18422323692357\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:54,  2.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  98.66035760461818\n","Test Loss:  26.403587497625267\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:54,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.80318963498576\n","Test Loss:  19.128462807799224\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:52,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.07322185987141\n","Test Loss:  17.51946200671955\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:49,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.25260970086674\n","Test Loss:  15.961399849824375\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:47,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.75199481798336\n","Test Loss:  16.314928625768516\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:44,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.68267350154929\n","Test Loss:  15.662270450382493\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:19<01:42,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.78381175536197\n","Test Loss:  15.53446072715451\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:21<01:39,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.47982334482367\n","Test Loss:  15.21291847381508\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:24<01:36,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.48355231320602\n","Test Loss:  15.441623431048356\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:26<01:33,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.026760983717395\n","Test Loss:  13.796285264921607\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:28<01:30,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.2948869051761\n","Test Loss:  14.371947766077938\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:31<01:28,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  49.75597128504887\n","Test Loss:  14.092176842459594\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:33<01:26,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.587597725272644\n","Test Loss:  13.785281474993099\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:36<01:24,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.657143842225196\n","Test Loss:  13.940135843513417\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:38<01:22,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.09122535807546\n","Test Loss:  15.364066557667684\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:41<01:19,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  45.29956188608776\n","Test Loss:  14.922816301579587\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:43<01:17,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  48.90646069415379\n","Test Loss:  15.268863800534746\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:45<01:21,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  46.80998916424869\n","Test Loss:  13.967980661116599\n","Early stopping with best_loss:  13.785281474993099 and test_loss for this epoch:  13.967980661116599 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.34001114914414665\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:58,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  145.09094557113713\n","Test Loss:  43.0573211790761\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:56,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.25549754820531\n","Test Loss:  26.931802871607943\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:55,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.400178991956636\n","Test Loss:  25.574720761011122\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:53,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.243580271082465\n","Test Loss:  22.059226506651612\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:50,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.96627664155676\n","Test Loss:  24.730825671489583\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:47,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.13027498195879\n","Test Loss:  20.773338487750152\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:44,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  49.263115243869834\n","Test Loss:  22.687876738695195\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:19<01:41,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.71018159066443\n","Test Loss:  19.880159342617844\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:22<01:40,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.70349493130925\n","Test Loss:  17.77733278553933\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:24<01:37,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.176635308598634\n","Test Loss:  18.056251396861626\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:26<01:35,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  47.862924631044734\n","Test Loss:  19.55384897434851\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:29<01:32,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.82809859563713\n","Test Loss:  17.24686208119965\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:31<01:30,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.426867228001356\n","Test Loss:  16.981633123359643\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:34<01:27,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.426740523194894\n","Test Loss:  17.48260435211705\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:36<01:25,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.41526873310795\n","Test Loss:  17.884396388748428\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:39<01:22,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  43.94576507915917\n","Test Loss:  19.664563725775224\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:41<01:19,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  42.341931765549816\n","Test Loss:  18.33244597411249\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:43<01:17,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.253706258983584\n","Test Loss:  16.03406393522164\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:46<01:15,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.573553922266\n","Test Loss:  15.512223863916006\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:48<01:12,  2.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.51599806122249\n","Test Loss:  16.527966462395852\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:51<01:10,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.7178110502864\n","Test Loss:  14.460411645792192\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:53<01:08,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.097563639094005\n","Test Loss:  18.084789439628366\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:56<01:06,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.43373812348\n","Test Loss:  15.04055449887528\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:58<01:03,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.2918513858458\n","Test Loss:  17.618053540354595\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:00<01:00,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.009473979705945\n","Test Loss:  14.320870603754884\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.65819459842169\n","Test Loss:  17.557541600923287\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:05<00:56,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.6953892048914\n","Test Loss:  15.34593331060023\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:08<00:53,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.57131108334579\n","Test Loss:  16.964584827190265\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:10<00:51,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.943230757839046\n","Test Loss:  16.169367386377417\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:13<00:52,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  37.41660973196849\n","Test Loss:  17.776473288453417\n","Early stopping with best_loss:  14.320870603754884 and test_loss for this epoch:  17.776473288453417 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.3221210387546912\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:11,  2.68s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  127.85697660478763\n","Test Loss:  27.890674567839596\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:10,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.54644952528179\n","Test Loss:  22.831346978025977\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:08,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.6690410534502\n","Test Loss:  20.205596267260262\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:06,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  54.781876717694104\n","Test Loss:  20.339711495587835\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:03,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.51134848824586\n","Test Loss:  19.022011420398485\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<02:01,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.40559955849312\n","Test Loss:  19.19463602383621\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<01:58,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.34378066471254\n","Test Loss:  15.780869235139107\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:55,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.64750587637536\n","Test Loss:  16.27722248446662\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:52,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.0809650682495\n","Test Loss:  15.765576862788294\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:49,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.79686579099507\n","Test Loss:  16.67687227767601\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:30<01:45,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.050875005632406\n","Test Loss:  15.960195593623212\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:42,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.76035332606989\n","Test Loss:  15.640034318174003\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:35<01:40,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.3814859015547\n","Test Loss:  14.897260620869929\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:37,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.20008934929501\n","Test Loss:  14.162427953328006\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:40<01:35,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.1425296721136\n","Test Loss:  14.360469487743103\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:43<01:32,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.33408503366081\n","Test Loss:  13.197078879071341\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:46<01:29,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.41869951642002\n","Test Loss:  14.580667357018683\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:49<01:27,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.6145177683793\n","Test Loss:  17.045377664035186\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:51<01:24,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  42.53922972930013\n","Test Loss:  16.296211723121814\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:54<01:21,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  42.63819931659964\n","Test Loss:  14.941671273030806\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:57<01:25,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  39.5094388355792\n","Test Loss:  13.428179369249847\n","Early stopping with best_loss:  13.197078879071341 and test_loss for this epoch:  13.428179369249847 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.315675332415877\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:24,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  401.2174826571718\n","Test Loss:  110.65842171758413\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:23,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  248.77533199987374\n","Test Loss:  74.5880712242215\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:20,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  204.2873461948475\n","Test Loss:  67.59485378907993\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:17,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  188.9190269196406\n","Test Loss:  61.77623340606806\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:16,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  171.88571570406202\n","Test Loss:  64.08282943710219\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:12,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  167.38140138972085\n","Test Loss:  56.383755260903854\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:09,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  158.94885546597652\n","Test Loss:  75.0326646992471\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:24<02:06,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.5097185280174\n","Test Loss:  52.71413534961175\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:27<02:02,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.92584133625496\n","Test Loss:  51.89527645750786\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:30<01:59,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  153.1758295559266\n","Test Loss:  51.681554473761935\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:33<01:56,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.8015972895082\n","Test Loss:  48.51573577336967\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:36<01:53,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  143.15238433063496\n","Test Loss:  56.40079364593839\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:39<01:50,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  141.14488809826435\n","Test Loss:  53.11452553162235\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:42<01:48,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  136.7847076645703\n","Test Loss:  52.642171474246425\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:45<01:45,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  137.08275228826096\n","Test Loss:  49.40082084998721\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:48<01:52,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  130.4189517851919\n","Test Loss:  49.136159030138515\n","Early stopping with best_loss:  48.51573577336967 and test_loss for this epoch:  49.136159030138515 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.2737933179208603\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:25,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  333.6687053460628\n","Test Loss:  96.9675219320925\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:23,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  216.94499787478708\n","Test Loss:  82.51978604646865\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:20,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  187.7079343055375\n","Test Loss:  64.27681626664707\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:18,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.24394662631676\n","Test Loss:  61.226468680542894\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:15,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.19868035410764\n","Test Loss:  56.9522795167868\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:11,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  153.6843898751249\n","Test Loss:  57.04759614937939\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:08,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.99479305674322\n","Test Loss:  52.391463936306536\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:23<02:05,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  141.8836575144087\n","Test Loss:  61.993203020247165\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:27<02:04,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.16050703037763\n","Test Loss:  50.84568881429732\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:30<02:01,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  133.8545825369656\n","Test Loss:  53.58814550016541\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:33<01:58,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.14217797489255\n","Test Loss:  50.198112904443406\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:36<01:55,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  131.02836719626794\n","Test Loss:  50.4855075913365\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:39<01:51,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.84094534488395\n","Test Loss:  48.685637199290795\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:42<01:48,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  131.06319328729296\n","Test Loss:  48.473880809615366\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:45<01:45,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  123.5602981960983\n","Test Loss:  48.83304890332511\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:48<01:42,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.4421862665913\n","Test Loss:  47.97060677308764\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:51<01:39,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  121.5734676393622\n","Test Loss:  54.35400145492167\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:54<01:35,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  120.22914820697042\n","Test Loss:  47.97734926349949\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:57<01:32,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  115.9420233744022\n","Test Loss:  46.606192687977455\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:00<01:31,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  114.65190207443084\n","Test Loss:  46.414866271894425\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:03<01:27,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  118.27289090910926\n","Test Loss:  50.233495204141946\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:06<01:24,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  115.99539397578337\n","Test Loss:  50.138825351168634\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:09<01:21,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  121.76440439993166\n","Test Loss:  49.09866989776492\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:12<01:18,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  114.37455304438481\n","Test Loss:  47.127815828542225\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:15<01:15,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  108.58739836656605\n","Test Loss:  45.96164834022056\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:18<01:12,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  115.44916615181137\n","Test Loss:  45.44620098103769\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:21<01:09,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  112.1503132568323\n","Test Loss:  48.096650823543314\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:24<01:06,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  112.41117543156724\n","Test Loss:  47.38632649963256\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:27<01:03,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  110.00168531725649\n","Test Loss:  45.69658589491155\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:30<01:01,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  108.76640801510075\n","Test Loss:  46.06402199473814\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:33<01:02,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  115.46856795033091\n","Test Loss:  47.003319962881505\n","Early stopping with best_loss:  45.44620098103769 and test_loss for this epoch:  47.003319962881505 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.2485679838662764\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:48,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  310.1782986805774\n","Test Loss:  89.92792916786857\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:44,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  204.16677221650025\n","Test Loss:  63.010167579341214\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:41,  3.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  180.91775458253687\n","Test Loss:  60.041144306305796\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:37,  3.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.10032484249678\n","Test Loss:  57.43033885920886\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:17<02:33,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.83531412272714\n","Test Loss:  51.60968448210042\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:20<02:28,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  149.82433606410632\n","Test Loss:  56.01161351718474\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:25,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.7453291695565\n","Test Loss:  48.442535017675254\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:27<02:23,  3.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  142.66639786888845\n","Test Loss:  49.84006814708118\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:30<02:19,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  142.8068888313137\n","Test Loss:  49.27190004888689\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:34<02:15,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.14801339848782\n","Test Loss:  51.112096358439885\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:37<02:12,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  138.97997134330217\n","Test Loss:  46.198409548567724\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:40<02:08,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.4802145405556\n","Test Loss:  46.19537825521547\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:44<02:05,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.89173462848703\n","Test Loss:  45.162728646653704\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:47<02:01,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.0568500882946\n","Test Loss:  40.051624792598886\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:50<01:58,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  131.1347802565142\n","Test Loss:  47.51347868290031\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:54<01:54,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  127.95693039358594\n","Test Loss:  45.03835161891766\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:57<01:51,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  128.40911499341018\n","Test Loss:  41.31212406689883\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:01<01:48,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  123.33088021795265\n","Test Loss:  45.79262294335058\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:04<01:54,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  127.9452423696639\n","Test Loss:  40.75564348141779\n","Early stopping with best_loss:  40.051624792598886 and test_loss for this epoch:  40.75564348141779 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9096556672484392\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.preprocessing import MinMaxScaler\n","from torch import nn\n","from tqdm import trange\n","from datetime import date, timedelta\n","\n","from collections import OrderedDict\n","from collections import namedtuple\n","from itertools import product\n","\n","import torch.nn.functional as F\n","\n","\n","data_file = '/content/drive/MyDrive/Flu Forecasting/code/trainingdata_rate0131.csv'\n","model_file = '/content/drive/MyDrive/Flu Forecasting/LSTM/weightselection/'\n","prediction_file = '/content/drive/MyDrive/Flu Forecasting/LSTM/weightselection/'\n","summary_file ='/content/drive/MyDrive/Flu Forecasting/LSTM/weightselection/'\n","def perdelta(start, end, delta):\n","    curr = start\n","    while curr < end:\n","        yield curr\n","        curr += delta\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","\n","params = OrderedDict(\n","    target = ['rate'], ### Our target variable\n","    lr = [0.0001,0.00025],\n","    batch_size = [2],\n","    seq_length = [6,8,12], # length of input sequence to predict values\n","    output_size = [4], # we are predicting next four weeks admissions\n","    num_pred_features = [1],\n","    week_range = [32,64,128], # number of historical data (per state) used to train the model\n","    input_size = [15], # total number of input features\n","    hidden_layer_size = [64,128,256], #test\n","    num_layers = [1], #test\n","    ratio = [0.7],  # ratio of training set and validation set\n","    num_epochs = [50],\n","    dropout_rate = [0.8],\n","    lossfunc = [nn.SmoothL1Loss(beta=0.05, reduction = 'sum'),\n","\n","                ]\n",")\n","\n","\n","class RunBuilder():\n","    @staticmethod\n","    def get_runs(params):\n","\n","        Run = namedtuple('Run', params.keys())\n","\n","        runs = []\n","        for v in product(*params.values()):\n","            runs.append(Run(*v))\n","\n","        return runs\n","\n","pd.options.mode.chained_assignment = None\n","\n","runs = RunBuilder.get_runs(params)\n","\n","# output dict\n","columns = [\n","    'Model',\n","    'lr',\n","    'batch_size',\n","    'seq_length',\n","    'week_range',\n","    'hidden_layer_size',\n","    'num_layers',\n","    'lossfunc',\n","    'mse_validation',\n","    'mse_validation_1w',\n","    'mse_validation_2w',\n","    'mse_validation_3w',\n","    'mse_validation_4w',\n","    'Target'\n","]\n","# output dataframe\n","df_summary = pd.DataFrame(columns=columns)\n","for run in RunBuilder.get_runs(params):\n","    if run.target == 'rate':\n","        results_file = 'rate'\n","\n","    validation_predictions = []\n","    validation_labels = []\n","    # read data\n","    df = pd.read_csv(data_file)\n","    #df = df.rename(columns={'End Date': 'Week_end', 'State': 'fips'})\n","    df['Week_end'] = pd.to_datetime(df['Week_end'])\n","    # too many missing values in State'11'\n","    df =  df[df['fips'] != 11]\n","    #df =  df[df['fips'] == 1]\n","    #df = df[['fips', 'Week_end', 'total_admissions']]\n","\n","    # drop weather data\n","    #df = df.drop(['PRCP_mean', 'SNOW_mean', 'TMAXDELTA', 'TMINDELTA'], axis=1)\n","    '''\n","    # choose data in 2023-11 as test data  test 10-01\n","    #start_date1 = pd.to_datetime('2023-11-01') - timedelta(weeks=run.seq_length * 7)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] < pd.to_datetime('2023-11-26'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2023-11 as training data and validation data\n","    df_train = df[(df['Week_end'] <= pd.to_datetime('2023-11-01'))& (df['Week_end'] >pd.to_datetime('2022-08-01')) ] # Use data before 11/1 as training set\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","    '''\n","    # test set is the week from 2024-01-13\n","    start_date1 = pd.to_datetime('2024-01-20') - timedelta(weeks=run.seq_length)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] <pd.to_datetime('2024-01-30'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2024-01-06 as training data and validation data and after 2022-08-01\n","    df_train = df[(df['Week_end'] <= pd.to_datetime('2024-01-20'))& (df['Week_end'] >pd.to_datetime('2022-08-01')) ] # Use data before 11/1 as training set\n","\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","\n","    #rescale the data from 0 to 1, normalization\n","    first_col = df_train.pop(run.target)\n","    df_train.insert(0, run.target, first_col)\n","    first_col_2 = df_test.pop(run.target)\n","    df_test.insert(0, run.target, first_col_2)\n","\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","    scaler.fit(df_train.iloc[:, 1:])\n","    train_features_normalized = scaler.transform(df_train.iloc[:, 1:])\n","    test_feature_normalized = scaler.transform(df_test.iloc[:, 1:])\n","\n","    scaler_target = MinMaxScaler(feature_range=(0, 1))\n","    scaler_target.fit(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    train_target_normalized = scaler_target.transform(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    test_target_normalized = scaler_target.transform(np.asarray(df_test.iloc[:, 0]).reshape(-1, 1))\n","\n","    df_train.iloc[:, 1:] = train_features_normalized\n","    df_train.iloc[:, 0] = train_target_normalized\n","    df_test.iloc[:, 1:] = test_feature_normalized\n","    df_test.iloc[:, 0] = test_target_normalized\n","\n","    '''\n","    Training\n","    '''\n","    # prepare the training and validation data (sequance format)\n","    full_data_main, state_ordered = prepare_data_main_model(df_train, run.seq_length,\n","                                                            run.output_size, run.week_range)\n","\n","    model_main = LSTM(run.input_size, run.hidden_layer_size, run.num_layers, run.output_size ,\n","                      run.dropout_rate).to(device)\n","    # split the training data into training set and validation set\n","    train_loader_main, test_loader_main = splitdata(full_data_main, run.ratio, run.batch_size)\n","\n","    loss_function = run.lossfunc\n","  # add l2 regularization\n","    optimizer_main = torch.optim.Adam(model_main.parameters(), lr=run.lr,weight_decay=1e-5)\n","\n","    track_loss_train = []\n","    track_loss_test = []\n","    best_loss = 100000\n","    ###\n","\n","    best_mse_numerical = None\n","    mse_numerical_weekly = [None] * 4\n","\n","    best_mse_numerical_weekly = [None] * 4\n","    for i in trange(run.num_epochs):\n","# Set the model in training mode\n","        model_main.train()\n","        epoch_loss_train = 0\n","# Iterate over the training data\n","        for i, (seq, labels) in enumerate(train_loader_main):\n","            seq, labels = seq.to(device), labels.to(device)\n","            optimizer_main.zero_grad()\n","            seq = torch.as_tensor(seq).reshape(-1, run.seq_length, run.input_size)\n","             # Initialize the hidden state of the LSTM\n","            model_main.hidden_cell = (torch.zeros(run.num_layers, seq.size()[0], run.hidden_layer_size).to(device),\n","                          torch.zeros(run.num_layers, seq.size()[0], run.hidden_layer_size).to(device))\n","\n","            # Forward pass to get predictions\n","            y_pred = model_main(seq.float())\n","\n","            # Calculate the loss and perform backpropagation\n","            single_loss = loss_function(y_pred, torch.as_tensor(labels).float())\n","            single_loss.backward()\n","            optimizer_main.step()\n","\n","            epoch_loss_train += single_loss.item()\n","        # Track the training loss for this epoch\n","        track_loss_train.append(epoch_loss_train)\n","\n","        with torch.no_grad():\n","          # Set the model in evaluation mode\n","            model_main.eval()\n","            epoch_loss_test = 0\n","            ########\n","            # Initialize lists to store validation predictions and labels\n","            validation_predictions = []\n","            validation_labels = []\n","            for i, (seq, labels) in enumerate(test_loader_main):\n","                seq, labels = seq.to(device), labels.to(device)\n","                seq = torch.as_tensor(seq).reshape(-1, run.seq_length, run.input_size)\n","                model_main.hidden_cell = (torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device),\n","                                 torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device))\n","                y_pred = model_main(seq.float())\n","\n","                single_loss = loss_function(y_pred, torch.as_tensor(labels).float())\n","                epoch_loss_test += single_loss.item()\n","                ######\n","                # Store predictions and labels for later evaluation\n","                validation_predictions.extend(y_pred.cpu().numpy())\n","                validation_labels.extend(labels.cpu().numpy())\n","            track_loss_test.append(epoch_loss_test)\n","        # Combine validation predictions and labels, and perform inverse scaling to get true value\n","        validation_predictions = np.concatenate(validation_predictions, axis=0)\n","        validation_labels = np.concatenate(validation_labels, axis=0)\n","        validation_predictions = scaler_target.inverse_transform(validation_predictions.reshape(-1, 1)).reshape(-1, 4)\n","        validation_labels = scaler_target.inverse_transform(validation_labels.reshape(-1, 1)).reshape(-1, 4)\n","\n","        # Calculate total and weekly MSE and accuracy for validation set\n","        mse_numerical = np.mean((validation_predictions - validation_labels)**2)\n","\n","        for week in range(4):\n","            # Calculate weekly MSE\n","            mse_numerical_week = np.mean((validation_predictions[:, week] - validation_labels[:, week])**2)\n","            mse_numerical_weekly[week] = mse_numerical_week\n","\n","\n","        if epoch_loss_test  < best_loss:\n","          # Update the best loss and save the model; perform early stopping\n","            best_mse_numerical = mse_numerical\n","            best_mse_numerical_weekly = mse_numerical_weekly\n","\n","            best_loss = epoch_loss_test\n","            print('Train Loss: ', epoch_loss_train)\n","            print('Test Loss: ', epoch_loss_test)\n","            es = 0\n","            torch.save(model_main.state_dict(),\n","                           model_file + run.target +'_' +str(run.lr) + '_' +\n","                           str(run.week_range) + '_' + str(run.hidden_layer_size)\\\n","                           + '_' + str(run.seq_length) + '_' + str(run.num_layers)\\\n","                           + '_LSTM_weights.pt')\n","        else:\n","            es += 1\n","            print(\"Counter {} of 5\".format(es))\n","            print('Train Loss: ', epoch_loss_train)\n","            print('Test Loss: ', epoch_loss_test)\n","\n","\n","        if es > 4:\n","            print(\"Early stopping with best_loss: \", best_loss, \"and test_loss for this epoch: \",\n","                      epoch_loss_test,\n","                      \"...\")\n","\n","            break\n","\n","    '''\n","    Prediction\n","    '''\n","    df_output = pd.DataFrame(columns=['fips', 'Week_end', 'Prediction_1w',\n","                                      'Prediction_2w', 'Prediction_3w',\n","                                      'Prediction_4w'])\n","  #test set starts with 2023-11-01\n","    test_weeks = df_test[df_test.index.get_level_values('Week_end') \\\n","                       >= pd.to_datetime('2024-01-20')].index.get_level_values('Week_end').unique()\n","    test_states = df_test.index.get_level_values('fips').unique()\n","\n","    m_state_dict_main = torch.load(model_file + run.target+ '_' +str(run.lr) + '_' +\n","                                   str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                                   + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                                   + '_LSTM_weights.pt')\n","\n","    model_main = LSTM(run.input_size, run.hidden_layer_size, run.num_layers,\n","                      run.output_size, run.dropout_rate).to(device)\n","    model_main.load_state_dict(m_state_dict_main)\n","\n","    with torch.no_grad():\n","        #model_main.eval()\n","        for fips in test_states:\n","            for week in test_weeks:\n","                seq = df_test[(df_test.index.get_level_values('fips') == fips)\\\n","                 & (df_test.index.get_level_values('Week_end') <= week)][-run.seq_length:].to_numpy()\n","\n","                seq = torch.tensor(seq).reshape(-1, run.seq_length, run.input_size).to(device)\n","\n","\n","                model_main.hidden_cell = (torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device),\n","                                 torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device))\n","                prediction = model_main(seq.float())\n","\n","                prediction = scaler_target.inverse_transform(prediction.cpu().detach().numpy().reshape(-1, 1))\n","                # save prediction results\n","                dic = {\n","                    'fips' : fips,\n","                    'Week_end' : week,\n","                    'Prediction_1w' : prediction[0].item(),\n","                    'Prediction_2w' : prediction[1].item(),\n","                    'Prediction_3w' : prediction[2].item(),\n","                    'Prediction_4w' : prediction[3].item()\n","\n","                }\n","\n","                df_output = pd.concat([df_output, pd.DataFrame([dic])], ignore_index=True)\n","\n","\n","        df_output.to_csv(prediction_file + run.target + '_' +str(run.lr) + '_' +\n","                            str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                            + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                            + '.csv')\n","\n","        '''\n","        Evaluation\n","        '''\n","\n","\n","\n","\n","\n","        dic_lstm = {\n","            'Model': 'LSTM',\n","            'lr': run.lr,\n","            'batch_size': run.batch_size,\n","            'seq_length': run.seq_length,\n","            'week_range': run.week_range,\n","            'hidden_layer_size': run.hidden_layer_size,\n","            'num_layers': run.num_layers,\n","            'lossfunc': run.lossfunc,\n","\n","            'mse_validation': best_mse_numerical,\n","\n","            'mse_validation_1w': best_mse_numerical_weekly[0],\n","            'mse_validation_2w': best_mse_numerical_weekly[1],\n","            'mse_validation_3w': best_mse_numerical_weekly[2],\n","            'mse_validation_4w': best_mse_numerical_weekly[3],\n","\n","            'Target': run.target\n","        }\n","\n","        print('mse_validation:')\n","        print(dic_lstm['mse_validation'])\n","\n","\n","        df_summary = pd.concat([df_summary, pd.DataFrame([dic_lstm])], ignore_index=True)\n","\n","        df_summary.to_csv(summary_file + 'summarytest.csv')\n","\n"]},{"cell_type":"code","source":["df_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"_GRaLaGH80z0","executionInfo":{"status":"ok","timestamp":1707319071423,"user_tz":300,"elapsed":168,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}},"outputId":"6fe24291-1f28-416c-c815-66c87ab06750"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   fips   Week_end  Prediction_1w  Prediction_2w  Prediction_3w  Prediction_4w\n","0     1 2024-01-20       1.553443       1.416178       1.360365       1.205082\n","1     1 2024-01-27       1.487583       1.222604       1.125432       1.034163\n","2     2 2024-01-20       0.780145       1.242551       1.931762       2.828534\n","3     2 2024-01-27       0.874534       1.304484       1.812373       1.968853\n","4     4 2024-01-20       4.193772       2.836079       2.034209       1.963451\n","..  ...        ...            ...            ...            ...            ...\n","95   54 2024-01-27       3.249407       3.569684       3.140540       2.866554\n","96   55 2024-01-20       2.217776       2.846013       3.614674       3.190379\n","97   55 2024-01-27       2.407753       2.235549       2.041720       1.472630\n","98   56 2024-01-20       4.787724       3.387617       3.147089       3.133203\n","99   56 2024-01-27       3.782526       3.483652       2.943386       2.468245\n","\n","[100 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-9ce3221c-faeb-4754-b2ec-9fdbc2286db0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fips</th>\n","      <th>Week_end</th>\n","      <th>Prediction_1w</th>\n","      <th>Prediction_2w</th>\n","      <th>Prediction_3w</th>\n","      <th>Prediction_4w</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2024-01-20</td>\n","      <td>1.553443</td>\n","      <td>1.416178</td>\n","      <td>1.360365</td>\n","      <td>1.205082</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2024-01-27</td>\n","      <td>1.487583</td>\n","      <td>1.222604</td>\n","      <td>1.125432</td>\n","      <td>1.034163</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2024-01-20</td>\n","      <td>0.780145</td>\n","      <td>1.242551</td>\n","      <td>1.931762</td>\n","      <td>2.828534</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>2024-01-27</td>\n","      <td>0.874534</td>\n","      <td>1.304484</td>\n","      <td>1.812373</td>\n","      <td>1.968853</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2024-01-20</td>\n","      <td>4.193772</td>\n","      <td>2.836079</td>\n","      <td>2.034209</td>\n","      <td>1.963451</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>54</td>\n","      <td>2024-01-27</td>\n","      <td>3.249407</td>\n","      <td>3.569684</td>\n","      <td>3.140540</td>\n","      <td>2.866554</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>55</td>\n","      <td>2024-01-20</td>\n","      <td>2.217776</td>\n","      <td>2.846013</td>\n","      <td>3.614674</td>\n","      <td>3.190379</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>55</td>\n","      <td>2024-01-27</td>\n","      <td>2.407753</td>\n","      <td>2.235549</td>\n","      <td>2.041720</td>\n","      <td>1.472630</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>56</td>\n","      <td>2024-01-20</td>\n","      <td>4.787724</td>\n","      <td>3.387617</td>\n","      <td>3.147089</td>\n","      <td>3.133203</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>56</td>\n","      <td>2024-01-27</td>\n","      <td>3.782526</td>\n","      <td>3.483652</td>\n","      <td>2.943386</td>\n","      <td>2.468245</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ce3221c-faeb-4754-b2ec-9fdbc2286db0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9ce3221c-faeb-4754-b2ec-9fdbc2286db0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9ce3221c-faeb-4754-b2ec-9fdbc2286db0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2f924933-5b79-4ca4-bb0f-3abfb590baab\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f924933-5b79-4ca4-bb0f-3abfb590baab')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2f924933-5b79-4ca4-bb0f-3abfb590baab button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f57ce315-c6e5-4357-b686-9755c3adb61e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_output')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f57ce315-c6e5-4357-b686-9755c3adb61e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_output');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["#### Run best model for 100 times"],"metadata":{"id":"mXYP3DSDrUQm"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.preprocessing import MinMaxScaler\n","from torch import nn\n","from tqdm import trange\n","from datetime import date, timedelta\n","\n","from collections import OrderedDict\n","from collections import namedtuple\n","from itertools import product\n","\n","import torch.nn.functional as F\n","\n","\n","n_result = pd.DataFrame()\n","data_file = '/content/drive/MyDrive/Flu Forecasting/code/trainingdata_rate0131.csv'\n","model_file = '/content/drive/MyDrive/Flu Forecasting/LSTM/weightselection/'\n","prediction_file = '/content/drive/MyDrive/Flu Forecasting/LSTM/weightselection/'\n","summary_file ='/content/drive/MyDrive/Flu Forecasting/LSTM/weightselection/'\n","# read data\n","def perdelta(start, end, delta):\n","    curr = start\n","    while curr < end:\n","        yield curr\n","        curr += delta\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","\n","params = OrderedDict(\n","    target = ['rate'], ### Our target variable\n","    lr = [0.0001],\n","    batch_size = [2],\n","    seq_length = [8], # length of input sequence to predict values\n","    output_size = [4], # we are predicting next four weeks admissions\n","    num_pred_features = [1],\n","    week_range = [64], # number of historical data (per state) used to train the model\n","    input_size = [15], # total number of input features\n","    hidden_layer_size = [64], #test\n","    num_layers = [1], #test\n","    ratio = [0.7],  # ratio of training set and validation set\n","    num_epochs = [50],\n","    dropout_rate = [0.8],\n","    lossfunc = [nn.SmoothL1Loss(beta=0.05, reduction = 'sum'),\n","\n","                ]\n",")\n","\n","\n","class RunBuilder():\n","    @staticmethod\n","    def get_runs(params):\n","\n","        Run = namedtuple('Run', params.keys())\n","\n","        runs = []\n","        for v in product(*params.values()):\n","            runs.append(Run(*v))\n","\n","        return runs\n","\n","pd.options.mode.chained_assignment = None\n","\n","runs = RunBuilder.get_runs(params)\n","\n","for run in RunBuilder.get_runs(params):\n","    if run.target == 'rate':\n","        results_file = 'rate'\n","\n","    validation_predictions = []\n","    validation_labels = []\n","    # read data\n","    df = pd.read_csv(data_file)\n","    #df = df.rename(columns={'End Date': 'Week_end', 'State': 'fips'})\n","    df['Week_end'] = pd.to_datetime(df['Week_end'])\n","    # too many missing values in State'11'\n","    df =  df[df['fips'] != 11]\n","    #df =  df[df['fips'] == 1]\n","    #df = df[['fips', 'Week_end', 'total_admissions']]\n","    #df = df.drop(['PRCP_mean', 'SNOW_mean', 'TMAXDELTA', 'TMINDELTA'], axis=1)\n","    # choose data in 2023-11 as test data  test 10-01\n","\n","    '''\n","    start_date1 = pd.to_datetime('2023-11-01') - timedelta(weeks=run.seq_length * 7)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] < pd.to_datetime('2023-11-26'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2023-11 as training data and validation data\n","    df_train = df[df['Week_end'] <= pd.to_datetime('2023-11-01')] # Use data before 11/1 as training set\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","\n","    #rescale the data from 0 to 1, normalization\n","    first_col = df_train.pop(run.target)\n","    df_train.insert(0, run.target, first_col)\n","    first_col_2 = df_test.pop(run.target)\n","    df_test.insert(0, run.target, first_col_2)\n","    '''\n","    start_date1 = pd.to_datetime('2024-01-20') - timedelta(weeks=run.seq_length)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] <pd.to_datetime('2024-01-26'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2024-01-13 as training data and validation data\n","    df_train = df[(df['Week_end'] <= pd.to_datetime('2024-01-20'))& (df['Week_end'] >pd.to_datetime('2022-08-01')) ] # Use data before 11/1 as training set\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","\n","    #rescale the data from 0 to 1, normalization\n","    first_col = df_train.pop(run.target)\n","    df_train.insert(0, run.target, first_col)\n","    first_col_2 = df_test.pop(run.target)\n","    df_test.insert(0, run.target, first_col_2)\n","\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","    scaler.fit(df_train.iloc[:, 1:])\n","    train_features_normalized = scaler.transform(df_train.iloc[:, 1:])\n","    test_feature_normalized = scaler.transform(df_test.iloc[:, 1:])\n","\n","    scaler_target = MinMaxScaler(feature_range=(0, 1))\n","    scaler_target.fit(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    train_target_normalized = scaler_target.transform(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    test_target_normalized = scaler_target.transform(np.asarray(df_test.iloc[:, 0]).reshape(-1, 1))\n","\n","    df_train.iloc[:, 1:] = train_features_normalized\n","    df_train.iloc[:, 0] = train_target_normalized\n","    df_test.iloc[:, 1:] = test_feature_normalized\n","    df_test.iloc[:, 0] = test_target_normalized\n","\n","\n","    for i in range(1000):\n","      df_output = pd.DataFrame(columns=['fips', 'Week_end', 'Prediction_1w',\n","                                        'Prediction_2w', 'Prediction_3w',\n","                                        'Prediction_4w'])\n","    #test set starts with 2024-01-13\n","      test_weeks = df_test[df_test.index.get_level_values('Week_end') \\\n","                          >= pd.to_datetime('2024-01-20')].index.get_level_values('Week_end').unique()\n","      test_states = df_test.index.get_level_values('fips').unique()\n","\n","      m_state_dict_main = torch.load(model_file + run.target + '_' +str(run.lr) + '_' +\n","                                      str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                                      + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                                      + '_LSTM_weights.pt')\n","\n","      model_main = LSTM(run.input_size, run.hidden_layer_size, run.num_layers,\n","                        run.output_size, run.dropout_rate).to(device)\n","      model_main.load_state_dict(m_state_dict_main)\n","\n","      with torch.no_grad():\n","          #model_main.eval()\n","          for fips in test_states:\n","              for week in test_weeks:\n","                  seq = df_test[(df_test.index.get_level_values('fips') == fips)\\\n","                    & (df_test.index.get_level_values('Week_end') <= week)][-run.seq_length:].to_numpy()\n","\n","                  seq = torch.tensor(seq).reshape(-1, run.seq_length, run.input_size).to(device)\n","\n","\n","                  model_main.hidden_cell = (torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device),\n","                                    torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device))\n","                  prediction = model_main(seq.float())\n","\n","                  prediction = scaler_target.inverse_transform(prediction.cpu().detach().numpy().reshape(-1, 1))\n","                  # save prediction results\n","                  dic = {\n","                      'fips' : fips,\n","                      'Week_end' : week,\n","                      'Prediction_1w' : prediction[0].item(),\n","                      'Prediction_2w' : prediction[1].item(),\n","                      'Prediction_3w' : prediction[2].item(),\n","                      'Prediction_4w' : prediction[3].item()\n","\n","                  }\n","\n","                  df_output = pd.concat([df_output, pd.DataFrame([dic])], ignore_index=True)\n","\n","\n","          df_output.to_csv(prediction_file + run.target + '_' +str(run.lr) + '_' +\n","                              str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                              + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                              + '.csv')\n","          n_result= pd.concat([n_result, df_output], ignore_index=True)\n","\n","\n","    n_result.to_pickle(summary_file + 'allresulttest4.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"618be84f-50ae-462d-985b-f13d08a802ba","id":"L_DAcEwWrUQm","executionInfo":{"status":"ok","timestamp":1707320358648,"user_tz":300,"elapsed":147679,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}]},{"cell_type":"code","source":["n_result"],"metadata":{"id":"tAkxT51PrUQn","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1706046147113,"user_tz":300,"elapsed":160,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}},"outputId":"8b01cfe7-91e0-426d-c9af-f0e8fc50affb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      fips   Week_end  Prediction_1w  Prediction_2w  Prediction_3w  \\\n","0        1 2023-12-16       2.030811       3.404916       4.509559   \n","1        2 2023-12-16       0.023632       0.239356       0.150441   \n","2        4 2023-12-16       5.346867       8.291306       8.709900   \n","3        5 2023-12-16       1.159860       2.735837       3.255077   \n","4        6 2023-12-16       1.004027       1.336492       1.735048   \n","...    ...        ...            ...            ...            ...   \n","49995   51 2023-12-16       2.396512       3.624523       3.849347   \n","49996   53 2023-12-16       0.184649       0.052782       0.142393   \n","49997   54 2023-12-16       0.541724       1.201434       1.669058   \n","49998   55 2023-12-16       1.475421       3.360832       4.460989   \n","49999   56 2023-12-16      10.403527      11.984213      11.871225   \n","\n","       Prediction_4w  \n","0           5.837484  \n","1           0.217191  \n","2           7.924041  \n","3           4.091725  \n","4           1.567238  \n","...              ...  \n","49995       3.313382  \n","49996       0.099187  \n","49997       2.020296  \n","49998       4.914268  \n","49999      12.024737  \n","\n","[50000 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-3eed56b0-0b67-4490-9097-75061db39b7d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fips</th>\n","      <th>Week_end</th>\n","      <th>Prediction_1w</th>\n","      <th>Prediction_2w</th>\n","      <th>Prediction_3w</th>\n","      <th>Prediction_4w</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2023-12-16</td>\n","      <td>2.030811</td>\n","      <td>3.404916</td>\n","      <td>4.509559</td>\n","      <td>5.837484</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2023-12-16</td>\n","      <td>0.023632</td>\n","      <td>0.239356</td>\n","      <td>0.150441</td>\n","      <td>0.217191</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>2023-12-16</td>\n","      <td>5.346867</td>\n","      <td>8.291306</td>\n","      <td>8.709900</td>\n","      <td>7.924041</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>2023-12-16</td>\n","      <td>1.159860</td>\n","      <td>2.735837</td>\n","      <td>3.255077</td>\n","      <td>4.091725</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>2023-12-16</td>\n","      <td>1.004027</td>\n","      <td>1.336492</td>\n","      <td>1.735048</td>\n","      <td>1.567238</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>51</td>\n","      <td>2023-12-16</td>\n","      <td>2.396512</td>\n","      <td>3.624523</td>\n","      <td>3.849347</td>\n","      <td>3.313382</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>53</td>\n","      <td>2023-12-16</td>\n","      <td>0.184649</td>\n","      <td>0.052782</td>\n","      <td>0.142393</td>\n","      <td>0.099187</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>54</td>\n","      <td>2023-12-16</td>\n","      <td>0.541724</td>\n","      <td>1.201434</td>\n","      <td>1.669058</td>\n","      <td>2.020296</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>55</td>\n","      <td>2023-12-16</td>\n","      <td>1.475421</td>\n","      <td>3.360832</td>\n","      <td>4.460989</td>\n","      <td>4.914268</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>56</td>\n","      <td>2023-12-16</td>\n","      <td>10.403527</td>\n","      <td>11.984213</td>\n","      <td>11.871225</td>\n","      <td>12.024737</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eed56b0-0b67-4490-9097-75061db39b7d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3eed56b0-0b67-4490-9097-75061db39b7d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3eed56b0-0b67-4490-9097-75061db39b7d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e300a76e-97fb-492e-b8ed-6c740d5a159d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e300a76e-97fb-492e-b8ed-6c740d5a159d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e300a76e-97fb-492e-b8ed-6c740d5a159d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_b65165d5-e3a7-45b6-aa61-e4aa4fbb3b8a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('n_result')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b65165d5-e3a7-45b6-aa61-e4aa4fbb3b8a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('n_result');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"ZpX-q0BerUQo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cpU7_PDot7O7"},"source":["## GRU"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"46CLOIsRyvnU","executionInfo":{"status":"ok","timestamp":1707321484943,"user_tz":300,"elapsed":224,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}}},"outputs":[],"source":["class GRU(nn.Module):\n","\n","    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout_rate):\n","        super().__init__()\n","\n","        self.input_size = input_size\n","        self.hidden_layer_size = hidden_layer_size\n","        self.num_layers = num_layers\n","        self.output_size = output_size\n","\n","\n","        self.gru = nn.GRU(self.input_size, hidden_layer_size, num_layers, batch_first=True, dropout=dropout_rate)\n","\n","        self.linear = nn.Linear(hidden_layer_size, 1000)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.linear2 = nn.Linear(1000, output_size)\n","\n","    def forward(self, input_seq):\n","        h = torch.zeros(self.num_layers, input_seq.size(0), self.hidden_layer_size).to(device)\n","\n","\n","        gru_out, self.hidden = self.gru(input_seq, h)\n","\n","\n","        gru_out = gru_out[:, -1, :]\n","        predictions = self.linear(gru_out)\n","        predictions = F.relu(predictions)\n","        predictions = self.dropout(predictions)\n","        predictions = self.linear2(predictions)\n","\n","        return predictions\n"]},{"cell_type":"markdown","metadata":{"id":"TxdyHkh-0FES"},"source":["### Main"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3591068,"status":"ok","timestamp":1707325078596,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"},"user_tz":300},"id":"1Z-Ef1xbzCXb","outputId":"8b27e3c9-6189-49f4-951e-6edaf1e772e3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","  0%|          | 0/50 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  197.20484140515327\n","Test Loss:  48.55406130850315\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 2/50 [00:03<01:22,  1.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.7801804728806\n","Test Loss:  39.00799242267385\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:04<01:07,  1.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  103.95858845859766\n","Test Loss:  32.53219617565628\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:05<01:01,  1.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  85.38225383870304\n","Test Loss:  28.93642709951382\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:07<00:56,  1.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.25116559676826\n","Test Loss:  26.26571881957352\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:08<00:52,  1.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.87105096480809\n","Test Loss:  22.795365295154625\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:09<00:50,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.57890404504724\n","Test Loss:  21.463057496992406\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:10<00:48,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.549877296201885\n","Test Loss:  20.81253395380918\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:11<00:46,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.39584673324134\n","Test Loss:  20.52899333019741\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:12<00:45,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.95913705509156\n","Test Loss:  20.56029986619251\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:13<00:43,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.52389839326497\n","Test Loss:  19.938806272577494\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:14<00:42,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.90426723158453\n","Test Loss:  19.13167368370341\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:15<00:41,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.84776562359184\n","Test Loss:  19.23875184491044\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:17<00:40,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.46097666292917\n","Test Loss:  18.564623149461113\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:18<00:39,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.93422910477966\n","Test Loss:  19.24721847579349\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:19<00:37,  1.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.925087533076294\n","Test Loss:  17.634861852158792\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:20<00:36,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.428557454259135\n","Test Loss:  18.40653853758704\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:21<00:35,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.20172479480971\n","Test Loss:  17.329076684545726\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:22<00:34,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.30715461424552\n","Test Loss:  20.545963425945956\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:23<00:33,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.08185843646061\n","Test Loss:  16.82033630576916\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:24<00:32,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.76116355624981\n","Test Loss:  17.611962186871096\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:25<00:31,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.53128168074181\n","Test Loss:  16.48581833022763\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:27<00:29,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.21455655171303\n","Test Loss:  17.109493000549264\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:28<00:28,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.24752987222746\n","Test Loss:  16.23539897799492\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:29<00:27,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.99521531711798\n","Test Loss:  16.244230420998065\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:30<00:26,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.95763061946491\n","Test Loss:  16.876405157410773\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:31<00:25,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.385931635508314\n","Test Loss:  17.347520845301915\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:32<00:24,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  38.69228228909196\n","Test Loss:  18.17199287598487\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:33<00:23,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.94224057998508\n","Test Loss:  16.234135778067866\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:34<00:22,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.364597616833635\n","Test Loss:  16.35344271856593\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:35<00:20,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.62475151766557\n","Test Loss:  16.02332667504379\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:36<00:19,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.722024129121564\n","Test Loss:  15.655286176042864\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:38<00:18,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.26806960243266\n","Test Loss:  16.337926914566197\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:39<00:17,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.00366782268975\n","Test Loss:  15.25122018836555\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:40<00:16,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.39646016707411\n","Test Loss:  15.665812694351189\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:41<00:15,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.850772012607194\n","Test Loss:  15.639259740128182\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:42<00:14,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.61647210089723\n","Test Loss:  15.261312696704408\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:43<00:13,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.334897229855414\n","Test Loss:  15.05016761024308\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:44<00:11,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.99185435945401\n","Test Loss:  14.982832945228438\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:45<00:10,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.190873545769136\n","Test Loss:  14.850085679150652\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:46<00:09,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.49650286528049\n","Test Loss:  15.759409570833668\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:47<00:08,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.968739954638295\n","Test Loss:  14.799468051991425\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:48<00:07,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.46699918335071\n","Test Loss:  14.831559721264057\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:50<00:06,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.05551289947471\n","Test Loss:  14.82887138996739\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:51<00:05,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  34.21529128885595\n","Test Loss:  15.04882708605146\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:52<00:04,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.29301987422514\n","Test Loss:  14.966843155038077\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:53<00:04,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  35.05133008718258\n","Test Loss:  15.20045209460659\n","Early stopping with best_loss:  14.799468051991425 and test_loss for this epoch:  15.20045209460659 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8160673819151832\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","  2%|▏         | 1/50 [00:01<00:53,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.03749548643827\n","Test Loss:  47.04193048574962\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:52,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  101.81492357887328\n","Test Loss:  34.24994355859235\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:51,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  74.99911021767184\n","Test Loss:  26.924128459068015\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:50,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.64176415302791\n","Test Loss:  23.930723650526488\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:49,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.57476845989004\n","Test Loss:  23.077264003630262\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:48,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.99665592593374\n","Test Loss:  23.59564167240751\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:47,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.429250560788205\n","Test Loss:  21.275853604252916\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:46,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.854469148558564\n","Test Loss:  21.114368730806746\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:45,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.20774980128044\n","Test Loss:  19.22499785956461\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:44,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.4383685978828\n","Test Loss:  20.157188428303925\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:43,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.957111491123214\n","Test Loss:  18.59945674148912\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:41,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.92234722455032\n","Test Loss:  18.74436731066089\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:14<00:40,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.344632040534634\n","Test Loss:  24.55919066653587\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:15<00:40,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.425566265475936\n","Test Loss:  18.19188056542771\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:16<00:38,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.09976250841282\n","Test Loss:  17.379642807500204\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:17<00:37,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.329438707529334\n","Test Loss:  17.750124485231936\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:18<00:36,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.04280673584435\n","Test Loss:  16.935478014391265\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:19<00:35,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.299174797779415\n","Test Loss:  17.68827209190931\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:20<00:34,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.61845691187773\n","Test Loss:  18.199412946152734\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:22<00:33,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.20457909081597\n","Test Loss:  16.574479414266534\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:23<00:32,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.31008654600009\n","Test Loss:  17.285783211817034\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:24<00:30,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.163356274715625\n","Test Loss:  17.017725214886013\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:25<00:29,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.74108945555054\n","Test Loss:  16.559458362986334\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:26<00:28,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.60617091646418\n","Test Loss:  16.456422305549495\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:27<00:27,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.2508872768376\n","Test Loss:  16.480957908031996\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:28<00:26,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.67883827078913\n","Test Loss:  16.876878373499494\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:29<00:25,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.454551697708666\n","Test Loss:  18.236520685255527\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:30<00:24,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.01568051686627\n","Test Loss:  16.926350448920857\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:31<00:25,  1.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  37.982438021106645\n","Test Loss:  19.29758407533518\n","Early stopping with best_loss:  16.456422305549495 and test_loss for this epoch:  19.29758407533518 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8879434435286873\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<01:00,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  118.1563107855618\n","Test Loss:  43.01677918480709\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:57,  1.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.60201331973076\n","Test Loss:  31.10986472701188\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:56,  1.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.175788779743016\n","Test Loss:  27.54065239985357\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:54,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.86328678415157\n","Test Loss:  27.686689418624155\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:53,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.11092932574684\n","Test Loss:  24.105071217752993\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:07<00:51,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.498812192701735\n","Test Loss:  25.23011757255881\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:50,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.85341355018318\n","Test Loss:  22.8148427142296\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:49,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.266681780223735\n","Test Loss:  23.307257864653366\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:48,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.34447056404315\n","Test Loss:  21.835592408839148\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:47,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.73688716732431\n","Test Loss:  20.569143591739703\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:13<00:46,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.07871200324735\n","Test Loss:  21.278891328314785\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:14<00:45,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.83062845171662\n","Test Loss:  20.384604813647456\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:15<00:43,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.086346575350035\n","Test Loss:  20.339476085151546\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:16<00:42,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.02180726657389\n","Test Loss:  19.359033607528545\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:41,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.02469604962971\n","Test Loss:  22.154283683077665\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:39,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.43395514343865\n","Test Loss:  19.41199222090654\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:20<00:38,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.247064723283984\n","Test Loss:  19.09401122230338\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:21<00:37,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.73317970789503\n","Test Loss:  19.15936072479235\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:22<00:36,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.50373450387269\n","Test Loss:  18.93085381417768\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:23<00:35,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.433303074736614\n","Test Loss:  18.264038535417058\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:24<00:34,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.87459337670589\n","Test Loss:  18.236350007297006\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:26<00:33,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.655973218847066\n","Test Loss:  18.937549691589084\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:27<00:32,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.45356906630332\n","Test Loss:  18.430530903919134\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:28<00:30,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  32.50493193522561\n","Test Loss:  18.849075147416443\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:29<00:29,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.041857169475406\n","Test Loss:  17.709340215020347\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:30<00:28,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  30.903236080222996\n","Test Loss:  18.503291691071354\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:31<00:27,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.99448934721295\n","Test Loss:  17.245219048054423\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:33<00:26,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  30.476549781044014\n","Test Loss:  17.554081184440292\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:34<00:24,  1.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  32.926588510890724\n","Test Loss:  17.250312117801514\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:35<00:23,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  31.763968298968393\n","Test Loss:  17.48404502705671\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:36<00:22,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  29.692878577276133\n","Test Loss:  19.07595643121749\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:37<00:23,  1.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  31.264907995122485\n","Test Loss:  18.498664812766947\n","Early stopping with best_loss:  17.245219048054423 and test_loss for this epoch:  18.498664812766947 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1441296239709795\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:08,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  358.2225726507604\n","Test Loss:  82.25087748304941\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:06,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  192.46470666886307\n","Test Loss:  65.67734818882309\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:03,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.2323120208457\n","Test Loss:  53.5548284536344\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:00,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  114.68744941882323\n","Test Loss:  47.02058884015423\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<01:57,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  105.51055926887784\n","Test Loss:  42.79343800665811\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:54,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  97.43733344355132\n","Test Loss:  40.77373283286579\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:51,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  96.16187347052619\n","Test Loss:  37.88653090408479\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:50,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  89.41161854832899\n","Test Loss:  40.61615748301847\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:47,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  85.49731343582971\n","Test Loss:  36.77198824414518\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:26<01:45,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.04142860911088\n","Test Loss:  34.283816960960394\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:42,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  82.92925135955738\n","Test Loss:  34.47263007616857\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:31<01:39,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  82.4511026601831\n","Test Loss:  37.07909326461959\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:34<01:37,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  84.33060157945147\n","Test Loss:  32.64471904223319\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:36<01:35,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.80417117261095\n","Test Loss:  31.2451285845018\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:39<01:32,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  77.99660562875215\n","Test Loss:  31.737303515401436\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:42<01:29,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.45566520438297\n","Test Loss:  30.850857078068657\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:44<01:26,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.23210416358779\n","Test Loss:  30.067029300989816\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:47<01:24,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  71.41994108847575\n","Test Loss:  30.2107843865233\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:49<01:21,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  71.45701664857916\n","Test Loss:  33.40897148102522\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:52<01:19,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  71.40611076622736\n","Test Loss:  31.46615920291515\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:55<01:16,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.81326201718184\n","Test Loss:  28.851929386000847\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:57<01:14,  2.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  69.41212363739032\n","Test Loss:  28.94706577420584\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:00<01:11,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.88322893308941\n","Test Loss:  28.722407368943095\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:03<01:07,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  67.80428184071206\n","Test Loss:  29.093184500030475\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:05<01:05,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  69.47826732519025\n","Test Loss:  28.9414325049147\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:08<01:02,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  71.17082490568282\n","Test Loss:  28.18176421080716\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:10<00:59,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.61307953723008\n","Test Loss:  28.14647920706193\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:13<00:57,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.12468557892134\n","Test Loss:  28.134711488557514\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:16<00:54,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  65.20694815230672\n","Test Loss:  32.720482303062454\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:18<00:51,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  67.40211368561722\n","Test Loss:  29.396129561559064\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:21<00:49,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.88938919251086\n","Test Loss:  27.069888415717287\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:23<00:46,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  66.25059487111866\n","Test Loss:  27.40991648650379\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:26<00:44,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  65.24990303980303\n","Test Loss:  27.162239576835418\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:29<00:41,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  65.2947166399681\n","Test Loss:  28.012637130508665\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:31<00:39,  2.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.01717669566278\n","Test Loss:  26.950071445317008\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:34<00:37,  2.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.19583645244711\n","Test Loss:  26.719764583584038\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:37<00:34,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  65.36850880552083\n","Test Loss:  28.287446016678587\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:39<00:31,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  62.43327180767665\n","Test Loss:  28.85424583769054\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:42<00:28,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.21197801240487\n","Test Loss:  26.177383353438927\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:45<00:26,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  61.69998675948591\n","Test Loss:  28.376959668996278\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:47<00:23,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  62.10136505885748\n","Test Loss:  26.600569261121564\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [01:50<00:21,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  63.03935900540091\n","Test Loss:  26.600029334964347\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:52<00:18,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  65.74634784960654\n","Test Loss:  27.30952833412448\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:55<00:18,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  62.20190620368521\n","Test Loss:  26.193575473938836\n","Early stopping with best_loss:  26.177383353438927 and test_loss for this epoch:  26.193575473938836 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6087841496501681\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:07,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  244.04520578077063\n","Test Loss:  84.0965772952186\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:05,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.311501543154\n","Test Loss:  63.64224888803437\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:03,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.23989088996314\n","Test Loss:  50.83292237855494\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:00,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  107.04475552483927\n","Test Loss:  44.972288625489455\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<01:57,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  98.78293793729972\n","Test Loss:  43.97202029515756\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:54,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  93.51173877017573\n","Test Loss:  38.76486979916808\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:51,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  91.08432922553038\n","Test Loss:  38.92290191331995\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:48,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  87.86646550346632\n","Test Loss:  37.51982385973679\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:46,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.98526034809765\n","Test Loss:  34.86289080407005\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:26<01:44,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  78.03264605501317\n","Test Loss:  35.00568896497134\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:41,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.66937749733916\n","Test Loss:  34.61455186249805\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:31<01:38,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.57939956785413\n","Test Loss:  33.53222186511266\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:35,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.14614633622114\n","Test Loss:  31.840395657738554\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:36<01:33,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.63489701561048\n","Test Loss:  31.508905435766792\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:39<01:31,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  71.80832644825568\n","Test Loss:  32.10480986404582\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:28,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  73.06117876796634\n","Test Loss:  33.34793059519143\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:44<01:25,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  71.2659433154331\n","Test Loss:  30.125374038500013\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:46<01:22,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  68.91126652638195\n","Test Loss:  30.328386193607002\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:49<01:19,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  68.89379406635999\n","Test Loss:  31.166549998000846\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:51<01:16,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.6327444864437\n","Test Loss:  29.932227133307606\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:54<01:14,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  64.45130217200494\n","Test Loss:  31.71849599451525\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:56<01:11,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  64.6402207709325\n","Test Loss:  30.007798766338965\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:59<01:09,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.31504543800838\n","Test Loss:  29.266328527970472\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:02<01:06,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  67.21676899096929\n","Test Loss:  30.279255644069053\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:04<01:04,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  63.39264949326753\n","Test Loss:  33.07265385426581\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:07<01:01,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  63.921070705284365\n","Test Loss:  30.966749793442432\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:09<00:58,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.85899434071325\n","Test Loss:  28.528073498309823\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:12<00:56,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.16017300594831\n","Test Loss:  29.65594746705756\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:14<00:53,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  63.03582853262196\n","Test Loss:  29.364637098187814\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:17<00:50,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  62.66004223184427\n","Test Loss:  29.7010860579976\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:19<00:48,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.88596667547245\n","Test Loss:  27.73298626075848\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:22<00:46,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.94359146771603\n","Test Loss:  27.81800131915952\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:25<00:43,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  57.94748223933857\n","Test Loss:  29.105809774133377\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:27<00:41,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.47456743163639\n","Test Loss:  27.15131885583105\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:30<00:38,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.5713302011427\n","Test Loss:  28.963725804554997\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:32<00:36,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  61.76297833205899\n","Test Loss:  28.212190700724022\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:35<00:33,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  60.36820309967152\n","Test Loss:  28.22974824186531\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:38<00:31,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  59.01216426884639\n","Test Loss:  27.743697734898888\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:40<00:31,  2.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  58.298511258966755\n","Test Loss:  28.629805277538253\n","Early stopping with best_loss:  27.15131885583105 and test_loss for this epoch:  28.629805277538253 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5976104236000298\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:14,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  217.76250371872447\n","Test Loss:  73.38467708689859\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:13,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.44206653360743\n","Test Loss:  51.962262955028564\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:10,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  111.62052575871348\n","Test Loss:  44.06543358252384\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:07,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  95.6329585435451\n","Test Loss:  40.539582279569004\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:05,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  89.1542038282787\n","Test Loss:  38.82351748936344\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<02:02,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  83.93834658619016\n","Test Loss:  36.44673206232255\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<01:59,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  81.17494821164291\n","Test Loss:  40.40660908186692\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:22<01:57,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.56014546158258\n","Test Loss:  33.86747227195883\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:25<01:54,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.57241062121466\n","Test Loss:  32.99310517573031\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:51,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.52885453138151\n","Test Loss:  30.313428680965444\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:30<01:48,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  70.5958675731672\n","Test Loss:  31.4676363444014\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:33<01:44,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  69.56971883503138\n","Test Loss:  31.720321620916366\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:36<01:41,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  73.43463193257776\n","Test Loss:  32.09661398641765\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:39,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  70.12742736830842\n","Test Loss:  35.93184402093175\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:41<01:36,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.25292313753744\n","Test Loss:  27.5046057672007\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:44<01:33,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  68.94428799831076\n","Test Loss:  30.443147618556395\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:47<01:31,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  66.40751218239893\n","Test Loss:  28.311421096732374\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:49<01:28,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  67.43265416311624\n","Test Loss:  28.41334677656414\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:52<01:25,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  66.09253742880537\n","Test Loss:  30.278116965317167\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:55<01:30,  2.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  65.92245996007114\n","Test Loss:  29.58001522430277\n","Early stopping with best_loss:  27.5046057672007 and test_loss for this epoch:  29.58001522430277 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6530835435494108\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:31,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  507.627449542284\n","Test Loss:  136.4385619382374\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  312.91136928927153\n","Test Loss:  111.60999867954524\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:27,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  257.71500120824203\n","Test Loss:  93.88002221891657\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:23,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  235.0651781342458\n","Test Loss:  84.48667226580437\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:20,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  211.94300392270088\n","Test Loss:  79.22561798244715\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:19,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  205.104221918853\n","Test Loss:  75.02269282344787\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:16,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  193.3816535124788\n","Test Loss:  72.63169205316808\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:13,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  184.6709619598696\n","Test Loss:  73.18662216787925\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:28<02:09,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  181.03135393362027\n","Test Loss:  70.9376878424082\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:31<02:06,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  175.44247990107397\n","Test Loss:  68.82918118721864\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:34<02:03,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  167.77543574903393\n","Test Loss:  62.399307479092386\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:37<02:00,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.14330253342632\n","Test Loss:  60.162642000679625\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:41<01:57,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  161.31145720291534\n","Test Loss:  60.569035967841046\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:44<01:53,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  159.63908667323994\n","Test Loss:  63.72622822818812\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:47<01:49,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  157.40555313398363\n","Test Loss:  61.23615426404285\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:50<01:46,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.36696739858598\n","Test Loss:  56.90349118094309\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:53<01:43,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.92824942569132\n","Test Loss:  56.00790938013233\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:56<01:40,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  148.35814526944887\n","Test Loss:  58.161364209488966\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:59<01:36,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  150.82127682704595\n","Test Loss:  60.54859735048376\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:02<01:34,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  148.7106194390508\n","Test Loss:  56.339129919273546\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:06<01:31,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.74624407617375\n","Test Loss:  54.05730878259055\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:09<01:27,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.40456940350123\n","Test Loss:  53.44928982120473\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:12<01:24,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.15379207962542\n","Test Loss:  58.016410454467405\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:15<01:21,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  138.42581709407386\n","Test Loss:  59.08793734262872\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:18<01:18,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  134.94905342860147\n","Test Loss:  57.48379810451297\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:21<01:14,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  141.9205850751605\n","Test Loss:  54.956264163178275\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:24<01:11,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.1869798655389\n","Test Loss:  51.74775873243925\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:28<01:09,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  141.41798385960283\n","Test Loss:  53.16091275178769\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:31<01:05,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  137.9155090698914\n","Test Loss:  51.77581345141516\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:34<01:02,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.72219693337684\n","Test Loss:  52.994658463052474\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:37<00:58,  3.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  139.99109051161213\n","Test Loss:  53.303090133093065\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:40<01:01,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  137.1984573684167\n","Test Loss:  52.82729623862542\n","Early stopping with best_loss:  51.74775873243925 and test_loss for this epoch:  52.82729623862542 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.282771734595098\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:30,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  417.84108832571656\n","Test Loss:  120.89758241048548\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:28,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  279.67580480105244\n","Test Loss:  95.88814904005267\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:26,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  231.85063832229935\n","Test Loss:  85.97245653616847\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:22,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  207.23325861920603\n","Test Loss:  78.92693409312051\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:20,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  196.91330254462082\n","Test Loss:  71.23446818522643\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:16,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.87731553439517\n","Test Loss:  67.6159275645332\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:14,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  176.43204326089472\n","Test Loss:  63.78435880879988\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:24<02:11,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  164.73561407325906\n","Test Loss:  65.58550376474159\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:28<02:08,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  166.36255670664832\n","Test Loss:  63.68669059120293\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:31<02:05,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  162.45270054414868\n","Test Loss:  59.611499027727405\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:34<02:01,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.89609244276653\n","Test Loss:  59.345732485176995\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:37<01:58,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.55425396788632\n","Test Loss:  56.736904260877054\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:40<01:55,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  155.344329841726\n","Test Loss:  57.59762803232297\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:43<01:52,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.9324212615611\n","Test Loss:  55.998187880730256\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:46<01:49,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.66201695616473\n","Test Loss:  53.44296029818361\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:49<01:45,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  143.7213552199828\n","Test Loss:  54.79088078654604\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:52<01:42,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.66886875528144\n","Test Loss:  52.929458286685986\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:56<01:39,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.24231353303185\n","Test Loss:  52.49449753703084\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:59<01:35,  3.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  142.07355003687553\n","Test Loss:  56.29693797748769\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:02<01:32,  3.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  145.00917758987634\n","Test Loss:  52.54291644640034\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:05<01:29,  3.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.8584630510304\n","Test Loss:  53.53724651617813\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:08<01:26,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.3347003982053\n","Test Loss:  51.78348287413246\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:11<01:23,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  139.53391346207354\n","Test Loss:  53.259735718689626\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:14<01:21,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.45459864434088\n","Test Loss:  51.54753788775997\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:17<01:18,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  137.8816322212806\n","Test Loss:  52.92897491768235\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:21<01:15,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.84962286689552\n","Test Loss:  50.94778812339064\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:24<01:12,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.49576077016536\n","Test Loss:  50.108955273928586\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:27<01:08,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  131.40872532565845\n","Test Loss:  51.26986711542122\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:30<01:06,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.02714923549502\n","Test Loss:  51.21929641607858\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:33<01:03,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.11454837096971\n","Test Loss:  49.289668439581874\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:36<00:59,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  125.29743370250799\n","Test Loss:  53.666512334079016\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:39<00:56,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  130.9388756796252\n","Test Loss:  51.36558760772459\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:42<00:52,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  127.60673716012388\n","Test Loss:  49.52784995897673\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:46<00:49,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  129.65473934466718\n","Test Loss:  51.20113501373271\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:49<00:46,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.17911614623154\n","Test Loss:  49.121371392160654\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:52<00:43,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  126.5861492906406\n","Test Loss:  63.96632921078708\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:55<00:40,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  125.04611018541618\n","Test Loss:  50.09395184830646\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:58<00:37,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  126.06090967188356\n","Test Loss:  47.899842760380125\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [02:01<00:34,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.4139185862732\n","Test Loss:  47.21239621625864\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [02:04<00:31,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  125.01446454363759\n","Test Loss:  50.51965619146358\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [02:07<00:28,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  125.21708940487588\n","Test Loss:  47.52542305228417\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:10<00:24,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  122.69732196629047\n","Test Loss:  50.522433534031734\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:14<00:21,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  122.10244149417849\n","Test Loss:  49.883617145824246\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:17<00:22,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  121.68081176432315\n","Test Loss:  48.8043200110551\n","Early stopping with best_loss:  47.21239621625864 and test_loss for this epoch:  48.8043200110551 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1021729201429054\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:45,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  364.2069551628083\n","Test Loss:  115.95738369075116\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:42,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  245.3542836920824\n","Test Loss:  85.42995115727535\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:39,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  206.03720384195913\n","Test Loss:  76.16160797467455\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:36,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  187.70014048251323\n","Test Loss:  68.68125363570289\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:32,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  178.27111844019964\n","Test Loss:  64.55734394246247\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:20<02:28,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  169.95355033996748\n","Test Loss:  62.267922733240994\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:25,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.43246147202444\n","Test Loss:  60.961919700494036\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:27<02:21,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  160.27792563399998\n","Test Loss:  61.430214893305674\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:30<02:18,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  160.565390542557\n","Test Loss:  59.02176222152775\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:33<02:15,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.61498951289104\n","Test Loss:  54.49701574674691\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:37<02:12,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  149.33428115129936\n","Test Loss:  54.84138093699585\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:40<02:08,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.26829968160018\n","Test Loss:  52.8036272712925\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:43<02:04,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.3670502944733\n","Test Loss:  54.3084447143483\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:47<02:02,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.62018918406102\n","Test Loss:  51.440630077719106\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:50<01:58,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  144.64395038716611\n","Test Loss:  51.64628516546509\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:54<01:54,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.12561508605722\n","Test Loss:  51.0957956428756\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:57<01:51,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  143.86546984652523\n","Test Loss:  47.89514370873803\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:00<01:48,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.04294095712248\n","Test Loss:  51.66870407012175\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:04<01:44,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  137.72222977338242\n","Test Loss:  57.67153570489609\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:07<01:41,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.33976952848025\n","Test Loss:  48.5785964136594\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:11<01:38,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  136.33876486349618\n","Test Loss:  49.0667555462569\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:14<01:42,  3.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  133.06277179246536\n","Test Loss:  50.93901011312846\n","Early stopping with best_loss:  47.89514370873803 and test_loss for this epoch:  50.93901011312846 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0878924649079298\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:48,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  199.75475200265646\n","Test Loss:  46.13400660455227\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:47,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  145.34665725380182\n","Test Loss:  39.43590146768838\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:46,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  115.15136486664414\n","Test Loss:  30.699689087457955\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:45,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  90.5400611772202\n","Test Loss:  26.281959212152287\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:44,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.40718671027571\n","Test Loss:  22.785095650935546\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:43,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.82035962073132\n","Test Loss:  21.63627212017309\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:43,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.22373609361239\n","Test Loss:  19.99688036669977\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:42,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.361563191981986\n","Test Loss:  20.05402177880751\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:41,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.38663505483419\n","Test Loss:  18.916628323320765\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:09<00:39,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.79442568146624\n","Test Loss:  18.739338345243596\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:10<00:38,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.50781770911999\n","Test Loss:  18.123401143035153\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:11<00:37,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.9961555559712\n","Test Loss:  18.110520387999713\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:12<00:36,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.83036554546561\n","Test Loss:  18.745514381997054\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:13<00:35,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.2570456948597\n","Test Loss:  17.368828891660087\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:14<00:34,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.12954949657433\n","Test Loss:  17.051839917112375\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:15<00:34,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.54672327742446\n","Test Loss:  16.19864107266767\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:16<00:33,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.741099900507834\n","Test Loss:  15.988851908710785\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:17<00:32,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.16764049557969\n","Test Loss:  16.494110469415318\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:18<00:31,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.57010145089589\n","Test Loss:  16.30575395550113\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:19<00:30,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.153571967675816\n","Test Loss:  15.628130786353722\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:20<00:28,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.137629612814635\n","Test Loss:  17.179628092620987\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:21<00:27,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  44.26150436507305\n","Test Loss:  16.511736817192286\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:22<00:26,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.930885380425025\n","Test Loss:  15.463496437761933\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:23<00:25,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.7853352422826\n","Test Loss:  14.97864877799293\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:24<00:24,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.48908380987996\n","Test Loss:  16.253246730251703\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:25<00:23,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.8440595701104\n","Test Loss:  15.387311013764702\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:26<00:22,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  39.17694019922055\n","Test Loss:  15.665592284291051\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:27<00:21,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  37.77107985498151\n","Test Loss:  15.499549854779616\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:28<00:20,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.74672032019589\n","Test Loss:  14.748062058584765\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:29<00:19,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.04163124639308\n","Test Loss:  15.20865424029762\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:30<00:18,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.5933092153864\n","Test Loss:  15.487653213378508\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:31<00:17,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.045592989830766\n","Test Loss:  14.67048226269253\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:32<00:16,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.24390830821358\n","Test Loss:  16.198651649290696\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:33<00:15,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.55577021249337\n","Test Loss:  14.269589444738813\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:34<00:14,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.67961179220583\n","Test Loss:  14.314338533848058\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:35<00:13,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.853506973944604\n","Test Loss:  14.357661213245592\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:36<00:12,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.046127542853355\n","Test Loss:  14.419493254739791\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:37<00:11,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.18648767963168\n","Test Loss:  13.678784258721862\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:38<00:10,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.96981979411794\n","Test Loss:  14.591894012526609\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:39<00:09,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.99327039757918\n","Test Loss:  13.628579003212508\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:40<00:08,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.90438330563484\n","Test Loss:  13.66934764222242\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:41<00:07,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.48039013170637\n","Test Loss:  12.845654773176648\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:42<00:06,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.046020472451346\n","Test Loss:  14.669186554150656\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:43<00:05,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.99667706619948\n","Test Loss:  13.355755042517558\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:44<00:04,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.04827610665234\n","Test Loss:  14.085963596473448\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:45<00:03,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.95639699633466\n","Test Loss:  13.515535835904302\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:46<00:04,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  36.217430121207144\n","Test Loss:  12.994140614959178\n","Early stopping with best_loss:  12.845654773176648 and test_loss for this epoch:  12.994140614959178 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.8730010386009521\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:49,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.8132488951087\n","Test Loss:  44.23592154867947\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:47,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  106.01417174190283\n","Test Loss:  33.5791461491026\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:46,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.88493773899972\n","Test Loss:  26.818257984123193\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:45,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.194851144682616\n","Test Loss:  25.5106242694892\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:44,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.957391772652045\n","Test Loss:  24.73182387347333\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:43,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.900932075455785\n","Test Loss:  22.22852583992062\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:42,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.79575790488161\n","Test Loss:  21.305729932442773\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:07<00:41,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.054959731176496\n","Test Loss:  20.917691507085692\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:08<00:40,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.22838627640158\n","Test Loss:  19.96605776064098\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:09<00:39,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.20349004317541\n","Test Loss:  19.568612476577982\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:10<00:38,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.011958059621975\n","Test Loss:  19.369513356650714\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:11<00:37,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.887005222262815\n","Test Loss:  18.510532091429923\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:12<00:36,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.889057196793146\n","Test Loss:  18.855814974638633\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:13<00:35,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.01443206286058\n","Test Loss:  19.811236167617608\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:14<00:34,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  42.35254751413595\n","Test Loss:  19.77530278460472\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:15<00:32,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  40.30155955569353\n","Test Loss:  19.172787468938623\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:16<00:32,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.64207258133683\n","Test Loss:  17.374191505776253\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:17<00:31,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.589494963584\n","Test Loss:  18.441307891975157\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:18<00:30,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.13527836475987\n","Test Loss:  22.27580505979131\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:19<00:29,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.43357946642209\n","Test Loss:  17.291239637939725\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:20<00:28,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.25252325809561\n","Test Loss:  17.336757041397505\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:21<00:27,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.282721871102694\n","Test Loss:  17.5329893064918\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:22<00:26,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.21512563171564\n","Test Loss:  16.72647461813176\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:23<00:25,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.787862147553824\n","Test Loss:  17.26651404122822\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:24<00:24,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.77023175690556\n","Test Loss:  15.723318672098685\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:25<00:23,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.17097137583187\n","Test Loss:  16.893586992868222\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:26<00:22,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.30886984290555\n","Test Loss:  16.005565576720983\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:27<00:21,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  37.345876758452505\n","Test Loss:  17.041630345236626\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:28<00:20,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.35888849501498\n","Test Loss:  15.562883607344702\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:29<00:20,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.69096261577215\n","Test Loss:  15.944499510107562\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:30<00:19,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.49854970537126\n","Test Loss:  16.862262087292038\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:31<00:18,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.03044520271942\n","Test Loss:  15.191595551499631\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:32<00:16,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.84283606550889\n","Test Loss:  15.632542875653598\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:33<00:15,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.3748011169082\n","Test Loss:  15.420719312329311\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:34<00:14,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  34.32030257687438\n","Test Loss:  15.504534142266493\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:35<00:13,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.06791393144522\n","Test Loss:  14.642801866168156\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:36<00:12,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.8660200748709\n","Test Loss:  14.579421646660194\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:37<00:11,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.434279705485096\n","Test Loss:  14.546545489458367\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:38<00:10,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.95035457517952\n","Test Loss:  15.47567956277635\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:39<00:09,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.71313614444807\n","Test Loss:  13.99977171595674\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:40<00:08,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.13822529974277\n","Test Loss:  14.299169067846378\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:41<00:07,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  32.33376329680323\n","Test Loss:  15.477089152031112\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:42<00:07,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.377242291287985\n","Test Loss:  13.92276110878447\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:43<00:05,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.44032997917384\n","Test Loss:  13.738270173082128\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:44<00:04,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.41018488374539\n","Test Loss:  14.334065886912867\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:45<00:03,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.67848682944896\n","Test Loss:  13.48396538553061\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [00:46<00:02,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.87271865212824\n","Test Loss:  14.788616648758762\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [00:47<00:01,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  31.9379780991585\n","Test Loss:  14.811604050453752\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 49/50 [00:48<00:00,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  32.51017085503554\n","Test Loss:  15.78617476625368\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:49<00:00,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  31.92443942639511\n","Test Loss:  13.568943989754189\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7828709869749956\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:52,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.01751124113798\n","Test Loss:  34.723473736085\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:51,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.57345154043287\n","Test Loss:  24.22878366918303\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:51,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.24544867384247\n","Test Loss:  20.764371566474438\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:50,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.82753205380868\n","Test Loss:  19.28194755304139\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:48,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.19481995748356\n","Test Loss:  20.00644328937051\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:47,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.724437101976946\n","Test Loss:  18.12578474590555\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:46,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.74119167041499\n","Test Loss:  17.436377024569083\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:45,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.58381589851342\n","Test Loss:  15.90883269731421\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:44,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.41122615151107\n","Test Loss:  15.648459332471248\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:43,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.88260173157323\n","Test Loss:  17.785574735957198\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:42,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.05571217817487\n","Test Loss:  14.94938716548495\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:41,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.663563081412576\n","Test Loss:  14.159832138975617\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:14<00:40,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.0941434741253\n","Test Loss:  15.62259110296145\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:15<00:39,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.500009707175195\n","Test Loss:  14.325952999221045\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:16<00:38,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  42.67349656519946\n","Test Loss:  14.829096153436694\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:17<00:37,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  41.47431122639682\n","Test Loss:  15.982169775816146\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:18<00:35,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.714308412221726\n","Test Loss:  13.679236484575085\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:19<00:34,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.4791173862759\n","Test Loss:  13.320386714302003\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:20<00:33,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.31888690168853\n","Test Loss:  13.200560522149317\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:21<00:32,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.60431711853016\n","Test Loss:  13.70596910722088\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:22<00:31,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.09453409083653\n","Test Loss:  13.32221269508591\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:23<00:30,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.35170740500325\n","Test Loss:  13.260323081747629\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:25<00:29,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.62961754674325\n","Test Loss:  13.095672917697811\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:26<00:28,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.24858437679359\n","Test Loss:  12.58120128174778\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:27<00:27,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.567672551900614\n","Test Loss:  13.557732083281735\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:28<00:26,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.37452613830101\n","Test Loss:  12.334135031735059\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:29<00:25,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.655106228077784\n","Test Loss:  12.212557665188797\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:30<00:24,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.51416799228173\n","Test Loss:  13.566219887696207\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:31<00:22,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.83698850910878\n","Test Loss:  12.415528481185902\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:32<00:21,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.13709232985275\n","Test Loss:  11.76730416645296\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:33<00:20,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.846457587060286\n","Test Loss:  12.629376968950965\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:34<00:19,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.176069308421575\n","Test Loss:  12.029225666134153\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:35<00:18,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.08275470614899\n","Test Loss:  11.395512667600997\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:37<00:17,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.42400714347605\n","Test Loss:  12.472547209821641\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:38<00:16,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.83940251413151\n","Test Loss:  11.487387206987478\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:39<00:15,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.82764553022571\n","Test Loss:  11.044685608067084\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:40<00:14,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.229544905538205\n","Test Loss:  11.987281152862124\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:41<00:13,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.35594398883404\n","Test Loss:  11.008921241387725\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:42<00:11,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.27938922285102\n","Test Loss:  13.122731765615754\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:43<00:10,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  31.231433485576417\n","Test Loss:  12.99662595648988\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [00:44<00:09,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  32.99040902405977\n","Test Loss:  11.421986466273665\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [00:45<00:08,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  31.388417889364064\n","Test Loss:  11.285598662565462\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [00:46<00:07,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.92898628860712\n","Test Loss:  10.726661072229035\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [00:47<00:06,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.24607536458643\n","Test Loss:  11.691938692820258\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [00:48<00:05,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  30.482111142540816\n","Test Loss:  12.45505245012464\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [00:50<00:04,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.89855178227299\n","Test Loss:  10.681628265941981\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [00:51<00:03,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  31.635790246538818\n","Test Loss:  10.691812989418395\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [00:52<00:02,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.19034478790127\n","Test Loss:  10.616180313634686\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 49/50 [00:53<00:01,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.901217105740216\n","Test Loss:  10.127741348260315\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:54<00:00,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  29.48387683875626\n","Test Loss:  10.64374370870064\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6169748972481313\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:57,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  316.79022732563317\n","Test Loss:  54.257896950119175\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:56,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  167.623099333141\n","Test Loss:  44.93545934581198\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:55,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  118.77267988026142\n","Test Loss:  36.948810103640426\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:52,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  97.82585513219237\n","Test Loss:  33.25902806548402\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:50,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  90.44660683698021\n","Test Loss:  30.716637599020032\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:47,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  83.63608099642443\n","Test Loss:  30.793045238417108\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:45,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.27611628075829\n","Test Loss:  27.394248295400757\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:19<01:43,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  76.71965845351224\n","Test Loss:  28.720089903014014\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:22<01:41,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  74.65289129060693\n","Test Loss:  24.71168965450488\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:24<01:38,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.49512606457574\n","Test Loss:  24.61947824328672\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:27<01:36,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.19992735789856\n","Test Loss:  24.079861110221827\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:29<01:34,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  69.10968972404953\n","Test Loss:  24.26571759194485\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:32<01:31,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.25153270980809\n","Test Loss:  23.101314425177407\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:34<01:28,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  66.33124007078004\n","Test Loss:  23.404235325520858\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:36<01:26,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.66406959675078\n","Test Loss:  21.5567917379376\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:39<01:23,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  64.98990819061873\n","Test Loss:  22.40703696804121\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:41<01:21,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  63.45012990757823\n","Test Loss:  23.358056578377727\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:44<01:18,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  61.9729261273751\n","Test Loss:  23.011251184041612\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:46<01:16,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.22871410800144\n","Test Loss:  21.09989198637777\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:49<01:14,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.483538333064644\n","Test Loss:  22.4933628111321\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:51<01:11,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  60.889502487989375\n","Test Loss:  22.088979063904844\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:54<01:09,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.269021495012566\n","Test Loss:  20.450999548429536\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:56<01:06,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.13718650781084\n","Test Loss:  20.120743066363502\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:59<01:03,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.09598589071538\n","Test Loss:  19.52903593078372\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:01<01:01,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.65208681070362\n","Test Loss:  19.403061228164006\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:03<00:58,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.46525541387382\n","Test Loss:  19.552963885304052\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:06<00:56,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  58.65845202415949\n","Test Loss:  19.460774304752704\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:08<00:54,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.11068916122167\n","Test Loss:  19.0474321974325\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:11<00:52,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.76383128859743\n","Test Loss:  18.713273275760002\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:13<00:49,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.01328864885727\n","Test Loss:  18.823212892806623\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:16<00:47,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.460361925826874\n","Test Loss:  18.319324848387623\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:18<00:45,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.985281735949684\n","Test Loss:  21.09783158416394\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:21<00:42,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.42365825967863\n","Test Loss:  18.151649763196474\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:23<00:39,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.96116199454991\n","Test Loss:  18.6709558989387\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:26<00:37,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.928404002508614\n","Test Loss:  18.049253641511314\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:28<00:35,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  55.47185392980464\n","Test Loss:  18.561327351184445\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:31<00:32,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  54.29922865334083\n","Test Loss:  18.712896609154996\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:34<00:30,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  52.12560190988006\n","Test Loss:  18.380976943764836\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:36<00:27,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.438729316403624\n","Test Loss:  17.692723745683907\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:39<00:25,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.53498872969067\n","Test Loss:  17.967953504543402\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:41<00:22,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  55.597808412712766\n","Test Loss:  18.223932066641282\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [01:44<00:20,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  53.215476591838524\n","Test Loss:  17.808829609886743\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  50.16551942873048\n","Test Loss:  17.93141542430385\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:49<00:17,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  52.51383339235326\n","Test Loss:  19.30959957349114\n","Early stopping with best_loss:  17.692723745683907 and test_loss for this epoch:  19.30959957349114 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.40283981351745335\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:03,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  215.946004669182\n","Test Loss:  56.83901575487107\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:59,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  126.26553932344541\n","Test Loss:  41.254254653002135\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:55,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  97.8130874815397\n","Test Loss:  34.31127480708528\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:53,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.26940161071252\n","Test Loss:  30.111690881079994\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:50,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.48062311238027\n","Test Loss:  28.173070348246256\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:48,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  73.29616208974039\n","Test Loss:  28.258244036027463\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:45,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.39356613473501\n","Test Loss:  25.47734841343481\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:19<01:42,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  70.59762253024383\n","Test Loss:  26.213390999066178\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:22<01:40,  2.45s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  70.48721352455323\n","Test Loss:  27.08693484106334\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:24<01:38,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  64.15192457009107\n","Test Loss:  29.547725970100146\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:27<01:36,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.21306076075416\n","Test Loss:  25.14837153159897\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:29<01:33,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.386386843340006\n","Test Loss:  23.383707188564586\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:32<01:31,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.84810476569692\n","Test Loss:  23.36226208350854\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:34<01:29,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.301427102822345\n","Test Loss:  27.16161628178088\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:37<01:26,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.326473348395666\n","Test Loss:  21.22639094607439\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:39<01:23,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.68475918547483\n","Test Loss:  22.69869764431496\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:41<01:21,  2.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  59.40607808911591\n","Test Loss:  22.82237805754994\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:44<01:18,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  58.19404270447558\n","Test Loss:  22.994398514973\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:46<01:15,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  56.28387223009486\n","Test Loss:  22.85978105344111\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:49<01:14,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.65112881734967\n","Test Loss:  20.504169161518803\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:51<01:11,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.815776442410424\n","Test Loss:  22.037786700791912\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:54<01:09,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.92723304592073\n","Test Loss:  20.385131881732377\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:56<01:06,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.875350706337485\n","Test Loss:  19.421615492086858\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:59<01:04,  2.47s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.23149797186488\n","Test Loss:  18.99897941207746\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:01<01:02,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  54.62349358035135\n","Test Loss:  23.084404049644945\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:04<00:59,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  52.64885902090464\n","Test Loss:  21.041439618275035\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:06<00:57,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  52.85998188945814\n","Test Loss:  21.12097173037182\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:09<00:54,  2.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  50.09060124232201\n","Test Loss:  19.728249886793492\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:11<00:56,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  53.46669446575106\n","Test Loss:  19.204053944995394\n","Early stopping with best_loss:  18.99897941207746 and test_loss for this epoch:  19.204053944995394 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.4348306944655795\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:14,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  168.05684199545067\n","Test Loss:  56.190573361935094\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:12,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  106.23943275085185\n","Test Loss:  39.619495535618626\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:09,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  80.87670892302413\n","Test Loss:  34.964057383840554\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:06,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.85566402395489\n","Test Loss:  33.52031292376341\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:04,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  67.69040081952699\n","Test Loss:  32.24946576880757\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<02:00,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  67.97634156461572\n","Test Loss:  33.23982432996854\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<01:57,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.449404105282156\n","Test Loss:  30.374039454589365\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:54,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.457527529855724\n","Test Loss:  28.804248598549748\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:52,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.64475352977752\n","Test Loss:  27.31381245292141\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:49,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.057105822634185\n","Test Loss:  28.58357234855066\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:30<01:46,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.610785922937794\n","Test Loss:  26.756981046142755\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:43,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.65570223607938\n","Test Loss:  25.67943378566997\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:35<01:40,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  54.703027440438746\n","Test Loss:  26.490184684764245\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:38,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.09501590778382\n","Test Loss:  24.852165361808147\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:41<01:35,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.66247837993433\n","Test Loss:  25.903417800553143\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:43<01:32,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  50.9364590960613\n","Test Loss:  26.590437066624872\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:46<01:29,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.73273072560551\n","Test Loss:  24.143453830387443\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:49<01:27,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.60026455260231\n","Test Loss:  24.035057629283983\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:51<01:24,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.581222695152974\n","Test Loss:  23.782013732852647\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:54<01:21,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.67958551226184\n","Test Loss:  23.19891699560685\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:57<01:18,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.12346812800388\n","Test Loss:  23.898623269953532\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:00<01:16,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  47.25274932815228\n","Test Loss:  23.259354549314594\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:02<01:13,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.39863650870393\n","Test Loss:  22.505513437849004\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:05<01:10,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.81076351454249\n","Test Loss:  22.11853891305509\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:08<01:07,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.665517523360904\n","Test Loss:  28.711680043896195\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:10<01:05,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.945810779434396\n","Test Loss:  21.574323526772787\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:13<01:02,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.768133190926164\n","Test Loss:  21.535449416085612\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:16<00:59,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.879252224141965\n","Test Loss:  22.600503557769116\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:18<00:56,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.63137196490425\n","Test Loss:  23.046343460358912\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:21<00:54,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  45.58975466591073\n","Test Loss:  23.533044439274818\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:24<00:51,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  45.04516400399734\n","Test Loss:  21.98411095776828\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:27<00:53,  2.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  43.28955831397616\n","Test Loss:  22.77495953332982\n","Early stopping with best_loss:  21.535449416085612 and test_loss for this epoch:  22.77495953332982 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5142851800597253\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:27,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  501.9151939060539\n","Test Loss:  136.71982035855763\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:25,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  304.17514724330977\n","Test Loss:  113.92167543066898\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:22,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  241.50372943654656\n","Test Loss:  101.78070302784909\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:18,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  220.450787788257\n","Test Loss:  95.57652035908541\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:16,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  203.4634814254241\n","Test Loss:  84.7831972700078\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:14,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  193.75815094279824\n","Test Loss:  80.01435907937412\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:11,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  181.9773645820096\n","Test Loss:  77.02023598429514\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:24<02:07,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  176.04279281652998\n","Test Loss:  78.00474832142936\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:27<02:04,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.5136074029724\n","Test Loss:  71.31442927161697\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:30<02:01,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.74700917763403\n","Test Loss:  70.6226652530022\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:33<01:58,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.754281754751\n","Test Loss:  70.00272384873824\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:36<01:54,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.6990570165217\n","Test Loss:  69.75057362625375\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:39<01:51,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.6369511037483\n","Test Loss:  64.20494535524631\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:42<01:48,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  157.45233385829488\n","Test Loss:  65.016778248013\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:45<01:45,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  147.0860276449239\n","Test Loss:  65.20043988310499\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:48<01:42,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.24371343903476\n","Test Loss:  61.91205867755343\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:51<01:40,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.72388974175556\n","Test Loss:  59.95033230521949\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:54<01:37,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.77561620622873\n","Test Loss:  59.80211423817673\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:57<01:34,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  145.560039647331\n","Test Loss:  67.20155004956177\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:00<01:31,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  144.5842677995679\n","Test Loss:  60.492915990180336\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:03<01:28,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  145.4730784621206\n","Test Loss:  58.83119367566542\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:06<01:26,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  138.22557618640712\n","Test Loss:  57.71844937186688\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:09<01:23,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  143.7582003357238\n","Test Loss:  57.604050954134436\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:13<01:20,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  141.44347486866172\n","Test Loss:  57.98120393780118\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:16<01:16,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  138.6579658460978\n","Test Loss:  58.061018167005386\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:19<01:14,  3.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  136.0821080563619\n","Test Loss:  55.427845794081804\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:22<01:10,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.1026311092137\n","Test Loss:  56.65427332994295\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:25<01:07,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  138.06831315427553\n","Test Loss:  55.31852381990757\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:28<01:04,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  133.84983924294647\n","Test Loss:  60.10532832815079\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:31<01:01,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  137.29368112364318\n","Test Loss:  56.67006134608528\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:34<00:58,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.54856157797622\n","Test Loss:  55.344976682798006\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:37<00:55,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.56184791095438\n","Test Loss:  53.858910201495746\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:40<00:52,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  133.68610951438313\n","Test Loss:  58.41245770963724\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:43<00:48,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.42008633972728\n","Test Loss:  53.51772823717329\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:46<00:45,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  128.03570876567392\n","Test Loss:  54.97771909477888\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:49<00:42,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.6640347755747\n","Test Loss:  53.196752227289835\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:52<00:39,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  131.31621065273066\n","Test Loss:  53.26181045442354\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:56<00:36,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  131.95727484568488\n","Test Loss:  52.743904603645205\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:59<00:33,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  128.73721782350913\n","Test Loss:  59.21996926609427\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [02:02<00:30,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  133.06297672580695\n","Test Loss:  55.66786573390709\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [02:05<00:27,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  129.0859599970281\n","Test Loss:  53.71301130973734\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:08<00:24,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  126.37010665168054\n","Test Loss:  55.517627136578085\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:11<00:25,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  127.81959289763472\n","Test Loss:  55.27191800996661\n","Early stopping with best_loss:  52.743904603645205 and test_loss for this epoch:  55.27191800996661 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.3782622914410574\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:31,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  419.64199304021895\n","Test Loss:  115.26751538360259\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:26,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  276.1919021771755\n","Test Loss:  92.13405535405036\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:23,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  229.54562132444698\n","Test Loss:  82.48024495627033\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:19,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  206.56641095655505\n","Test Loss:  75.41600872090203\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:17,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  197.01553936698474\n","Test Loss:  71.97033606667537\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:13,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  184.6834550097119\n","Test Loss:  65.46925495070172\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:10,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  173.75907892396208\n","Test Loss:  67.20757488440722\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:24<02:07,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.4132427929435\n","Test Loss:  62.253014315647306\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:27<02:04,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  168.75703212834196\n","Test Loss:  58.27349853422493\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:30<02:01,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  162.58171268517617\n","Test Loss:  56.98343891202239\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:33<01:58,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.4217116542859\n","Test Loss:  56.30519736633869\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:36<01:55,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  157.58971421619935\n","Test Loss:  56.52408271841705\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:39<01:52,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.91697046678746\n","Test Loss:  54.3212847171817\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:42<01:49,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.4021948860318\n","Test Loss:  53.02817995523219\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:45<01:45,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.26279194728704\n","Test Loss:  52.30443668784574\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:48<01:42,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  150.6188024522853\n","Test Loss:  57.704372631793376\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:51<01:39,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.1729615299264\n","Test Loss:  51.34018730667594\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:54<01:36,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.72413518768735\n","Test Loss:  51.07018397876527\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:57<01:33,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  143.40061575654545\n","Test Loss:  50.615858313511126\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:00<01:30,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  143.50620175688528\n","Test Loss:  51.163536412641406\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:03<01:27,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  143.42169706546701\n","Test Loss:  49.396902601001784\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:06<01:23,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  143.28833036858123\n","Test Loss:  49.7702628338011\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:09<01:20,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  142.82867077927222\n","Test Loss:  49.346551615628414\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:12<01:17,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  137.1543047669693\n","Test Loss:  52.066325337364106\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:15<01:14,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.08936156559503\n","Test Loss:  49.27361006219871\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:18<01:11,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  137.36673829192296\n","Test Loss:  53.90637840755517\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:21<01:08,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.91666039335541\n","Test Loss:  47.43963837553747\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:24<01:06,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.93940881855087\n","Test Loss:  46.89040026185103\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:27<01:02,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.6942960183951\n","Test Loss:  46.19135165188345\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:30<00:59,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.15039797211648\n","Test Loss:  44.924739892972866\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:33<00:56,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  128.71206676738802\n","Test Loss:  45.89908730718889\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:36<00:54,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  133.21893258037744\n","Test Loss:  46.014538303992595\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:39<00:50,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  133.99832101125503\n","Test Loss:  51.365448630647734\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:42<00:48,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  129.13990737689892\n","Test Loss:  45.29931251134258\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:45<00:45,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  127.49488224409288\n","Test Loss:  44.4111392176128\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:48<00:42,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.16914389727754\n","Test Loss:  43.82926973272697\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:51<00:39,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.8600405814068\n","Test Loss:  43.20127452889574\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:54<00:36,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  129.16000168109895\n","Test Loss:  43.913978894619504\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:57<00:32,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.02457389392657\n","Test Loss:  42.712434242945164\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [02:00<00:29,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  131.94474696007092\n","Test Loss:  42.85519234649837\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [02:03<00:26,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  125.1915268948942\n","Test Loss:  45.152930184529396\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:06<00:23,  2.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  123.91558084177086\n","Test Loss:  44.67025194960297\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:09<00:20,  3.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  122.29975009680493\n","Test Loss:  43.25564142561052\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:12<00:21,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  127.69747460837243\n","Test Loss:  44.91545329988003\n","Early stopping with best_loss:  42.712434242945164 and test_loss for this epoch:  44.91545329988003 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9436695774046645\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:42,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  369.05251624574885\n","Test Loss:  111.5683844598243\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:40,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  246.95593205466866\n","Test Loss:  82.82293667620979\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:36,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  206.25720452878159\n","Test Loss:  70.746702514356\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:33,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  192.0072202454321\n","Test Loss:  66.16988276562188\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:29,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  178.10916922136676\n","Test Loss:  74.69025719820638\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:26,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.5238780620566\n","Test Loss:  59.810429360251874\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:22,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  164.58620683586923\n","Test Loss:  62.75719765308895\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:26<02:19,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  160.21483205264667\n","Test Loss:  59.3124337104673\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:16,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  156.21956081947428\n","Test Loss:  59.81692479245248\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:33<02:13,  3.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.049335013784\n","Test Loss:  52.506653774529696\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:36<02:09,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  147.42811015603365\n","Test Loss:  52.51485682936618\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:39<02:06,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  143.03626473632175\n","Test Loss:  53.2108450208616\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:43<02:02,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.3972448342538\n","Test Loss:  51.70493387596798\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:46<01:59,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.91746603965294\n","Test Loss:  50.903170273057185\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:49<01:55,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  139.0767346576613\n","Test Loss:  51.62234030663967\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:53<01:52,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  138.62771570670884\n","Test Loss:  50.725268774083816\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:56<01:49,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  142.4686520959949\n","Test Loss:  49.11991278329515\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:59<01:46,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  140.86246938665863\n","Test Loss:  50.948906752309995\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:03<01:42,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.57910177463782\n","Test Loss:  49.94685893901624\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:06<01:39,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  136.38324446609477\n","Test Loss:  51.03226966087823\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:09<01:35,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  135.56529852430685\n","Test Loss:  50.4184397701174\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:12<01:40,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  134.71454165395699\n","Test Loss:  49.999955074861646\n","Early stopping with best_loss:  49.11991278329515 and test_loss for this epoch:  49.999955074861646 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0513004100467893\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:40,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  169.37140019237995\n","Test Loss:  46.60904893092811\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:38,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.10462381318212\n","Test Loss:  38.73092105612159\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:37,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  109.19488360360265\n","Test Loss:  31.79695111978799\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:37,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  88.14014881849289\n","Test Loss:  27.103405650239438\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:36,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  74.21058149076998\n","Test Loss:  24.331479499931447\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:04<00:35,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.879398833960295\n","Test Loss:  22.25159827747848\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:05<00:35,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.42377387546003\n","Test Loss:  20.55132465157658\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:34,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.803772419225425\n","Test Loss:  19.648509024293162\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:32,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.003642732743174\n","Test Loss:  20.10121332621202\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:32,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.729546929942444\n","Test Loss:  18.910387483861996\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:08<00:31,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.70507016405463\n","Test Loss:  18.041704385424964\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:09<00:30,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.43102388642728\n","Test Loss:  17.337337827077135\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:10<00:29,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.981909218709916\n","Test Loss:  16.885107772191986\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:11<00:28,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.94351586466655\n","Test Loss:  20.369240593456198\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:28,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.315199700999074\n","Test Loss:  16.634881011443213\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:12<00:27,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.412485290900804\n","Test Loss:  16.312674636254087\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:13<00:26,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.05834556184709\n","Test Loss:  16.797522509586997\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:14<00:25,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.78276542504318\n","Test Loss:  17.688013973995112\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:15<00:25,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.43100962927565\n","Test Loss:  16.15132537903264\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:16<00:24,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.24558918795083\n","Test Loss:  16.33793345396407\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:17<00:23,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.60586595488712\n","Test Loss:  15.32424899021862\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:17<00:23,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.53454211296048\n","Test Loss:  14.81170324969571\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:18<00:22,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.017814450664446\n","Test Loss:  15.154732779716142\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:19<00:21,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.05499701946974\n","Test Loss:  14.683193999808282\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:20<00:20,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.941935075912625\n","Test Loss:  14.641897752182558\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:21<00:19,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.795686822384596\n","Test Loss:  15.143600625917315\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:21<00:18,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.88190102099907\n","Test Loss:  14.375068847788498\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:22<00:17,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.07904707605485\n","Test Loss:  14.495380581822246\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:23<00:16,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.59371380851371\n","Test Loss:  14.768033172469586\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:24<00:16,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.69261742383242\n","Test Loss:  14.509359561197925\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:25<00:15,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.363973293046\n","Test Loss:  13.481861555483192\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:25<00:14,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.244032906834036\n","Test Loss:  14.308369929436594\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:26<00:13,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.57014286762569\n","Test Loss:  13.892043318599463\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:27<00:12,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  37.36103676259518\n","Test Loss:  13.798326916410588\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:28<00:12,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  38.2718581725494\n","Test Loss:  13.850291293172631\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:29<00:11,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.79694065544754\n","Test Loss:  13.36975633178372\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:29<00:10,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.01219669904094\n","Test Loss:  13.887267411570065\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:30<00:09,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.27459988906048\n","Test Loss:  13.436515171895735\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:31<00:08,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.131038765306585\n","Test Loss:  13.741672279254999\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:32<00:08,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.38593374800985\n","Test Loss:  13.661173933069222\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [00:33<00:08,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  36.98547013569623\n","Test Loss:  13.722223301127087\n","Early stopping with best_loss:  13.36975633178372 and test_loss for this epoch:  13.722223301127087 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9915870053585659\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:39,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.95473771169782\n","Test Loss:  43.29121769219637\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:39,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  105.02041048370302\n","Test Loss:  41.11219148337841\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:38,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  83.33545560389757\n","Test Loss:  28.956983538111672\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:37,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.73159042093903\n","Test Loss:  25.461178549798205\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:36,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  57.14433714840561\n","Test Loss:  25.71541184873786\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:04<00:36,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.18251882866025\n","Test Loss:  22.438984372653067\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:05<00:35,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.300202034413815\n","Test Loss:  22.336782071739435\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:34,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.87681960884947\n","Test Loss:  21.43258682428859\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:33,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.111925926757976\n","Test Loss:  21.782731083221734\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:32,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.220931347226724\n","Test Loss:  21.786748458456714\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:09<00:31,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.544283668044955\n","Test Loss:  19.6522796159843\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:09<00:31,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.942216054245364\n","Test Loss:  19.269570663338527\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:10<00:30,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.51337618078105\n","Test Loss:  19.072465566219762\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:11<00:29,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.668262321851216\n","Test Loss:  18.81921381596476\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:28,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.53773786011152\n","Test Loss:  18.27068941819016\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:13<00:27,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.943723527598195\n","Test Loss:  18.48386872012634\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:13<00:27,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.3180549251847\n","Test Loss:  18.07468145014718\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:14<00:26,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.47089681320358\n","Test Loss:  19.431349194346694\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:15<00:25,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.02704116271343\n","Test Loss:  16.8434788902523\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:16<00:24,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.870122199179605\n","Test Loss:  17.24055831087753\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:17<00:24,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.56881574331783\n","Test Loss:  17.970458487514406\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:18<00:23,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  37.47873637586599\n","Test Loss:  16.881944238208234\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:18<00:22,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  37.74681733222678\n","Test Loss:  17.30678552458994\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:19<00:21,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.66665562102571\n","Test Loss:  16.419489162391983\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:20<00:20,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.18988226365764\n","Test Loss:  16.239037804189138\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:21<00:20,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.35681084403768\n","Test Loss:  16.0567402044544\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:22<00:19,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.00003183854278\n","Test Loss:  15.873085353057832\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:23<00:18,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.44097174901981\n","Test Loss:  16.161977693787776\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:23<00:17,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.89420685067307\n","Test Loss:  16.645127282710746\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:24<00:16,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.52338900684845\n","Test Loss:  17.24033330217935\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:25<00:15,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  33.67401448515011\n","Test Loss:  16.28720693977084\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:26<00:16,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  35.120837582915556\n","Test Loss:  16.47297500714194\n","Early stopping with best_loss:  15.873085353057832 and test_loss for this epoch:  16.47297500714194 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.3963043143052973\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:44,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  120.6503073470667\n","Test Loss:  45.52346746250987\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:43,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.48395613022149\n","Test Loss:  27.951657539000735\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:42,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.5468383342959\n","Test Loss:  26.310252777300775\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:41,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.28273456543684\n","Test Loss:  21.413153012515977\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:41,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.7912352506537\n","Test Loss:  20.123193931183778\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:40,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.28544089267962\n","Test Loss:  18.682328447466716\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:39,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.77373659377918\n","Test Loss:  18.403816684149206\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:07<00:38,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.452197877748404\n","Test Loss:  21.285694764228538\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:08<00:37,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.665919960825704\n","Test Loss:  16.969029708532616\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:09<00:36,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.24022402858827\n","Test Loss:  17.137512112036347\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:10<00:35,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.95998643618077\n","Test Loss:  16.37052334868349\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:10<00:34,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.9937071504537\n","Test Loss:  17.985433804569766\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:11<00:33,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.441325001156656\n","Test Loss:  15.922593074850738\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:12<00:32,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.24238051637076\n","Test Loss:  16.272514769574627\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:13<00:31,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.17856265953742\n","Test Loss:  15.700686166295782\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:14<00:31,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.49272949423175\n","Test Loss:  14.652266550576314\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:15<00:30,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.43033954780549\n","Test Loss:  14.939584505278617\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:16<00:29,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.90817482187413\n","Test Loss:  16.29798844800098\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:17<00:28,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.7682595346123\n","Test Loss:  14.504795761895366\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:18<00:27,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.57886070711538\n","Test Loss:  14.52937371272128\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:19<00:26,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.687193102552556\n","Test Loss:  14.276126323034987\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:20<00:25,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.24808421358466\n","Test Loss:  14.391818555537611\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:20<00:24,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.56170018622652\n","Test Loss:  14.086881384719163\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:21<00:23,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.64672197843902\n","Test Loss:  13.794100980449002\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:22<00:22,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.17767049447866\n","Test Loss:  14.095717437914573\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:23<00:21,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.50211408478208\n","Test Loss:  13.144353726645932\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:24<00:20,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.64797514327802\n","Test Loss:  13.460486269308603\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:25<00:19,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.8645328769926\n","Test Loss:  12.956466353789438\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:26<00:19,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.04407385207014\n","Test Loss:  14.375704142730683\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:27<00:18,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.02648462820798\n","Test Loss:  13.940887735050637\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:28<00:17,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.644160015683156\n","Test Loss:  13.45377263519913\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:29<00:16,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  34.24706031358801\n","Test Loss:  13.207980445818976\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:30<00:16,  1.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  31.987780170631595\n","Test Loss:  13.304017913644202\n","Early stopping with best_loss:  12.956466353789438 and test_loss for this epoch:  13.304017913644202 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9767270045355507\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:52,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  259.88243130687624\n","Test Loss:  54.91251378855668\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:51,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.86451973812655\n","Test Loss:  47.82433876412688\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:49,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  111.28109491197392\n","Test Loss:  37.56363530222734\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:48,  2.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  84.46379983704537\n","Test Loss:  29.12093075172743\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:11<01:46,  2.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.64431326917838\n","Test Loss:  26.117590317502618\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:43,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.83066245273221\n","Test Loss:  22.75810059881769\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:16<01:41,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.25407127436483\n","Test Loss:  25.152779558469774\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:18<01:38,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.109622365329415\n","Test Loss:  21.318864022032358\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:21<01:36,  2.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.965910731698386\n","Test Loss:  20.630309980217135\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:23<01:34,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.831402747135144\n","Test Loss:  20.054164693603525\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:25<01:31,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.98749666500953\n","Test Loss:  19.448280801152578\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:28<01:28,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  50.24864951655036\n","Test Loss:  19.72452352786786\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:30<01:26,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.055168394814245\n","Test Loss:  19.21783262034296\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:32<01:23,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.97817358642351\n","Test Loss:  21.54878248400928\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:35<01:21,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.68166644341545\n","Test Loss:  18.64151337117073\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:37<01:19,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.32478471685317\n","Test Loss:  18.478712716663722\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:39<01:17,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.846064923884114\n","Test Loss:  17.597183954407228\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:42<01:14,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.06879004917573\n","Test Loss:  17.145937662076904\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:44<01:12,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.58051321042876\n","Test Loss:  16.96187391030253\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:46<01:10,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.61807763627439\n","Test Loss:  16.760148596891668\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:49<01:08,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.619130461942405\n","Test Loss:  16.469025378115475\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:51<01:06,  2.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.22922806930728\n","Test Loss:  16.40726534697751\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:54<01:03,  2.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.460208286269335\n","Test Loss:  17.87500129858381\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:56<01:01,  2.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.69101591879735\n","Test Loss:  16.23494021751685\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:58<00:58,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.25421526108403\n","Test Loss:  18.31165802673786\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:01<00:56,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.50006281824608\n","Test Loss:  15.750776905741077\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:03<00:53,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.71277894200466\n","Test Loss:  16.520069367514225\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:05<00:51,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.49219000483572\n","Test Loss:  17.02280105065438\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:07<00:49,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.12987663515378\n","Test Loss:  17.905275391298346\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:10<00:46,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.09445637234603\n","Test Loss:  15.651301328267436\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:12<00:44,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.93191522322013\n","Test Loss:  16.928863478184212\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:14<00:41,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.5248188025289\n","Test Loss:  15.618216965638567\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:17<00:39,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.56065757520264\n","Test Loss:  15.477482831280213\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:19<00:37,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.264614592757425\n","Test Loss:  16.686203919671243\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:21<00:34,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.59856790055346\n","Test Loss:  14.816681364434771\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:24<00:32,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.33464548073243\n","Test Loss:  14.523924286593683\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:26<00:30,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.18254015839193\n","Test Loss:  17.064407001889776\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:28<00:27,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.387110193638364\n","Test Loss:  14.768775651726173\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:31<00:25,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.18040866522642\n","Test Loss:  15.507644258323126\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:33<00:23,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  39.63017877272796\n","Test Loss:  14.576467887265608\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:35<00:23,  2.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  40.43977664154954\n","Test Loss:  15.867167137643264\n","Early stopping with best_loss:  14.523924286593683 and test_loss for this epoch:  15.867167137643264 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.346748004601581\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:52,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  184.29855635017157\n","Test Loss:  56.6693548837211\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:50,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  113.3750723322155\n","Test Loss:  41.11526170105208\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:06<01:48,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.81226889556274\n","Test Loss:  30.47482276696246\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:46,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.50542838446563\n","Test Loss:  25.3227170080645\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:11<01:44,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.231882102176314\n","Test Loss:  25.287777129095048\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:13<01:41,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.55242920538876\n","Test Loss:  23.39152762037702\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:16<01:40,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.10697316081496\n","Test Loss:  22.719112896957085\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:18<01:38,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.90703516913345\n","Test Loss:  23.170211469521746\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:20<01:35,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.75326193476212\n","Test Loss:  21.8652921282046\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:23<01:32,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.500905426219106\n","Test Loss:  21.342951216443907\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:25<01:29,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.555110960965976\n","Test Loss:  22.38627769978484\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:27<01:27,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  49.34711607065401\n","Test Loss:  22.503735990903806\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:30<01:25,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.06040915043559\n","Test Loss:  20.34902566362871\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:32<01:22,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.44472701699124\n","Test Loss:  19.60809717400116\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:34<01:20,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.72328384636785\n","Test Loss:  21.485650455695577\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:36<01:17,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.10336888639722\n","Test Loss:  18.75284686233499\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:39<01:15,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.28407162774238\n","Test Loss:  19.676761263632216\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:41<01:13,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.79502280140878\n","Test Loss:  19.048351426317822\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:43<01:11,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.356579585932195\n","Test Loss:  18.221253090625396\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:46<01:08,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.2623804048053\n","Test Loss:  20.143794352086843\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:48<01:06,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.61226111277938\n","Test Loss:  17.887576427863678\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:50<01:04,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.81321327754995\n","Test Loss:  17.90595123631647\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:53<01:02,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.682328674331075\n","Test Loss:  17.713770685630152\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:55<00:59,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.56425419164589\n","Test Loss:  18.388428860591375\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:57<00:57,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.23112595258863\n","Test Loss:  17.43879749192274\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:59<00:55,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.371228824573336\n","Test Loss:  17.22648495127214\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:02<00:53,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.27777436794713\n","Test Loss:  16.75572832916805\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:04<00:50,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.55068316042889\n","Test Loss:  17.23072338735801\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:06<00:48,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.20554590559914\n","Test Loss:  16.13802333199419\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:09<00:46,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.98823647055542\n","Test Loss:  16.89908613706939\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:11<00:44,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.03845387905312\n","Test Loss:  16.748906766151777\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:13<00:41,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.28948086456512\n","Test Loss:  16.071037619083654\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:16<00:39,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.745312153114355\n","Test Loss:  16.754922642634483\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:18<00:36,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.79557322872279\n","Test Loss:  15.404588978854008\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:20<00:34,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.96194723498775\n","Test Loss:  16.281422592699528\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:22<00:31,  2.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.31064672514913\n","Test Loss:  15.568771557344007\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:25<00:29,  2.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  37.41094321012497\n","Test Loss:  15.407217276340816\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:27<00:27,  2.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.63746517637628\n","Test Loss:  15.533818452997366\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:29<00:25,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.57647213761811\n","Test Loss:  15.231014711520402\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:32<00:22,  2.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.26284316935926\n","Test Loss:  15.765282993561414\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:34<00:20,  2.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  35.42178544669878\n","Test Loss:  15.393210791517049\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [01:36<00:18,  2.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  34.57002210392966\n","Test Loss:  15.660290171814268\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:38<00:16,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  34.91272859041055\n","Test Loss:  15.919898203661432\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [01:41<00:16,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  34.524783983972156\n","Test Loss:  15.988394608953968\n","Early stopping with best_loss:  15.231014711520402 and test_loss for this epoch:  15.988394608953968 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.37724945041833247\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:05,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.17888756631874\n","Test Loss:  41.12194806692423\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:03,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  96.23762279446237\n","Test Loss:  21.017917320888955\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:01,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.25470281561138\n","Test Loss:  17.960175304091536\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:59,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.65962952171685\n","Test Loss:  18.683067664154805\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:56,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.72941882361192\n","Test Loss:  17.04678982438054\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:53,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.204328473395435\n","Test Loss:  15.8343626948772\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:50,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.54673217411619\n","Test Loss:  16.004786058329046\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:48,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.45248857536353\n","Test Loss:  14.247335118619958\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:45,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.83539014062262\n","Test Loss:  14.440695012774086\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:43,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.66395318895229\n","Test Loss:  14.032244024710963\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:40,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.29727437029942\n","Test Loss:  15.646533055230975\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:38,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.71562789667223\n","Test Loss:  13.594774571654852\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:35,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.635827298334334\n","Test Loss:  13.247643826209242\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:36<01:33,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.9014220534591\n","Test Loss:  14.241244414937682\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:38<01:30,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.304325190823874\n","Test Loss:  13.07662460958818\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:27,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.71214345499175\n","Test Loss:  13.679850490298122\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:43<01:25,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.30144696010393\n","Test Loss:  13.379134812246775\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:46<01:22,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  43.9460230814002\n","Test Loss:  13.474595230421983\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:49<01:20,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.90763104573125\n","Test Loss:  12.469411902071442\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:51<01:17,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  39.46105683443602\n","Test Loss:  13.095976565382443\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:54<01:14,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  44.04278728735517\n","Test Loss:  13.058536397933494\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:56<01:12,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  42.1570088203589\n","Test Loss:  12.517551208497025\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:59<01:09,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  41.44880998667213\n","Test Loss:  12.824677646480268\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:01<01:12,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  41.02276632151916\n","Test Loss:  12.612030356016476\n","Early stopping with best_loss:  12.469411902071442 and test_loss for this epoch:  12.612030356016476 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.2963463416087861\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:18,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  479.57512201555073\n","Test Loss:  140.5592108053388\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:17,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  302.6848930339329\n","Test Loss:  113.85973962326534\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:14,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  245.83565781731158\n","Test Loss:  98.20256945420988\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:11,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  218.9864301495254\n","Test Loss:  90.03141218482051\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:08,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  200.8488783768844\n","Test Loss:  83.76455187384272\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:06,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  189.07146875560284\n","Test Loss:  78.15336446010042\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:03,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  181.8616140865197\n","Test Loss:  77.92580068821553\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:22<02:00,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  172.45954315771814\n","Test Loss:  73.70739154992043\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:25<01:57,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  167.20996179326903\n","Test Loss:  75.41168538591592\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:28<01:55,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  158.94341580261244\n","Test Loss:  76.0438086031645\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:31<01:53,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  153.76103656808846\n","Test Loss:  68.32287368434481\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:34<01:50,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  152.77427094517043\n","Test Loss:  68.5767962699756\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:37<01:47,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  149.66764916601824\n","Test Loss:  68.35586610884639\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:40<01:44,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.56468774698442\n","Test Loss:  67.48625668053865\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:43<01:41,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.12677984044421\n","Test Loss:  64.56774633798341\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:46<01:37,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  140.87478160811588\n","Test Loss:  65.5362411160022\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:48<01:34,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  139.56297851435374\n","Test Loss:  65.74477956307237\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:51<01:32,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  135.72648271470098\n","Test Loss:  65.04609706974588\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:54<01:29,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.69360345351743\n","Test Loss:  64.4896311169141\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:57<01:26,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  135.8447742391727\n","Test Loss:  63.13256823428674\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:00<01:23,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.9750438136689\n","Test Loss:  62.62582215415023\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:03<01:21,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  131.17192299023736\n","Test Loss:  60.33695889177034\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:06<01:18,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  133.212813664024\n","Test Loss:  62.59795082309574\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:09<01:15,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  128.95217234241136\n","Test Loss:  60.82068584894296\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:12<01:12,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  130.8656936287298\n","Test Loss:  58.079190318072506\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:14<01:09,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  124.12874558987096\n","Test Loss:  58.593316063605016\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:17<01:06,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  128.25027837402013\n","Test Loss:  60.51692939217901\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:20<01:03,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  128.97538934656768\n","Test Loss:  62.54534563966445\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:23<01:00,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  119.4836849058338\n","Test Loss:  56.14603923592949\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:26<00:57,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  123.69005097117042\n","Test Loss:  56.63944596092915\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:29<00:54,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.75614997386583\n","Test Loss:  55.84302780686994\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:32<00:52,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  123.61047035944648\n","Test Loss:  56.22212135611335\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:35<00:49,  2.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  117.18057207312086\n","Test Loss:  54.46922459459165\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:38<00:46,  2.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  124.7942082954105\n","Test Loss:  58.77702987464727\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:41<00:43,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  121.27559701149585\n","Test Loss:  54.62031637446489\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:43<00:40,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  125.48633664904628\n","Test Loss:  56.894126477855025\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [01:46<00:37,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  121.25499907466292\n","Test Loss:  54.85523111450311\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [01:49<00:34,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  122.35081484279362\n","Test Loss:  53.1685814645607\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [01:52<00:31,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  120.62138505047187\n","Test Loss:  55.08990388462553\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 40/50 [01:55<00:29,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  118.07499458140228\n","Test Loss:  53.06968306162162\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 41/50 [01:58<00:26,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  121.15741435658128\n","Test Loss:  54.064301786231226\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 42/50 [02:01<00:23,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  122.25627912161872\n","Test Loss:  52.25915275166335\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 43/50 [02:04<00:20,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  119.67324568284675\n","Test Loss:  54.850424309115624\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 44/50 [02:07<00:17,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  113.36370159231592\n","Test Loss:  51.33394047780894\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 45/50 [02:09<00:14,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  120.19046211335808\n","Test Loss:  51.44446670848993\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 46/50 [02:12<00:11,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  117.69740113196895\n","Test Loss:  53.53984511029557\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 47/50 [02:15<00:08,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  113.77608852600679\n","Test Loss:  51.741029628770775\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [02:18<00:05,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  115.57726880180417\n","Test Loss:  52.17195716823335\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 48/50 [02:21<00:05,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  115.05034011031967\n","Test Loss:  52.64868933230173\n","Early stopping with best_loss:  51.33394047780894 and test_loss for this epoch:  52.64868933230173 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.3392117744942045\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:19,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  404.44699147250503\n","Test Loss:  109.02492827200331\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:17,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  264.2911083518993\n","Test Loss:  82.19815229461528\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:14,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  218.30539262329694\n","Test Loss:  70.82483867980773\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:11,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  200.90505625749938\n","Test Loss:  65.97037961991737\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:10,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  188.27254546876065\n","Test Loss:  62.48244796282961\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:07,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  183.5292619781685\n","Test Loss:  57.85365796776023\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:03,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  167.49707759119337\n","Test Loss:  58.89589339654776\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:22<01:59,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  168.55200218898244\n","Test Loss:  63.63541757676285\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:25<01:57,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.49330210185144\n","Test Loss:  55.791877660667524\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:28<01:54,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.37288990287925\n","Test Loss:  54.15534476400353\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:31<01:52,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  150.54634873801842\n","Test Loss:  52.267230516445125\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:34<01:49,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.15132532309508\n","Test Loss:  50.53400279596099\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:37<01:46,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  146.27547050447902\n","Test Loss:  54.08139075434883\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:40<01:43,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.66563017637236\n","Test Loss:  49.71115427778568\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:42<01:39,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  145.13864846728393\n","Test Loss:  47.3680161726661\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:45<01:36,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  140.96406323552947\n","Test Loss:  55.50111177621875\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:48<01:33,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  137.82742029172368\n","Test Loss:  57.111293571972055\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:51<01:31,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.53507431485923\n","Test Loss:  56.46261419611983\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:54<01:27,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  138.1408590769861\n","Test Loss:  48.8186219134368\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:57<01:33,  3.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  135.83122916187858\n","Test Loss:  50.31402538673137\n","Early stopping with best_loss:  47.3680161726661 and test_loss for this epoch:  50.31402538673137 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.2867860806553317\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:39,  3.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  343.0632292306982\n","Test Loss:  111.49314752500504\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:35,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  231.87094904948026\n","Test Loss:  89.165172494133\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:30,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  200.2613908740459\n","Test Loss:  71.60443299848703\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:27,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  180.7710416271584\n","Test Loss:  66.78101123427041\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:25,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  169.20973248843802\n","Test Loss:  66.9618918702181\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:21,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  162.75138470710954\n","Test Loss:  59.070003036089474\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:17,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.97745741764084\n","Test Loss:  55.843815232263296\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:14,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.83116993802832\n","Test Loss:  54.82960551872384\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:28<02:11,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.00683269216097\n","Test Loss:  53.19285090272024\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:32<02:07,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.86100476724096\n","Test Loss:  51.49709153943695\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:35<02:04,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  139.0517581536551\n","Test Loss:  57.527861589042004\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:38<02:01,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  138.58183613355504\n","Test Loss:  51.55076060659485\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:41<01:58,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  136.1287896805443\n","Test Loss:  51.31236145965522\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:44<01:54,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  129.30323073040927\n","Test Loss:  52.64441948199237\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:47<01:51,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  131.02922770910664\n","Test Loss:  50.029598331137095\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:51<01:48,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  129.76171445060754\n","Test Loss:  51.07711935249972\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:54<01:44,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  127.84052555687958\n","Test Loss:  54.53613768419018\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:57<01:41,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  125.40041897303308\n","Test Loss:  51.353990774281556\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:00<01:38,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  123.98178463650402\n","Test Loss:  49.27291570749367\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:03<01:35,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  122.84287770136143\n","Test Loss:  56.77030707143422\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:06<01:31,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  122.89981438277755\n","Test Loss:  47.021675232681446\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:10<01:29,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  117.69539465219714\n","Test Loss:  49.252053739794064\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:13<01:26,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  118.4173238207004\n","Test Loss:  51.70927447392023\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:16<01:22,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  116.15888338338118\n","Test Loss:  51.03645754256286\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:19<01:20,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  116.36543865135172\n","Test Loss:  55.92807981118676\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:23<01:23,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  114.08800268181949\n","Test Loss:  47.855268774175784\n","Early stopping with best_loss:  47.021675232681446 and test_loss for this epoch:  47.855268774175784 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1381555908428531\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:53,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.75883967801929\n","Test Loss:  36.14424785156734\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:51,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  93.0546672521159\n","Test Loss:  24.00700481736567\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:50,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.113117643632\n","Test Loss:  18.538883841887582\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:49,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.82582089188509\n","Test Loss:  18.506053185119526\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:48,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  52.14748227223754\n","Test Loss:  18.862803003983572\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:47,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.313812256092206\n","Test Loss:  16.049564954038942\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:45,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.533440723316744\n","Test Loss:  17.130557780328672\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:45,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.44321521797974\n","Test Loss:  14.97202010161709\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:44,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.89944417454535\n","Test Loss:  18.829127434873953\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:42,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.67642450128915\n","Test Loss:  13.815072919416707\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:41,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.33511093282141\n","Test Loss:  14.992496106744511\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:12<00:41,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.8328817000729\n","Test Loss:  16.3664733923506\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:14<00:40,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  42.84603950550081\n","Test Loss:  14.726887527678628\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:15<00:38,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  43.06199101090897\n","Test Loss:  13.948863186989911\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:16<00:41,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  43.47021049913019\n","Test Loss:  14.475464711489622\n","Early stopping with best_loss:  13.815072919416707 and test_loss for this epoch:  14.475464711489622 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7472765190803301\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:52,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.34502079617232\n","Test Loss:  30.72010337887332\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:51,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  71.59385142452084\n","Test Loss:  21.178133660869207\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:50,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  59.58047558774706\n","Test Loss:  29.794080096995458\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:49,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.85355695604812\n","Test Loss:  17.969341738062212\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:48,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.67698599497089\n","Test Loss:  16.760181786725298\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:47,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.98646425700281\n","Test Loss:  15.564354821806774\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:46,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.35543202259578\n","Test Loss:  18.96309743472375\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:45,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.1945079555735\n","Test Loss:  14.806395877851173\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:44,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.36868883424904\n","Test Loss:  17.058649172540754\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:42,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  45.044410177797545\n","Test Loss:  14.84560912832967\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:41,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  43.59171327599324\n","Test Loss:  15.294273667561356\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:12<00:40,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.76708457618952\n","Test Loss:  14.231719516974408\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:13<00:39,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.644261726760305\n","Test Loss:  14.888775132945739\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:15<00:38,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.27759301115293\n","Test Loss:  15.385197785246419\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:16<00:37,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  43.61942426126916\n","Test Loss:  16.738119322340935\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:17<00:36,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.67028444411699\n","Test Loss:  13.9333138197253\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:18<00:35,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.70334487443324\n","Test Loss:  14.868940231855959\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:19<00:34,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.493850701255724\n","Test Loss:  16.638829047617037\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:20<00:33,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.85770608719031\n","Test Loss:  13.858534700528253\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:21<00:32,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.63950273109367\n","Test Loss:  14.835701315256301\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:22<00:31,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.835345422674436\n","Test Loss:  15.245532786473632\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:23<00:29,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.38614223210607\n","Test Loss:  14.935383203381207\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:24<00:28,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.45388742201612\n","Test Loss:  13.360264925344381\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:25<00:27,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.08290840651898\n","Test Loss:  13.956335351802409\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:26<00:26,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.92363470309647\n","Test Loss:  14.198504909640178\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:27<00:25,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  39.46558075607754\n","Test Loss:  14.799430955201387\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:29<00:24,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.54416268542991\n","Test Loss:  15.141705380985513\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:30<00:23,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.77528645150596\n","Test Loss:  13.109899043454789\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:31<00:22,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.07458280422725\n","Test Loss:  13.350692231062567\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:32<00:21,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.761532100324985\n","Test Loss:  12.819425720721483\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:33<00:20,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.78099849424325\n","Test Loss:  12.75498558988329\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:34<00:19,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.02530265919631\n","Test Loss:  13.15922206651885\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:35<00:18,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.84708810708253\n","Test Loss:  14.053930321126245\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:36<00:17,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.037334078224376\n","Test Loss:  14.301268309529405\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:37<00:16,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.32875651028007\n","Test Loss:  12.491674420540221\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:38<00:15,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  35.19782987746294\n","Test Loss:  14.49709291337058\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 37/50 [00:39<00:14,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.33990831056144\n","Test Loss:  12.662090359866852\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 38/50 [00:40<00:12,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  34.428399158408865\n","Test Loss:  12.598567724227905\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:42<00:11,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.48034840476612\n","Test Loss:  14.35469811715302\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 39/50 [00:43<00:12,  1.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  34.42293289292138\n","Test Loss:  12.735316517588217\n","Early stopping with best_loss:  12.491674420540221 and test_loss for this epoch:  12.735316517588217 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7332741019263811\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:57,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  106.25432728603482\n","Test Loss:  27.851041853777133\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:56,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.82403811486438\n","Test Loss:  25.299553875345737\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:55,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.32392334606266\n","Test Loss:  22.09305130879511\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:53,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.90935785043985\n","Test Loss:  21.22800193337025\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:52,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.40446551766945\n","Test Loss:  21.071323382901028\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:51,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.887990580289625\n","Test Loss:  20.349650353891775\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:08<00:50,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.57973084563855\n","Test Loss:  19.962283433647826\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:09<00:48,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.59144719509641\n","Test Loss:  21.908953785925405\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:10<00:47,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  41.45313914777944\n","Test Loss:  21.91195811983198\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:11<00:46,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.866653662582394\n","Test Loss:  18.477084473444847\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:12<00:45,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.898814242566004\n","Test Loss:  19.34471071846201\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:44,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.64759009424597\n","Test Loss:  17.93998568004463\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:15<00:42,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.282723847660236\n","Test Loss:  18.124313568347134\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:16<00:41,  1.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.87691303784959\n","Test Loss:  17.49318106859573\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:17<00:40,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.33329544001026\n","Test Loss:  17.554626517521683\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:18<00:39,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.652689392794855\n","Test Loss:  18.486795795004582\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:19<00:38,  1.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  34.4308024009224\n","Test Loss:  18.199809029116295\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:20<00:36,  1.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.167984124447685\n","Test Loss:  18.56976533890702\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:22<00:39,  1.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  37.063581565686036\n","Test Loss:  18.06196132733021\n","Early stopping with best_loss:  17.49318106859573 and test_loss for this epoch:  18.06196132733021 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9967164462130529\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:06,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  279.6863590464927\n","Test Loss:  56.218280444154516\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:03,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  142.67159759392962\n","Test Loss:  53.81162898265757\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:00,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  119.6848040423356\n","Test Loss:  34.16847302266979\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:58,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  104.8121450120234\n","Test Loss:  32.17077255103504\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:56,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  100.51974931923905\n","Test Loss:  30.109542000107467\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:53,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  95.3743147685309\n","Test Loss:  30.460681673401268\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:50,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  94.09903977735667\n","Test Loss:  29.843710565415677\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:48,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  84.8479048483423\n","Test Loss:  27.927034684631508\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:45,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  91.62981922191102\n","Test Loss:  28.140743416239275\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:43,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  88.12071977529558\n","Test Loss:  27.277930506388657\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:40,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  89.19573706478695\n","Test Loss:  26.545647925697267\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:38,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  84.57318609458162\n","Test Loss:  25.919295173109276\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:35,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  83.01522929716157\n","Test Loss:  26.622540705953725\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:36<01:33,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  82.35158743476495\n","Test Loss:  26.495244382880628\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:38<01:30,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.5307006338262\n","Test Loss:  25.851848625869025\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:27,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  79.97665284998948\n","Test Loss:  27.067880779737607\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:43<01:25,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  80.25145653716754\n","Test Loss:  26.637004569085548\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:46<01:23,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.36660398717504\n","Test Loss:  25.287511895992793\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:49<01:20,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  78.82409609443857\n","Test Loss:  25.79962893310585\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:51<01:17,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.68276194517966\n","Test Loss:  24.97642297213315\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:54<01:14,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  79.05229672064888\n","Test Loss:  26.519852176425047\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:56<01:12,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  72.65892244450515\n","Test Loss:  31.93406533781672\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:59<01:09,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.63453061511973\n","Test Loss:  23.917355639801826\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:01<01:06,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  77.42752599911182\n","Test Loss:  28.459645979921333\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:04<01:03,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  79.41365386845428\n","Test Loss:  28.686486947874073\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:07<01:01,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.39977964153513\n","Test Loss:  22.642412175162463\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:09<00:59,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  75.91561072229524\n","Test Loss:  23.65876409507473\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:12<00:56,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  73.77555564470822\n","Test Loss:  24.208966207981575\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:14<00:54,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  75.00182796691661\n","Test Loss:  25.579014208633453\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:17<00:51,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  77.11863857271965\n","Test Loss:  25.679826670559123\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:19<00:53,  2.67s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  75.1855407244002\n","Test Loss:  24.508327711868333\n","Early stopping with best_loss:  22.642412175162463 and test_loss for this epoch:  24.508327711868333 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.49581997137690825\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:04,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  218.7666461286135\n","Test Loss:  46.76696107088355\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:02,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  117.97815756301861\n","Test Loss:  35.41602302208776\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:59,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  103.24707762838807\n","Test Loss:  36.87969195336336\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:57,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  95.31359785760287\n","Test Loss:  31.58751112408936\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:55,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  93.28645491230418\n","Test Loss:  31.09039082773961\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:51,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  89.40303136559669\n","Test Loss:  32.2727648197324\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:49,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  87.76682916798745\n","Test Loss:  28.987812747844146\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:47,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  83.05614456138574\n","Test Loss:  29.52204544848064\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:45,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  83.80336176865967\n","Test Loss:  27.01746462797746\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:42,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.97329438329325\n","Test Loss:  25.33742391850683\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:39,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  82.59672021667939\n","Test Loss:  31.456112297135405\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:37,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  81.47535443911329\n","Test Loss:  25.56911261321511\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:33<01:35,  2.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  74.93959255784284\n","Test Loss:  24.12812955584377\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:35<01:33,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  77.7506411182112\n","Test Loss:  26.229237803490832\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:38<01:29,  2.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  78.69607392442413\n","Test Loss:  27.88462546048686\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:41<01:27,  2.56s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  73.7537502435589\n","Test Loss:  32.119483659858815\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:43<01:24,  2.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  75.0077675456414\n","Test Loss:  24.174323879298754\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:46<01:29,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  70.86825955339009\n","Test Loss:  28.995691767369863\n","Early stopping with best_loss:  24.12812955584377 and test_loss for this epoch:  28.995691767369863 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5590327473783294\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:15,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.77322279126383\n","Test Loss:  47.742940944910515\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:12,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  114.45203953282908\n","Test Loss:  36.127510705118766\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:09,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  98.07182152295718\n","Test Loss:  36.65975806687493\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:06,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  96.4999293606379\n","Test Loss:  34.91262430755887\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:05,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  86.2826535293134\n","Test Loss:  39.67387926997617\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<02:02,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  87.323138061387\n","Test Loss:  28.889925575844245\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<01:59,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  86.71062352412264\n","Test Loss:  32.69265340856509\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:22<01:56,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.03038228614605\n","Test Loss:  28.487010791082866\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:53,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  78.60891626524972\n","Test Loss:  30.384416400105692\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:50,  2.77s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  80.49079716391861\n","Test Loss:  30.273730581975542\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:30<01:47,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  79.17249214008916\n","Test Loss:  32.053102233214304\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:33<01:45,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  77.58452251119888\n","Test Loss:  34.01867072447203\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:36<01:43,  2.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  74.65276117899339\n","Test Loss:  27.087428294849815\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:40,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.30925004879828\n","Test Loss:  27.028242452826817\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:41<01:36,  2.76s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.58573817260913\n","Test Loss:  26.76102379686199\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:44<01:33,  2.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  74.93821209162707\n","Test Loss:  27.286322468688013\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:47<01:32,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.30045483530557\n","Test Loss:  26.121543896006187\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:50<01:30,  2.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  74.767803600349\n","Test Loss:  28.48258233795059\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:52<01:27,  2.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  72.38331622057012\n","Test Loss:  26.740480870503234\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:55<01:24,  2.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.04741265370103\n","Test Loss:  23.856765494900174\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:58<01:21,  2.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  69.70506063758512\n","Test Loss:  32.56052463254309\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:01<01:18,  2.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  72.90505235505407\n","Test Loss:  27.422598142176867\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:04<01:15,  2.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.35541087895399\n","Test Loss:  23.190643357578665\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:06<01:12,  2.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  70.9076468568528\n","Test Loss:  30.511360706033884\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:09<01:09,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  74.48862151001231\n","Test Loss:  25.76094836962875\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:12<01:07,  2.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  69.63975765544455\n","Test Loss:  30.254503800169914\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:15<01:04,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.96668042882811\n","Test Loss:  22.540983600280015\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:18<01:01,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  66.85750754072797\n","Test Loss:  22.88358208682621\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:20<00:58,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  68.29887008690275\n","Test Loss:  24.529565284232376\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:23<00:55,  2.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.26173787507287\n","Test Loss:  22.360886661044788\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  69.61148001853144\n","Test Loss:  23.304377383130486\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:29<00:50,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  67.51415164535865\n","Test Loss:  24.724285734759178\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:31<00:47,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  65.8655553155404\n","Test Loss:  23.40078565402655\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:34<00:44,  2.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  64.48842092399718\n","Test Loss:  22.491187039151555\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:37<00:45,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  63.440638101281365\n","Test Loss:  29.169647185015492\n","Early stopping with best_loss:  22.360886661044788 and test_loss for this epoch:  29.169647185015492 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.42267569392369736\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:31,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  395.1533665275201\n","Test Loss:  113.5711919827736\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:29,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  230.8741119862534\n","Test Loss:  90.37646097160177\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:28,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  201.7231720435666\n","Test Loss:  81.53358175007452\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:25,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  191.35549515861203\n","Test Loss:  78.23673818894895\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:22,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  178.6027194907074\n","Test Loss:  76.17459870572202\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:19,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  172.92717397556407\n","Test Loss:  71.20458269794472\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:16,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  171.59717434161576\n","Test Loss:  72.89007972902618\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:13,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.72881424973457\n","Test Loss:  64.20695894712117\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:28<02:09,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.6120743820211\n","Test Loss:  63.02810624415724\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:31<02:07,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  164.93392172563472\n","Test Loss:  66.93502025137423\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:34<02:03,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  163.5371996538015\n","Test Loss:  60.27091851271689\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:37<02:00,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.88702473026933\n","Test Loss:  58.5167041545501\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:41<01:57,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  158.6315512463043\n","Test Loss:  62.56220449344255\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:44<01:54,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  154.47855999867897\n","Test Loss:  61.45510713485419\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:47<01:51,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.4278791412653\n","Test Loss:  56.44364232721273\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:50<01:48,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  150.90651764158974\n","Test Loss:  55.63443887516041\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:53<01:44,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  151.97299041048973\n","Test Loss:  55.99594601773424\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:57<01:41,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  149.46323173860583\n","Test Loss:  54.52854265310452\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:00<01:38,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.69453025434632\n","Test Loss:  53.17488072106789\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:03<01:34,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  148.12352958339034\n","Test Loss:  55.893826310755685\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:06<01:31,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  147.86880907337763\n","Test Loss:  54.64415883598849\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:09<01:28,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  143.63274159422144\n","Test Loss:  56.78533586265985\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:12<01:25,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  146.4712737564696\n","Test Loss:  54.94014426667127\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:16<01:22,  3.16s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.48353066464188\n","Test Loss:  52.45610459236195\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:19<01:19,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  143.68139161216095\n","Test Loss:  56.162835692986846\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:22<01:16,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.86241028964287\n","Test Loss:  52.3854018637503\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:25<01:13,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.46575647921418\n","Test Loss:  50.74819965190545\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:28<01:10,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  140.0690493817383\n","Test Loss:  59.499829231004696\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:32<01:07,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.38359846659296\n","Test Loss:  53.32232668856159\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:35<01:03,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  137.73769604886184\n","Test Loss:  51.591005694674095\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [01:38<01:00,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  139.64201506390236\n","Test Loss:  53.2204858007899\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [01:41<00:57,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.76380076032365\n","Test Loss:  49.165711964684306\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [01:44<00:54,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  138.66722606070107\n","Test Loss:  61.88230293733068\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [01:47<00:50,  3.17s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  133.40012299257796\n","Test Loss:  54.935542662395164\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [01:51<00:47,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  132.38251030276297\n","Test Loss:  49.547094701993046\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:54<00:44,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  134.84526348797954\n","Test Loss:  50.62964077363722\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [01:57<00:45,  3.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  126.64608548715478\n","Test Loss:  49.31014957340085\n","Early stopping with best_loss:  49.165711964684306 and test_loss for this epoch:  49.31014957340085 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.068523130218441\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:32,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  360.4657776206732\n","Test Loss:  84.57975108572282\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:29,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  227.07644037762657\n","Test Loss:  70.09706118321628\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:26,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  198.12660511609283\n","Test Loss:  55.61338424292626\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:23,  3.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  187.29142470733495\n","Test Loss:  55.226313941704575\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:21,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  179.5753693957231\n","Test Loss:  52.741234716493636\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:17,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  172.30008157389238\n","Test Loss:  56.237099084537476\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:14,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.7564443743904\n","Test Loss:  51.15751131376601\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:11,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  167.10567714710487\n","Test Loss:  49.95520953601226\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:28<02:08,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  167.03467006102437\n","Test Loss:  55.92540646402631\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:31<02:06,  3.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  161.9004263059469\n","Test Loss:  55.553125047910726\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:34<02:02,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  161.42584108910523\n","Test Loss:  57.20909824455157\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:37<01:59,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.16189158213092\n","Test Loss:  48.32395765816909\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:40<01:55,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  153.03034238974215\n","Test Loss:  53.11075048765633\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:43<01:53,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  153.34568711431348\n","Test Loss:  49.67875631985953\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:47<01:49,  3.14s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  150.6113655398949\n","Test Loss:  54.12624474649783\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:50<01:46,  3.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  147.90686320251552\n","Test Loss:  51.96484982498805\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:53<01:53,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  145.81155964627396\n","Test Loss:  49.16625291551463\n","Early stopping with best_loss:  48.32395765816909 and test_loss for this epoch:  49.16625291551463 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0639582629153714\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:46,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  312.7300744005479\n","Test Loss:  91.70232467446476\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:42,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  213.92695952637587\n","Test Loss:  80.73560280387755\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:10<02:39,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  190.90933789894916\n","Test Loss:  64.21949863305781\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:36,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  185.5196521806938\n","Test Loss:  60.338265877682716\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:32,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  172.57882018137025\n","Test Loss:  62.46621525916271\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:20<02:28,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  167.98787074931897\n","Test Loss:  61.67170293236268\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:25,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  167.4121731959749\n","Test Loss:  52.516689053270966\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:27<02:22,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  159.55119548458606\n","Test Loss:  51.388217432424426\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:30<02:18,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  156.74155295168748\n","Test Loss:  55.95992752671009\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:33<02:15,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.37443398140022\n","Test Loss:  49.88256999832811\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:37<02:12,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  157.33176343992818\n","Test Loss:  54.125645367312245\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:40<02:09,  3.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.34823037072783\n","Test Loss:  48.94622012748732\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:44<02:06,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  147.3406206497457\n","Test Loss:  53.35588180972263\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:47<02:02,  3.41s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.08556408068398\n","Test Loss:  48.536288367642555\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:50<01:58,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  147.9752708771848\n","Test Loss:  51.48309286177391\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:54<01:54,  3.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  146.4919207142084\n","Test Loss:  57.2216592541663\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:57<01:51,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  144.56291177490493\n","Test Loss:  51.537839363736566\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:01<01:48,  3.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  146.95929470297415\n","Test Loss:  52.77456808646093\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [01:04<01:54,  3.58s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  145.26079291006317\n","Test Loss:  50.17875170588377\n","Early stopping with best_loss:  48.536288367642555 and test_loss for this epoch:  50.17875170588377 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0976694161554723\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:49,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.148062068969\n","Test Loss:  34.06296733720228\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:48,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  93.04514655098319\n","Test Loss:  23.37685915734619\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:46,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.13954341039062\n","Test Loss:  21.288980177487247\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:46,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  55.74769980914425\n","Test Loss:  19.908931831247173\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:45,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.3740224794019\n","Test Loss:  19.134029544249643\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:44,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.84233774954919\n","Test Loss:  17.791522686253302\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:43,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.435114980558865\n","Test Loss:  17.310357246693457\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:42,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.034653554379474\n","Test Loss:  20.36994272036827\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:40,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.5962429131032\n","Test Loss:  16.884224423673004\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:39,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.159844246227294\n","Test Loss:  18.278494485188276\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:10<00:38,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.720331152144354\n","Test Loss:  16.67519782547606\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:11<00:37,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.55403598526027\n","Test Loss:  16.541337162954733\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:12<00:36,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.88636702916119\n","Test Loss:  17.25962997903116\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:13<00:35,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.707959737977944\n","Test Loss:  21.28148873662576\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:14<00:34,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.245655022677965\n","Test Loss:  15.781352000660263\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:15<00:34,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.699050806986634\n","Test Loss:  15.276649275561795\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:17<00:33,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  40.29510021532769\n","Test Loss:  16.695972467481624\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:17<00:31,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.605818654439645\n","Test Loss:  16.347266162221786\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:18<00:30,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.824539795401506\n","Test Loss:  14.772051964624552\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:19<00:29,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.14251644164324\n","Test Loss:  14.74523903656518\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:20<00:28,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.448176169535145\n","Test Loss:  18.640214932296658\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:21<00:27,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.297355000220705\n","Test Loss:  14.650563693721779\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:22<00:26,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.657672172412276\n","Test Loss:  15.81106231501326\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:23<00:25,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.80138004512992\n","Test Loss:  14.921257403009804\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:24<00:24,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  35.962003797932994\n","Test Loss:  15.203399176709354\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:25<00:23,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.00144494604319\n","Test Loss:  15.73426689452026\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:26<00:24,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  36.536727746541146\n","Test Loss:  14.98373488796642\n","Early stopping with best_loss:  14.650563693721779 and test_loss for this epoch:  14.98373488796642 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.951149344458758\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:48,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.42785497382283\n","Test Loss:  25.39953869068995\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:47,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  75.45104510081\n","Test Loss:  18.44109537312761\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:47,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  58.99756421125494\n","Test Loss:  17.093572026817128\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:45,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.250033635646105\n","Test Loss:  15.531647452386096\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:44,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  49.942920820903964\n","Test Loss:  14.392844626621809\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:43,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.89797229040414\n","Test Loss:  15.113561407430097\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:42,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  48.044362327316776\n","Test Loss:  14.783461531973444\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:07<00:41,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.47841023642104\n","Test Loss:  14.05297932040412\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:08<00:40,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.16603735135868\n","Test Loss:  14.915790570434183\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:09<00:39,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  43.26296918874141\n","Test Loss:  14.586959880776703\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:10<00:38,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  45.06621711386833\n","Test Loss:  15.31495350273326\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:11<00:37,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.3126871290151\n","Test Loss:  12.516971974167973\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:12<00:36,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.47007581338403\n","Test Loss:  13.534338136669248\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:13<00:35,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.050231807050295\n","Test Loss:  12.439529211376794\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:14<00:34,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.1249457776139\n","Test Loss:  12.269668434164487\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:15<00:33,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  41.423983240674715\n","Test Loss:  13.86280368315056\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:16<00:32,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  40.31058066850528\n","Test Loss:  12.836227990745101\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:17<00:31,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.772421051282436\n","Test Loss:  12.970458883384708\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:18<00:30,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  40.421119020553306\n","Test Loss:  14.064264318090864\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:19<00:32,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  38.9725710649509\n","Test Loss:  12.758093074313365\n","Early stopping with best_loss:  12.269668434164487 and test_loss for this epoch:  12.758093074313365 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.6792407264357304\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:01<00:52,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  106.94313548691571\n","Test Loss:  24.330888483207673\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:02<00:51,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.61850192723796\n","Test Loss:  20.035156027181074\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:03<00:50,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.922603033599444\n","Test Loss:  22.28121584194014\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:04<00:50,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.43761680251919\n","Test Loss:  17.00655244360678\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:05<00:49,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.97321988095064\n","Test Loss:  28.090223464387236\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:06<00:48,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  49.79101076815277\n","Test Loss:  17.688297538203187\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:07<00:47,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.54082616243977\n","Test Loss:  15.150930712465197\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:08<00:45,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.732215787051246\n","Test Loss:  19.143593177897856\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:09<00:44,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  44.30618357413914\n","Test Loss:  15.539417263644282\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:10<00:43,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.394594720040914\n","Test Loss:  14.021665979700629\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:11<00:42,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  43.30867502419278\n","Test Loss:  15.087583818036364\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:13<00:41,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  42.08136704179924\n","Test Loss:  14.738570468500257\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:14<00:40,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  41.066601375467144\n","Test Loss:  14.43522556242533\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:15<00:39,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  42.71971767343348\n","Test Loss:  14.38780225883238\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:16<00:38,  1.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.024383825890254\n","Test Loss:  13.038603915774729\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:17<00:37,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.37362655485049\n","Test Loss:  14.24406002392061\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:18<00:35,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  36.61172303085914\n","Test Loss:  13.046858621528372\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:19<00:34,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.462781720329076\n","Test Loss:  13.343395414762199\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:20<00:33,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  35.37295023072511\n","Test Loss:  13.58568809798453\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:21<00:32,  1.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.28368759062141\n","Test Loss:  12.793944485019892\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:22<00:31,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.125126731349155\n","Test Loss:  13.068866029148921\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:23<00:30,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.87284839863423\n","Test Loss:  11.501306631835178\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:24<00:29,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.224905778537504\n","Test Loss:  12.874173213058384\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:26<00:28,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  34.457790743443184\n","Test Loss:  13.500171245861566\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:27<00:27,  1.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  36.7182875755243\n","Test Loss:  13.920869363588281\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:28<00:26,  1.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  34.873524067690596\n","Test Loss:  12.49955049075652\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:29<00:27,  1.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  35.680252878635656\n","Test Loss:  13.710732244187966\n","Early stopping with best_loss:  11.501306631835178 and test_loss for this epoch:  13.710732244187966 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.7241410668141499\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:02,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  225.24849295709282\n","Test Loss:  46.44640039699152\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:01,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  104.65532179316506\n","Test Loss:  32.32323979632929\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:57,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.83659102616366\n","Test Loss:  29.680041373852873\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<01:54,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.41943683271529\n","Test Loss:  28.679815335432068\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:51,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  76.6449084324413\n","Test Loss:  24.73743557650596\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:50,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  72.45120106014656\n","Test Loss:  28.80543310137\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:47,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  74.61012743704487\n","Test Loss:  24.027063311863458\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:45,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  73.93890859885141\n","Test Loss:  25.83478071447462\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:22<01:43,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  68.39944132107485\n","Test Loss:  25.433915582339978\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:40,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.95039427245501\n","Test Loss:  23.6923667275114\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:27<01:37,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  68.58503765633213\n","Test Loss:  22.66489136207383\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:35,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  66.8215157999075\n","Test Loss:  23.233491638238775\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:32<01:33,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  64.29842231198563\n","Test Loss:  20.83082044836192\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:35<01:30,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  62.32316727912985\n","Test Loss:  20.84121572622098\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:37<01:27,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  62.826984162966255\n","Test Loss:  22.419780205818824\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:40<01:25,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  61.71726548913284\n","Test Loss:  26.47671845345758\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:42<01:23,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.3943860969448\n","Test Loss:  20.582379889441654\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:45<01:21,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.45521223722608\n","Test Loss:  19.588651482015848\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:47<01:18,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.25572334474418\n","Test Loss:  20.407288750517182\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:50<01:15,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  60.36006077070488\n","Test Loss:  20.801963034144137\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:52<01:13,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.397791810537456\n","Test Loss:  19.560120094480226\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:55<01:10,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  59.821943798684515\n","Test Loss:  19.10807904637477\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:57<01:08,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.414649415790336\n","Test Loss:  19.113541946338955\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:00<01:05,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  57.44019584113266\n","Test Loss:  18.757736174971797\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:02<01:02,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  58.113568284665234\n","Test Loss:  19.46228222810896\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:05<01:00,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  58.423470184498\n","Test Loss:  20.243311358673964\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:07<00:57,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  58.8495389779855\n","Test Loss:  19.722574793966487\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:10<00:55,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  55.34401615773095\n","Test Loss:  20.689947106147883\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:12<00:57,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  57.21988524333574\n","Test Loss:  24.47970265033655\n","Early stopping with best_loss:  18.757736174971797 and test_loss for this epoch:  24.47970265033655 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.41621784420601543\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:59,  2.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.7935771382181\n","Test Loss:  43.089460360002704\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:59,  2.49s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  94.57147443771828\n","Test Loss:  37.634435208077775\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:57,  2.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  83.13209520338569\n","Test Loss:  30.49802257923875\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:55,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  81.89545685102348\n","Test Loss:  29.372744692955166\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:12<01:53,  2.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  78.33639047614997\n","Test Loss:  25.29365624592174\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:50,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  72.29209349298617\n","Test Loss:  28.195980514516123\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:17<01:49,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.36049464228563\n","Test Loss:  23.581846118613612\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:20<01:46,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.48858742316952\n","Test Loss:  21.838897240915685\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:22<01:43,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  70.26010673679411\n","Test Loss:  27.77826689343783\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:25<01:41,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  65.43235384699074\n","Test Loss:  25.238161151326494\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  66.50546547456179\n","Test Loss:  25.872224193182774\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:35,  2.52s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  66.75531524108374\n","Test Loss:  27.170831427327357\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:43,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  61.669838190689916\n","Test Loss:  21.921550002356526\n","Early stopping with best_loss:  21.838897240915685 and test_loss for this epoch:  21.921550002356526 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5704675255996229\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:12,  2.70s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.41261895222124\n","Test Loss:  35.483461391646415\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:09,  2.69s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  89.06198155955644\n","Test Loss:  36.0662138206535\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:07,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  79.30247233796399\n","Test Loss:  32.073777219397016\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:04,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  77.5240302173188\n","Test Loss:  29.199918165890267\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<02:02,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  73.00468972086674\n","Test Loss:  28.939194242993835\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:16<01:59,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  69.68607820983743\n","Test Loss:  23.06560467556119\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:56,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  70.47321014094632\n","Test Loss:  23.48523357824888\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:54,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.92927862791112\n","Test Loss:  22.707402084372006\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:24<01:51,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.64947928176844\n","Test Loss:  19.812464534363244\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:27<01:48,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  65.87198971078033\n","Test Loss:  23.70772994644358\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:29<01:45,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.85027662056382\n","Test Loss:  19.65253720236069\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:32<01:43,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  66.86242159904214\n","Test Loss:  19.535226365405833\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:35<01:40,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  65.59663231810555\n","Test Loss:  19.69755358947441\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:38<01:37,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  62.38220489661035\n","Test Loss:  22.4389796347823\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:40<01:35,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  63.192172232375015\n","Test Loss:  21.118516991497017\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:43<01:32,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  60.70097050903132\n","Test Loss:  21.239629063929897\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:46<01:29,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.982238325843355\n","Test Loss:  17.55129288317403\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:48<01:26,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  57.68406211596448\n","Test Loss:  20.26372114989499\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:51<01:24,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  59.83432549179997\n","Test Loss:  21.674888303154148\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:54<01:21,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  61.99837320311053\n","Test Loss:  21.79983591931523\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:57<01:19,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  59.50835053002811\n","Test Loss:  18.1143415539118\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:59<01:16,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  61.254611794196535\n","Test Loss:  17.387939029256813\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:02<01:14,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.47366930311546\n","Test Loss:  17.204444433329627\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:05<01:11,  2.74s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.65088254606235\n","Test Loss:  18.244622759521008\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:08<01:08,  2.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  57.61668385841767\n","Test Loss:  17.735628175054444\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:10<01:05,  2.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  56.37812862434657\n","Test Loss:  20.009519576866296\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:13<01:02,  2.71s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  56.42622810599278\n","Test Loss:  18.245641139277723\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:16<01:04,  2.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  53.03298156478559\n","Test Loss:  21.065704067994375\n","Early stopping with best_loss:  17.204444433329627 and test_loss for this epoch:  21.065704067994375 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.3649129769598475\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:28,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  401.4376246337779\n","Test Loss:  102.81843209353974\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:24,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  230.77969029080123\n","Test Loss:  84.41258828266291\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:22,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  197.36400061054155\n","Test Loss:  73.81199096987257\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:20,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  189.3224069607095\n","Test Loss:  72.53878095990513\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:18,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.82802205136977\n","Test Loss:  70.67222210229374\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:15,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  171.5400236818532\n","Test Loss:  63.25017388971173\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:12,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  172.33236182376277\n","Test Loss:  65.6564378135372\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:24<02:09,  3.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  163.30557048492483\n","Test Loss:  64.47461368655786\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:27<02:07,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  158.11000359072932\n","Test Loss:  64.88167045312002\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:30<02:04,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.3688469614135\n","Test Loss:  57.41191429737955\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:33<02:00,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  157.48380286450265\n","Test Loss:  67.12756323328358\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:36<01:57,  3.10s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  156.06575867236825\n","Test Loss:  59.71206817746861\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:40<01:54,  3.11s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  154.78361260110978\n","Test Loss:  57.43889505235711\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:43<01:50,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.0836497946293\n","Test Loss:  52.90170938076335\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:46<01:47,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  143.792480765027\n","Test Loss:  53.80497346390621\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:49<01:44,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  144.95401476119878\n","Test Loss:  52.932089852547506\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:52<01:40,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  141.6280788659933\n","Test Loss:  53.960992806445574\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:55<01:37,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  136.7246505750809\n","Test Loss:  50.819971606877516\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:58<01:35,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  140.71471206081333\n","Test Loss:  53.66881423868472\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:01<01:32,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  143.2750807076809\n","Test Loss:  52.28911212575622\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:04<01:28,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.46925354847917\n","Test Loss:  51.08487029038952\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:07<01:25,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  137.95826272619888\n","Test Loss:  53.58792100532446\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:10<01:29,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  137.31091957906028\n","Test Loss:  58.8329465384013\n","Early stopping with best_loss:  50.819971606877516 and test_loss for this epoch:  58.8329465384013 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.2908498066019929\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:28,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  340.6722709725145\n","Test Loss:  87.385732455994\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:26,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  220.54513185156975\n","Test Loss:  69.9609164246358\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:21,  3.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  191.41397111077094\n","Test Loss:  69.43811932695098\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:20,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  184.06282564153662\n","Test Loss:  60.50836003597942\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:15<02:17,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  177.44328713195864\n","Test Loss:  60.62772199854953\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:18<02:15,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  167.68665431204136\n","Test Loss:  64.5683508743532\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:21<02:12,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  166.47846451721853\n","Test Loss:  54.860780534974765\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:24<02:09,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  158.65966320119333\n","Test Loss:  55.422545515495585\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:27<02:05,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  160.2676081226091\n","Test Loss:  55.43632038094802\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:30<02:02,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  150.80280953925103\n","Test Loss:  58.70455319166649\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:33<01:59,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  153.27087706158636\n","Test Loss:  52.37181748027797\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:36<01:56,  3.08s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.33381979644764\n","Test Loss:  52.26283070043428\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:39<01:53,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  150.6188891409547\n","Test Loss:  53.32765764655778\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:42<01:50,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  148.30791458213935\n","Test Loss:  60.63240269309608\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:45<01:47,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.46612632327015\n","Test Loss:  51.66803430544678\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:49<01:44,  3.07s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  146.86993557354435\n","Test Loss:  47.559252390419715\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:52<01:40,  3.06s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  142.20055118759046\n","Test Loss:  50.93173252145061\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:55<01:37,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  141.6523379778664\n","Test Loss:  49.29725703742588\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:58<01:34,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  136.32555845956085\n","Test Loss:  48.17693672620226\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:01<01:31,  3.04s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  139.2572854438331\n","Test Loss:  47.06837734847795\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:04<01:27,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  141.55548908852506\n","Test Loss:  48.31509808663395\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:07<01:24,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  139.80349164654035\n","Test Loss:  48.207119164362666\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:10<01:21,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  137.1914511906216\n","Test Loss:  47.3310805039946\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:13<01:18,  3.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  140.43138229931355\n","Test Loss:  49.94481320108753\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:16<01:22,  3.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  131.50332742542378\n","Test Loss:  51.02844594052294\n","Early stopping with best_loss:  47.06837734847795 and test_loss for this epoch:  51.02844594052294 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.2025275401926823\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:43,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  313.49699993780814\n","Test Loss:  78.55303740967065\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:40,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  216.62277708627516\n","Test Loss:  66.81220392911928\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:36,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  193.40315230499255\n","Test Loss:  56.80703559634276\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:13<02:32,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  179.5579414651147\n","Test Loss:  55.21641834048205\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:29,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  176.61904290269013\n","Test Loss:  59.57772641579504\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:20<02:26,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  166.12593282101443\n","Test Loss:  51.87179013129207\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:23<02:22,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  157.84715358214453\n","Test Loss:  52.74359447445022\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:26<02:19,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  158.89731111947913\n","Test Loss:  50.98383991688024\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:16,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  153.54065294878092\n","Test Loss:  50.70085307239788\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:33<02:13,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.9183816644363\n","Test Loss:  48.86580563048483\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:36<02:10,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  150.61591702324222\n","Test Loss:  55.44934949581511\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:39<02:07,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  148.08260549191618\n","Test Loss:  45.92180599021958\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:43<02:03,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  148.77534500526963\n","Test Loss:  52.66628614073852\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:46<01:59,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  156.2282204304356\n","Test Loss:  45.727648563573894\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:49<01:56,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  145.5476417481259\n","Test Loss:  48.28807426383719\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:53<01:53,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.02412138401996\n","Test Loss:  45.482731767289806\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:56<01:50,  3.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  142.8826485738682\n","Test Loss:  48.144881952452124\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:59<01:46,  3.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  139.33422832150245\n","Test Loss:  53.96832686988637\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:03<01:43,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  134.87133713555522\n","Test Loss:  53.604524308640976\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:06<01:40,  3.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  134.56721689194092\n","Test Loss:  45.38870431878604\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:10<01:37,  3.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.90404516962008\n","Test Loss:  46.881782730371924\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:13<01:34,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  135.9782216057356\n","Test Loss:  49.18692540854681\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:16<01:31,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  137.98697383984108\n","Test Loss:  46.50384743924951\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:20<01:27,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  138.75230543670477\n","Test Loss:  48.98537354786822\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:23<01:30,  3.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  134.00739644368878\n","Test Loss:  47.11875799240079\n","Early stopping with best_loss:  45.38870431878604 and test_loss for this epoch:  47.11875799240079 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.0078608766230988\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:39,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  154.21575757488608\n","Test Loss:  36.58646044600755\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:39,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  98.67459196783602\n","Test Loss:  25.729642839170992\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:38,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.25228977575898\n","Test Loss:  20.452374712796882\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:37,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.773256773129106\n","Test Loss:  18.690759929362684\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:36,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  54.45068741356954\n","Test Loss:  18.846043104771525\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:04<00:35,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.94024933781475\n","Test Loss:  17.59734600619413\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:05<00:34,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.48066632589325\n","Test Loss:  17.447588686598465\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:33,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  46.927951648365706\n","Test Loss:  16.299021311220713\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:32,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  47.09094085893594\n","Test Loss:  16.902336516184732\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:32,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.89447033405304\n","Test Loss:  16.25115034088958\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:08<00:31,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.13049032562412\n","Test Loss:  15.80975224939175\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:09<00:30,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  44.4045655336231\n","Test Loss:  16.658158506266773\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:10<00:29,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.713180714985356\n","Test Loss:  15.240614316891879\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:11<00:29,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  42.47549043619074\n","Test Loss:  21.20624659396708\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:28,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  39.69885254348628\n","Test Loss:  16.397523860563524\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:12<00:27,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  40.69696518406272\n","Test Loss:  15.914548616798129\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:13<00:26,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  40.28636509727221\n","Test Loss:  17.892437387956306\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:14<00:25,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  39.125937766744755\n","Test Loss:  14.31844808824826\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:15<00:25,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.57121834822465\n","Test Loss:  14.273568927776068\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:16<00:24,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.309122680919245\n","Test Loss:  14.132270141155459\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:16<00:23,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.5433700773865\n","Test Loss:  14.360121178324334\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:17<00:22,  1.26it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.848178378888406\n","Test Loss:  13.960328722023405\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:18<00:21,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  38.67458782994072\n","Test Loss:  14.268693591933697\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:19<00:20,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.33586309570819\n","Test Loss:  13.337625037296675\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:20<00:20,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.904174140887335\n","Test Loss:  13.476434016774874\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:20<00:19,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.8440473388182\n","Test Loss:  13.64968044043053\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:21<00:18,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.80714542407077\n","Test Loss:  14.456400249153376\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:22<00:17,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  36.01558640890289\n","Test Loss:  15.006803801748902\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:23<00:18,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  36.2814620283898\n","Test Loss:  14.545289445726667\n","Early stopping with best_loss:  13.337625037296675 and test_loss for this epoch:  14.545289445726667 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1075923678439787\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:39,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  119.28939275816083\n","Test Loss:  34.44532305281609\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:39,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  70.36099983751774\n","Test Loss:  24.957780571188778\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:39,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.616047721821815\n","Test Loss:  22.781717090168968\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:37,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.09798055514693\n","Test Loss:  21.144734364468604\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:36,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  48.9716527974233\n","Test Loss:  21.45311786979437\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:04<00:35,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  44.693943283404224\n","Test Loss:  21.74501964612864\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:05<00:34,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  44.68306539487094\n","Test Loss:  19.242310339584947\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:06<00:34,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.2496561598964\n","Test Loss:  18.890197154134512\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:07<00:33,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  42.35945056693163\n","Test Loss:  18.739382877596654\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:08<00:32,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.79717979510315\n","Test Loss:  18.01947937940713\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:08<00:31,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  40.46857779775746\n","Test Loss:  17.423754379269667\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:09<00:30,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  38.252335071738344\n","Test Loss:  17.288555012317374\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:10<00:30,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.38142088451423\n","Test Loss:  16.577653566142544\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:11<00:29,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  36.35669999476522\n","Test Loss:  16.631845486117527\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:12<00:28,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  37.98636635253206\n","Test Loss:  16.963415096630342\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:13<00:27,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.64407253684476\n","Test Loss:  16.115033612586558\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:13<00:26,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.883826048113406\n","Test Loss:  16.023935407050885\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:14<00:26,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.538192572654225\n","Test Loss:  15.280273879121523\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:15<00:25,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  34.20104950200766\n","Test Loss:  16.546746144187637\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:16<00:24,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  32.61553435056703\n","Test Loss:  17.63949301163666\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:17<00:23,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  34.834402500709984\n","Test Loss:  15.785520145494957\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:17<00:22,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.79220562404953\n","Test Loss:  14.80856008711271\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:18<00:21,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.80099621589761\n","Test Loss:  14.146422548394185\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:19<00:20,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.32510646514129\n","Test Loss:  15.25385862425901\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:20<00:20,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  32.4616547775222\n","Test Loss:  16.870396532816812\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:21<00:19,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  31.160806570202112\n","Test Loss:  15.225882825208828\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:21<00:18,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  33.10299589729402\n","Test Loss:  14.125131961423904\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:22<00:17,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.48257760881097\n","Test Loss:  14.476562699011993\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:23<00:17,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  29.965191695839167\n","Test Loss:  16.0480028137099\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:24<00:16,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  32.337178299436346\n","Test Loss:  15.189229675102979\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 31/50 [00:25<00:15,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  31.143319865921512\n","Test Loss:  14.83180799218826\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 32/50 [00:25<00:14,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  30.85771706851665\n","Test Loss:  13.38421609334182\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 33/50 [00:26<00:13,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  28.514602900482714\n","Test Loss:  14.82340290537104\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 34/50 [00:27<00:13,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  29.592098425142467\n","Test Loss:  14.4614164668601\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 35/50 [00:28<00:12,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  28.322516015381552\n","Test Loss:  13.734020884963684\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:29<00:11,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  31.465663247159682\n","Test Loss:  13.605923453869764\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 36/50 [00:30<00:11,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  31.084732909104787\n","Test Loss:  15.18247799295932\n","Early stopping with best_loss:  13.38421609334182 and test_loss for this epoch:  15.18247799295932 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.027259853640023\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:00<00:44,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  106.69891417771578\n","Test Loss:  29.489268525736406\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:01<00:43,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  65.616572646657\n","Test Loss:  22.1865965295583\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:02<00:42,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  54.53845060779713\n","Test Loss:  24.007655842462555\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:03<00:41,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.59302958403714\n","Test Loss:  18.305099158082157\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:04<00:40,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  47.16949323611334\n","Test Loss:  17.04336512973532\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:05<00:40,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.30258212052286\n","Test Loss:  17.00832607189659\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:06<00:39,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  43.82078537106281\n","Test Loss:  16.668139628134668\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:07<00:37,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.33380770380609\n","Test Loss:  16.12385287450161\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:08<00:36,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  41.34190894989297\n","Test Loss:  15.004778659436852\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:09<00:35,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  37.91124344826676\n","Test Loss:  17.141458261932712\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:09<00:35,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  38.90578820579685\n","Test Loss:  16.341062802122906\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:10<00:34,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  38.09205437055789\n","Test Loss:  15.25419177825097\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:11<00:33,  1.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  38.106456886045635\n","Test Loss:  17.77504429873079\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:12<00:32,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  36.99043599900324\n","Test Loss:  14.71597382100299\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:13<00:31,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.96279905294068\n","Test Loss:  14.316091893124394\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:14<00:31,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  35.78750104038045\n","Test Loss:  14.13827280967962\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:15<00:30,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  37.8690312106628\n","Test Loss:  13.689824067987502\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:16<00:29,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.976128724985756\n","Test Loss:  14.03229016205296\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:17<00:28,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.250437137670815\n","Test Loss:  13.648168033920228\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:18<00:27,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  32.064892304246314\n","Test Loss:  15.554577911971137\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:19<00:26,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  34.823084703297354\n","Test Loss:  13.435682555951644\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [00:19<00:25,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.7357574836351\n","Test Loss:  14.462819766020402\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [00:20<00:24,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  31.998327707871795\n","Test Loss:  16.072244516573846\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [00:21<00:23,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  33.175772530725226\n","Test Loss:  14.040861707180738\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [00:22<00:22,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.24549629201647\n","Test Loss:  12.319607384619303\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [00:23<00:21,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  32.073872653068975\n","Test Loss:  11.875519952387549\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [00:24<00:20,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  33.46505115099717\n","Test Loss:  12.757877908472437\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [00:25<00:19,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  30.06564214185346\n","Test Loss:  13.57374584954232\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [00:26<00:18,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  28.57773214939516\n","Test Loss:  12.505228427704424\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:27<00:17,  1.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  29.963763665175065\n","Test Loss:  12.000389689972508\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [00:28<00:18,  1.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  27.851537926355377\n","Test Loss:  11.90803007921204\n","Early stopping with best_loss:  11.875519952387549 and test_loss for this epoch:  11.90803007921204 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9252452569534603\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:52,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  202.22886143624783\n","Test Loss:  41.54348159447545\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:52,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  86.20384938747156\n","Test Loss:  21.22015276676393\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<01:50,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  63.15253278746968\n","Test Loss:  24.493825288518565\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:47,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  62.1275369230425\n","Test Loss:  19.93342465860769\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:11<01:45,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  60.512268787104404\n","Test Loss:  21.212628196837613\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:14<01:43,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  56.613192432618234\n","Test Loss:  17.578265957767144\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:16<01:40,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.33836185443215\n","Test Loss:  16.942470749345375\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:18<01:38,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  51.3489276603068\n","Test Loss:  16.54327038221527\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:21<01:35,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  53.990331440989394\n","Test Loss:  16.83718366769608\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:23<01:33,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  48.10258981803781\n","Test Loss:  16.746936522438773\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:25<01:31,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  52.744988990423735\n","Test Loss:  16.931822071172064\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:28<01:29,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  50.26010713999858\n","Test Loss:  17.146250979683828\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:30<01:36,  2.54s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  50.98604078353674\n","Test Loss:  17.845273018610897\n","Early stopping with best_loss:  16.54327038221527 and test_loss for this epoch:  17.845273018610897 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.4203994578078926\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<01:53,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  155.26094363513403\n","Test Loss:  25.138950937543996\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:04<01:53,  2.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  72.93022651737556\n","Test Loss:  19.776190696051344\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:06<01:49,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.25358896725811\n","Test Loss:  18.436133544659242\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:09<01:45,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  60.95678955700714\n","Test Loss:  17.134145658332272\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:11<01:43,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  56.53021360596176\n","Test Loss:  18.222863117349334\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:13<01:40,  2.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  54.7208314476884\n","Test Loss:  15.179871243715752\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:16<01:38,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  51.69113871169975\n","Test Loss:  18.774352347070817\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:18<01:36,  2.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  53.60774597918498\n","Test Loss:  17.76289537572302\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:20<01:34,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  49.630097444343846\n","Test Loss:  20.074726819293573\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:23<01:32,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.786575710983016\n","Test Loss:  14.15724320555455\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:25<01:30,  2.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  49.81524688960053\n","Test Loss:  18.452369002014166\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:27<01:28,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  50.21579591589398\n","Test Loss:  14.464141331423889\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:30<01:25,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  46.09772652538959\n","Test Loss:  15.065544085256988\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:32<01:23,  2.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  48.98893915285589\n","Test Loss:  17.293088254969916\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:34<01:21,  2.34s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.51046303260955\n","Test Loss:  13.684700680052629\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:37<01:19,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.98503386134689\n","Test Loss:  13.144886719062924\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:39<01:16,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  45.46427127846982\n","Test Loss:  12.905538487364538\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:41<01:14,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  45.02922639186727\n","Test Loss:  17.200961644295603\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:44<01:12,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.89290637508384\n","Test Loss:  16.705984106549295\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:46<01:09,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  42.425298915826716\n","Test Loss:  16.39906689534837\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:48<01:07,  2.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  44.39016573940171\n","Test Loss:  14.545825972600142\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [00:51<01:10,  2.43s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  41.38604338944424\n","Test Loss:  13.818302723957459\n","Early stopping with best_loss:  12.905538487364538 and test_loss for this epoch:  13.818302723957459 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.306307219686891\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:07,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  114.5835771933198\n","Test Loss:  33.86484918568749\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  63.64543488656636\n","Test Loss:  26.578756130475085\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:07<02:03,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  52.93734303774545\n","Test Loss:  25.857193594332784\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:10<02:00,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  53.51414929312887\n","Test Loss:  21.275559491943568\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:13<01:58,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.965947181830416\n","Test Loss:  26.04672302934341\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:15<01:55,  2.62s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.87521721981466\n","Test Loss:  22.1540035000653\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:18<01:51,  2.60s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  50.37349974602694\n","Test Loss:  19.3572644519154\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:21<01:50,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  48.96889873253531\n","Test Loss:  18.704285173138487\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:23<01:48,  2.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  46.87970252594096\n","Test Loss:  19.48855487140827\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:26<01:45,  2.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  46.79040301730856\n","Test Loss:  23.146432879730128\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:28<01:41,  2.61s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  45.34302298055263\n","Test Loss:  19.131300631095655\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:31<01:38,  2.59s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  42.51385256263893\n","Test Loss:  20.337221892463276\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:34<01:47,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  42.717303932091454\n","Test Loss:  18.776652949571144\n","Early stopping with best_loss:  18.704285173138487 and test_loss for this epoch:  18.776652949571144 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.5405365969221414\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:22,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  384.36024997290224\n","Test Loss:  91.65306098229485\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:18,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  226.97295830096118\n","Test Loss:  77.2365745427087\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:16,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  205.76166147110052\n","Test Loss:  78.76849219610449\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:15,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.86687387002166\n","Test Loss:  63.44536527368473\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:13,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  176.49891239704448\n","Test Loss:  61.716035030200146\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:09,  2.95s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.70190212855232\n","Test Loss:  58.90386905102059\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:20<02:06,  2.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  166.3101207317668\n","Test Loss:  57.26657701213844\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:23<02:02,  2.92s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  160.21173201221973\n","Test Loss:  53.05374342488358\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:26<01:58,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  150.63097089267103\n","Test Loss:  61.71898389500711\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:29<01:55,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  152.83869867044268\n","Test Loss:  52.68682704475941\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:32<01:53,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  150.3730597193935\n","Test Loss:  49.710516864201054\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:34<01:50,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  147.77291482838336\n","Test Loss:  56.34745203051716\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:37<01:47,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  146.59438049403252\n","Test Loss:  51.104572620999534\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:40<01:44,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  140.5213184087188\n","Test Loss:  50.028404866112396\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:43<01:41,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  147.3515485447133\n","Test Loss:  46.32033797254553\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:46<01:38,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  141.85138881165767\n","Test Loss:  49.75482375524007\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:49<01:35,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.16362027754076\n","Test Loss:  45.66621558369661\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:52<01:32,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  139.00914541928796\n","Test Loss:  45.671145737112965\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:55<01:29,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  136.79626445070608\n","Test Loss:  48.47077045071637\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:58<01:26,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  139.74213380884612\n","Test Loss:  59.21896154322894\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:01<01:24,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  129.01059395307675\n","Test Loss:  47.25939598408877\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:03<01:28,  3.05s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  134.06023772625485\n","Test Loss:  45.90865428792313\n","Early stopping with best_loss:  45.66621558369661 and test_loss for this epoch:  45.90865428792313 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.1778955583020436\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:02<02:20,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  315.0696464693174\n","Test Loss:  99.08948781556683\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:05<02:17,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  206.78599069896154\n","Test Loss:  74.84159218182322\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:08<02:14,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  179.13028237764956\n","Test Loss:  69.02017812413396\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:11<02:10,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  170.20497993484605\n","Test Loss:  69.96456746011972\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:14<02:07,  2.83s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  167.39402669016272\n","Test Loss:  63.5324857084197\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:17<02:05,  2.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  150.36531590047525\n","Test Loss:  61.3563624931121\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:19<02:02,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  152.37646555056563\n","Test Loss:  61.501171103678644\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:22<02:00,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  144.30436567217112\n","Test Loss:  59.271657076256815\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:25<01:57,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  136.79103982349625\n","Test Loss:  61.0693432596745\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:28<01:55,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  140.80385613266844\n","Test Loss:  57.58109008974861\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:31<01:52,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  137.3586232176749\n","Test Loss:  58.97069835892762\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:34<01:49,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  136.20862289867364\n","Test Loss:  57.65220988623332\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:37<01:47,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  137.91491018529632\n","Test Loss:  59.03853734803852\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:40<01:44,  2.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.13638404011726\n","Test Loss:  53.051747662131675\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:43<01:41,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  135.25725026620785\n","Test Loss:  66.74269788328093\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:46<01:38,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  125.88799243466929\n","Test Loss:  51.684296057443134\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:48<01:35,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  129.004953557509\n","Test Loss:  52.206180995708564\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:51<01:32,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  128.0607989244745\n","Test Loss:  49.48801853207988\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [00:54<01:29,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  129.03382071614033\n","Test Loss:  53.17479108565021\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [00:57<01:26,  2.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  126.46680127532454\n","Test Loss:  54.46762554248562\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:00<01:23,  2.89s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  123.61392979166703\n","Test Loss:  53.90286118607037\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:03<01:20,  2.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  129.55882271908922\n","Test Loss:  47.69983421411598\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:06<01:17,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  122.8187494984013\n","Test Loss:  50.93564905482344\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:09<01:14,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  123.5496856943355\n","Test Loss:  49.766233511734754\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:11<01:11,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  119.96151985495817\n","Test Loss:  50.57257691939594\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:14<01:08,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  120.25230202410603\n","Test Loss:  47.34759031160502\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:17<01:05,  2.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  116.81778944496182\n","Test Loss:  51.92989604016475\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:20<01:02,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  117.8611971430073\n","Test Loss:  50.45897862792481\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:23<01:00,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  114.95777224918129\n","Test Loss:  54.299915265874006\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:26<00:57,  2.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  116.59857935630134\n","Test Loss:  49.870477938471595\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 30/50 [01:29<00:59,  2.97s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  119.02999126515351\n","Test Loss:  54.30267600901425\n","Early stopping with best_loss:  47.34759031160502 and test_loss for this epoch:  54.30267600901425 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","1.24338155628716\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/50 [00:03<02:37,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  315.1513969346415\n","Test Loss:  81.72492742532631\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 2/50 [00:06<02:34,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  207.64824463694822\n","Test Loss:  71.98057244991651\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 3/50 [00:09<02:32,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  182.41997681290377\n","Test Loss:  60.660624659692985\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 4/50 [00:12<02:28,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  170.76865582639584\n","Test Loss:  56.48694916261593\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 5/50 [00:16<02:25,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  165.85846852196846\n","Test Loss:  54.57744977157563\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 6/50 [00:19<02:21,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  163.36463724431815\n","Test Loss:  53.70168721239315\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 7/50 [00:22<02:19,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  157.48425295675406\n","Test Loss:  65.22761715680826\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 8/50 [00:25<02:15,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  151.25639625807526\n","Test Loss:  49.75046416919213\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 9/50 [00:29<02:11,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  150.99361747771036\n","Test Loss:  50.796868208330125\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 10/50 [00:32<02:08,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  144.24713807628723\n","Test Loss:  53.34469881467521\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 11/50 [00:35<02:05,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  141.17355901369592\n","Test Loss:  49.43741275226057\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 12/50 [00:38<02:02,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  136.24180328135844\n","Test Loss:  45.792969550821\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 13/50 [00:41<01:59,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  133.1825445968425\n","Test Loss:  44.80579426389886\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 14/50 [00:45<01:56,  3.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  138.30528727918863\n","Test Loss:  59.63473880360834\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 15/50 [00:48<01:53,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  138.27856902900385\n","Test Loss:  47.488746638468\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 16/50 [00:51<01:49,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  131.38388722541276\n","Test Loss:  45.78113028751977\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 17/50 [00:54<01:45,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  137.77287486891146\n","Test Loss:  44.41167921916349\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 18/50 [00:58<01:43,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  134.94366097426973\n","Test Loss:  49.70918583951425\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 19/50 [01:01<01:39,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  131.48959928390104\n","Test Loss:  46.541702500660904\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 20/50 [01:04<01:36,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  131.34920872567454\n","Test Loss:  45.005286097264616\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 21/50 [01:07<01:33,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  132.69097169637098\n","Test Loss:  40.68169452325674\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 22/50 [01:10<01:30,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  129.4709150257986\n","Test Loss:  49.036247009644285\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 23/50 [01:14<01:26,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  128.2932697868091\n","Test Loss:  40.909213029255625\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 24/50 [01:17<01:23,  3.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  125.89530554227531\n","Test Loss:  45.029228143859655\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 25/50 [01:20<01:20,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Train Loss:  125.82875696348492\n","Test Loss:  40.477302574552596\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 26/50 [01:23<01:16,  3.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 1 of 5\n","Train Loss:  128.87338587030536\n","Test Loss:  46.51748006114212\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 27/50 [01:26<01:13,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 2 of 5\n","Train Loss:  118.35152638706495\n","Test Loss:  44.551904993481\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 28/50 [01:30<01:10,  3.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 3 of 5\n","Train Loss:  121.95172811913653\n","Test Loss:  44.53268759752973\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:33<01:07,  3.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 4 of 5\n","Train Loss:  118.8743472439528\n","Test Loss:  51.67924027889967\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 29/50 [01:36<01:09,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Counter 5 of 5\n","Train Loss:  123.52814664982725\n","Test Loss:  42.03477039845893\n","Early stopping with best_loss:  40.477302574552596 and test_loss for this epoch:  42.03477039845893 ...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["mse_validation:\n","0.9083332743517355\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.preprocessing import MinMaxScaler\n","from torch import nn\n","from tqdm import trange\n","from datetime import date, timedelta\n","\n","from collections import OrderedDict\n","from collections import namedtuple\n","from itertools import product\n","\n","import torch.nn.functional as F\n","\n","\n","'''\n","Don't save trained model or results in github, there is no enough space\n","'''\n","data_file = '/content/drive/MyDrive/Flu Forecasting/code/trainingdata_rate0131.csv'\n","model_file = '/content/drive/MyDrive/Flu Forecasting/GRU/weightselection/'\n","prediction_file = '/content/drive/MyDrive/Flu Forecasting/GRU/weightselection/'\n","summary_file ='/content/drive/MyDrive/Flu Forecasting/GRU/weightselection/'\n","def perdelta(start, end, delta):\n","    curr = start\n","    while curr < end:\n","        yield curr\n","        curr += delta\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","params = OrderedDict(\n","    target = ['rate'], ### Our target variable\n","    lr = [0.0001,0.00025],\n","    batch_size = [2],\n","    seq_length = [6,8,12], # length of input sequence to predict values\n","    output_size = [4], # we are predicting next four weeks admissions\n","    num_pred_features = [1],\n","    week_range = [32,64,128], # number of historical data (per state) used to train the model\n","    input_size = [15], # total number of input features\n","    hidden_layer_size = [64,128,256], #test\n","    num_layers = [1], #test\n","    ratio = [0.7],  # ratio of training set and validation set\n","    num_epochs = [50],\n","    dropout_rate = [0.8],\n","    lossfunc = [nn.SmoothL1Loss(beta=0.05, reduction = 'sum'),\n","\n","                ]\n",")\n","\n","class RunBuilder():\n","    @staticmethod\n","    def get_runs(params):\n","\n","        Run = namedtuple('Run', params.keys())\n","\n","        runs = []\n","        for v in product(*params.values()):\n","            runs.append(Run(*v))\n","\n","        return runs\n","\n","pd.options.mode.chained_assignment = None\n","\n","runs = RunBuilder.get_runs(params)\n","\n","# output dict\n","columns = [\n","    'Model',\n","    'lr',\n","    'batch_size',\n","    'seq_length',\n","    'week_range',\n","    'hidden_layer_size',\n","    'num_layers',\n","    'lossfunc',\n","    'mse_validation',\n","    'mse_validation_1w',\n","    'mse_validation_2w',\n","    'mse_validation_3w',\n","    'mse_validation_4w',\n","    'Target'\n","]\n","# output dataframe\n","df_summary = pd.DataFrame(columns=columns)\n","for run in RunBuilder.get_runs(params):\n","    if run.target == 'rate':\n","        results_file = 'rate'\n","\n","    validation_predictions = []\n","    validation_labels = []\n","    # read data\n","    df = pd.read_csv(data_file)\n","    #df = df.rename(columns={'End Date': 'Week_end', 'State': 'fips'})\n","    df['Week_end'] = pd.to_datetime(df['Week_end'])\n","    # too many missing values in State'11'\n","    df =  df[df['fips'] != 11]\n","    #df =  df[df['fips'] == 1]\n","    #df = df[['fips', 'Week_end', 'total_admissions']]\n","\n","    # drop weather data\n","    #df = df.drop(['PRCP_mean', 'SNOW_mean', 'TMAXDELTA', 'TMINDELTA'], axis=1)\n","    # choose data in 2023-11 as test data  test 10-01\n","    '''\n","    start_date1 = pd.to_datetime('2023-11-01') - timedelta(weeks=run.seq_length * 7)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] < pd.to_datetime('2023-11-26'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2023-11 as training data and validation data\n","    df_train = df[(df['Week_end'] <= pd.to_datetime('2023-11-01'))& (df['Week_end'] >pd.to_datetime('2022-08-01')) ] # Use data before 11/1 as training set\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","'''\n","\n","\n","    start_date1 = pd.to_datetime('2024-01-20') - timedelta(weeks=run.seq_length)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] <pd.to_datetime('2024-01-30'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2024-01-06 as training data and validation data and after 2022-08-01\n","    df_train = df[(df['Week_end'] <= pd.to_datetime('2024-01-20'))& (df['Week_end'] >pd.to_datetime('2022-08-01')) ] # Use data before 11/1 as training set\n","\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","    #rescale the data from 0 to 1, normalization\n","\n","    first_col = df_train.pop(run.target)\n","    df_train.insert(0, run.target, first_col)\n","    first_col_2 = df_test.pop(run.target)\n","    df_test.insert(0, run.target, first_col_2)\n","\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","    scaler.fit(df_train.iloc[:, 1:])\n","    train_features_normalized = scaler.transform(df_train.iloc[:, 1:])\n","    test_feature_normalized = scaler.transform(df_test.iloc[:, 1:])\n","\n","    scaler_target = MinMaxScaler(feature_range=(0, 1))\n","    scaler_target.fit(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    train_target_normalized = scaler_target.transform(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    test_target_normalized = scaler_target.transform(np.asarray(df_test.iloc[:, 0]).reshape(-1, 1))\n","\n","    df_train.iloc[:, 1:] = train_features_normalized\n","    df_train.iloc[:, 0] = train_target_normalized\n","    df_test.iloc[:, 1:] = test_feature_normalized\n","    df_test.iloc[:, 0] = test_target_normalized\n","\n","    '''\n","    Training\n","    '''\n","\n","    full_data_main, state_ordered = prepare_data_main_model(df_train, run.seq_length,\n","                                                            run.output_size, run.week_range)\n","\n","\n","    model_main = GRU(run.input_size, run.hidden_layer_size, run.num_layers, run.output_size, run.dropout_rate).to(device)\n","\n","\n","    train_loader_main, test_loader_main = splitdata(full_data_main, run.ratio, run.batch_size)\n","\n","    loss_function = run.lossfunc\n","\n","    optimizer_main = torch.optim.Adam(model_main.parameters(), lr=run.lr)\n","\n","    track_loss_train = []\n","    track_loss_test = []\n","    best_loss = 100000\n","    ###\n","    best_mse_categorical = None\n","    best_accuracy_categorical = None\n","    best_mse_numerical = None\n","    mse_numerical_weekly = [None] * 4\n","    accuracy_categorical_weekly = [None] * 4\n","    mse_categorical_weekly = [None] * 4\n","    best_mse_categorical_weekly = [None] * 4\n","    best_accuracy_categorical_weekly = [None] * 4\n","    best_mse_numerical_weekly = [None] * 4\n","    for i in trange(run.num_epochs):\n","\n","        model_main.train()\n","        epoch_loss_train = 0\n","\n","        for i, (seq, labels) in enumerate(train_loader_main):\n","            seq, labels = seq.to(device), labels.to(device)\n","            optimizer_main.zero_grad()\n","            seq = torch.as_tensor(seq).reshape(-1, run.seq_length, run.input_size)\n","            model_main.hidden = torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device)\n","\n","            y_pred = model_main(seq.float())\n","\n","            single_loss = loss_function(y_pred, torch.as_tensor(labels).float())\n","            single_loss.backward()\n","            optimizer_main.step()\n","\n","            epoch_loss_train += single_loss.item()\n","\n","        track_loss_train.append(epoch_loss_train)\n","        model_main.eval()\n","        with torch.no_grad():\n","            epoch_loss_test = 0\n","          ########\n","            validation_predictions = []\n","            validation_labels = []\n","            for i, (seq, labels) in enumerate(test_loader_main):\n","                seq, labels = seq.to(device), labels.to(device)\n","                seq = torch.as_tensor(seq).reshape(-1, run.seq_length, run.input_size)\n","                model_main.hidden = torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device)\n","                y_pred = model_main(seq.float())\n","\n","                single_loss = loss_function(y_pred, torch.as_tensor(labels).float())\n","                epoch_loss_test += single_loss.item()\n","\n","                            ######\n","                validation_predictions.extend(y_pred.cpu().numpy())\n","                validation_labels.extend(labels.cpu().numpy())\n","            track_loss_test.append(epoch_loss_test)\n","\n","        validation_predictions = np.concatenate(validation_predictions, axis=0)\n","        validation_labels = np.concatenate(validation_labels, axis=0)\n","        validation_predictions = scaler_target.inverse_transform(validation_predictions.reshape(-1, 1)).reshape(-1, 4)\n","        validation_labels = scaler_target.inverse_transform(validation_labels.reshape(-1, 1)).reshape(-1, 4)\n","\n","        # Calculate total and weekly MSE and accuracy\n","        mse_numerical = np.mean((validation_predictions - validation_labels)**2)\n","\n","        for week in range(4):\n","            # Numerical MSE\n","            mse_numerical_week = np.mean((validation_predictions[:, week] - validation_labels[:, week])**2)\n","            mse_numerical_weekly[week] = mse_numerical_week\n","\n","\n","        if epoch_loss_test  < best_loss:\n","          #####\n","            best_mse_numerical = mse_numerical\n","            best_mse_numerical_weekly = mse_numerical_weekly\n","\n","            best_loss = epoch_loss_test\n","            print('Train Loss: ', epoch_loss_train)\n","            print('Test Loss: ', epoch_loss_test)\n","            es = 0\n","            torch.save(model_main.state_dict(),\n","                           model_file + run.target + '_' + str(run.lr) + '_' +\n","                           str(run.week_range) + '_' + str(run.hidden_layer_size)\\\n","                           + '_' + str(run.seq_length) + '_' + str(run.num_layers)\\\n","                                                  + '_GRU_weights.pt')\n","        else:\n","            es += 1\n","            print(\"Counter {} of 5\".format(es))\n","            print('Train Loss: ', epoch_loss_train)\n","            print('Test Loss: ', epoch_loss_test)\n","\n","\n","        if es > 4:\n","            print(\"Early stopping with best_loss: \", best_loss, \"and test_loss for this epoch: \",\n","                      epoch_loss_test,\n","                      \"...\")\n","\n","            break\n","\n","    '''\n","    Prediction\n","    '''\n","    df_output = pd.DataFrame(columns=['fips', 'Week_end', 'Prediction_1w',\n","                                      'Prediction_2w', 'Prediction_3w',\n","                                      'Prediction_4w'])\n","\n","    test_weeks = df_test[df_test.index.get_level_values('Week_end') \\\n","                       >= pd.to_datetime('2024-01-20')].index.get_level_values('Week_end').unique()\n","    test_states = df_test.index.get_level_values('fips').unique()\n","\n","    m_state_dict_main = torch.load(model_file + run.target + '_'  +str(run.lr) + '_' +\n","                                   str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                                   + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                                   + '_GRU_weights.pt')\n","\n","    model_main = GRU(run.input_size, run.hidden_layer_size, run.num_layers, run.output_size, run.dropout_rate).to(device)\n","\n","    model_main.load_state_dict(m_state_dict_main)\n","\n","    with torch.no_grad():\n","\n","        for fips in test_states:\n","            for week in test_weeks:\n","                seq = df_test[(df_test.index.get_level_values('fips') == fips)\\\n","                 & (df_test.index.get_level_values('Week_end') <= week)][-run.seq_length:].to_numpy()\n","\n","                seq = torch.tensor(seq).reshape(-1, run.seq_length, run.input_size).to(device)\n","\n","                model_main.hidden = torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device)\n","                prediction = model_main(seq.float())\n","\n","                prediction = scaler_target.inverse_transform(prediction.cpu().detach().numpy().reshape(-1, 1))\n","\n","                dic = {\n","                    'fips' : fips,\n","                    'Week_end' : week,\n","                    'Prediction_1w' : prediction[0].item(),\n","                    'Prediction_2w' : prediction[1].item(),\n","                    'Prediction_3w' : prediction[2].item(),\n","                    'Prediction_4w' : prediction[3].item()\n","\n","                }\n","\n","                df_output = pd.concat([df_output, pd.DataFrame([dic])], ignore_index=True)\n","\n","\n","        df_output.to_csv(prediction_file + run.target + '_'  +str(run.lr) + '_' +\n","                            str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                            + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                            + '.csv')\n","\n","        '''\n","        Evaluation\n","        '''\n","\n","\n","\n","        dic_lstm = {\n","            'Model': 'GRU',\n","            'lr': run.lr,\n","            'batch_size': run.batch_size,\n","            'seq_length': run.seq_length,\n","            'week_range': run.week_range,\n","            'hidden_layer_size': run.hidden_layer_size,\n","            'num_layers': run.num_layers,\n","            'lossfunc': run.lossfunc,\n","\n","            'mse_validation': best_mse_numerical,\n","\n","            'mse_validation_1w': best_mse_numerical_weekly[0],\n","            'mse_validation_2w': best_mse_numerical_weekly[1],\n","            'mse_validation_3w': best_mse_numerical_weekly[2],\n","            'mse_validation_4w': best_mse_numerical_weekly[3],\n","\n","            'Target': run.target\n","        }\n","\n","        print('mse_validation:')\n","        print(dic_lstm['mse_validation'])\n","\n","\n","        df_summary = pd.concat([df_summary, pd.DataFrame([dic_lstm])], ignore_index=True)\n","\n","        df_summary.to_csv(summary_file + 'summarytest0.csv')"]},{"cell_type":"markdown","metadata":{"id":"DyTRgADeMHYa"},"source":["### run best model for 100 times"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.preprocessing import MinMaxScaler\n","from torch import nn\n","from tqdm import trange\n","from datetime import date, timedelta\n","\n","from collections import OrderedDict\n","from collections import namedtuple\n","from itertools import product\n","\n","import torch.nn.functional as F\n","\n","\n","n_result = pd.DataFrame()\n","data_file = '/content/drive/MyDrive/Flu Forecasting/code/trainingdata_rate0131.csv'\n","model_file = '/content/drive/MyDrive/Flu Forecasting/GRU/weightselection/'\n","prediction_file = '/content/drive/MyDrive/Flu Forecasting/GRU/weightselection/'\n","summary_file ='/content/drive/MyDrive/Flu Forecasting/GRU/weightselection/'\n","# read data\n","def perdelta(start, end, delta):\n","    curr = start\n","    while curr < end:\n","        yield curr\n","        curr += delta\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","\n","params = OrderedDict(\n","    target = ['rate'], ### Our target variable\n","    lr = [0.0001],\n","    batch_size = [2],\n","    seq_length = [12], # length of input sequence to predict values\n","    output_size = [4], # we are predicting next four weeks admissions\n","    num_pred_features = [1],\n","    week_range = [64], # number of historical data (per state) used to train the model\n","    input_size = [15], # total number of input features\n","    hidden_layer_size = [256], #test\n","    num_layers = [1], #test\n","    ratio = [0.7],  # ratio of training set and validation set\n","    num_epochs = [50],\n","    dropout_rate = [0.8],\n","    lossfunc = [nn.SmoothL1Loss(beta=0.05, reduction = 'sum'),\n","\n","                ]\n",")\n","\n","\n","class RunBuilder():\n","    @staticmethod\n","    def get_runs(params):\n","\n","        Run = namedtuple('Run', params.keys())\n","\n","        runs = []\n","        for v in product(*params.values()):\n","            runs.append(Run(*v))\n","\n","        return runs\n","\n","pd.options.mode.chained_assignment = None\n","\n","runs = RunBuilder.get_runs(params)\n","\n","for run in RunBuilder.get_runs(params):\n","    if run.target == 'rate':\n","        results_file = 'rate'\n","\n","    validation_predictions = []\n","    validation_labels = []\n","    # read data\n","    df = pd.read_csv(data_file)\n","    #df = df.rename(columns={'End Date': 'Week_end', 'State': 'fips'})\n","    df['Week_end'] = pd.to_datetime(df['Week_end'])\n","    # too many missing values in State'11'\n","    df =  df[df['fips'] != 11]\n","    #df =  df[df['fips'] == 1]\n","    #df = df[['fips', 'Week_end', 'total_admissions']]\n","    #df = df.drop(['PRCP_mean', 'SNOW_mean', 'TMAXDELTA', 'TMINDELTA'], axis=1)\n","    # choose data in 2023-11 as test data  test 10-01\n","    '''\n","    start_date1 = pd.to_datetime('2023-11-01') - timedelta(weeks=run.seq_length * 7)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] < pd.to_datetime('2023-11-26'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2023-11 as training data and validation data\n","    df_train = df[df['Week_end'] <= pd.to_datetime('2023-11-01')] # Use data before 11/1 as training set\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","'''\n","\n","    start_date1 = pd.to_datetime('2024-01-20') - timedelta(weeks=run.seq_length)\n","    df_test = df[(df['Week_end'] > start_date1) & (df['Week_end'] <pd.to_datetime('2024-01-26'))] # Use data after 2023-11-01 as testing set\n","    df_test = df_test.set_index(['fips', 'Week_end'])\n","    df_test1 = df_test.copy()\n","    #choose data before 2024-01-06 as training data and validation data and after 2022-08-01\n","    df_train = df[(df['Week_end'] <= pd.to_datetime('2024-01-20'))& (df['Week_end'] >pd.to_datetime('2022-08-01')) ] # Use data before 11/1 as training set\n","\n","    df_train = df_train.set_index(['fips', 'Week_end'])\n","    #rescale the data from 0 to 1, normalization\n","    first_col = df_train.pop(run.target)\n","    df_train.insert(0, run.target, first_col)\n","    first_col_2 = df_test.pop(run.target)\n","    df_test.insert(0, run.target, first_col_2)\n","\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","    scaler.fit(df_train.iloc[:, 1:])\n","    train_features_normalized = scaler.transform(df_train.iloc[:, 1:])\n","    test_feature_normalized = scaler.transform(df_test.iloc[:, 1:])\n","\n","    scaler_target = MinMaxScaler(feature_range=(0, 1))\n","    scaler_target.fit(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    train_target_normalized = scaler_target.transform(np.asarray(df_train.iloc[:, 0]).reshape(-1, 1))\n","    test_target_normalized = scaler_target.transform(np.asarray(df_test.iloc[:, 0]).reshape(-1, 1))\n","\n","    df_train.iloc[:, 1:] = train_features_normalized\n","    df_train.iloc[:, 0] = train_target_normalized\n","    df_test.iloc[:, 1:] = test_feature_normalized\n","    df_test.iloc[:, 0] = test_target_normalized\n","\n","\n","    for i in range(1000):\n","\n","      df_output = pd.DataFrame(columns=['fips', 'Week_end', 'Prediction_1w',\n","                                        'Prediction_2w', 'Prediction_3w',\n","                                        'Prediction_4w'])\n","\n","      test_weeks = df_test[df_test.index.get_level_values('Week_end') \\\n","                        >= pd.to_datetime('2024-01-20')].index.get_level_values('Week_end').unique()\n","      test_states = df_test.index.get_level_values('fips').unique()\n","\n","      m_state_dict_main = torch.load(model_file + run.target + '_'  +str(run.lr) + '_' +\n","                                    str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                                    + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                                    + '_GRU_weights.pt')\n","\n","      model_main = GRU(run.input_size, run.hidden_layer_size, run.num_layers, run.output_size, run.dropout_rate).to(device)\n","\n","      model_main.load_state_dict(m_state_dict_main)\n","\n","      with torch.no_grad():\n","\n","          for fips in test_states:\n","              for week in test_weeks:\n","                  seq = df_test[(df_test.index.get_level_values('fips') == fips)\\\n","                  & (df_test.index.get_level_values('Week_end') <= week)][-run.seq_length:].to_numpy()\n","\n","                  seq = torch.tensor(seq).reshape(-1, run.seq_length, run.input_size).to(device)\n","\n","                  model_main.hidden = torch.zeros(run.num_layers, seq.size(0), run.hidden_layer_size).to(device)\n","                  prediction = model_main(seq.float())\n","\n","                  prediction = scaler_target.inverse_transform(prediction.cpu().detach().numpy().reshape(-1, 1))\n","\n","                  dic = {\n","                      'fips' : fips,\n","                      'Week_end' : week,\n","                      'Prediction_1w' : prediction[0].item(),\n","                      'Prediction_2w' : prediction[1].item(),\n","                      'Prediction_3w' : prediction[2].item(),\n","                      'Prediction_4w' : prediction[3].item()\n","\n","                  }\n","\n","                  df_output = pd.concat([df_output, pd.DataFrame([dic])], ignore_index=True)\n","\n","\n","          df_output.to_csv(prediction_file + run.target + '_'  +str(run.lr) + '_' +\n","                              str(run.week_range) + '_' + str(run.hidden_layer_size) \\\n","                              + '_' + str(run.seq_length) + '_' + str(run.num_layers) \\\n","                              + '.csv')\n","          n_result= pd.concat([n_result, df_output], ignore_index=True)\n","\n","\n","    n_result.to_pickle(summary_file + 'allresulttest1.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ek9ttPXoYJzR","outputId":"7538b269-90f6-4fdb-95f2-95adce41423b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ux5Nf5cT9Dr"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EE9mROnd1u-L","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1706046446992,"user_tz":300,"elapsed":8,"user":{"displayName":"Shawn XU","userId":"03794891599117456463"}},"outputId":"a9e16903-f7c2-4d86-ae88-f3d21177c16c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      fips   Week_end  Prediction_1w  Prediction_2w  Prediction_3w  \\\n","0        1 2023-12-16       1.617280       1.146696       0.627724   \n","1        2 2023-12-16       0.245919       0.087149      -0.078879   \n","2        4 2023-12-16       3.430712       5.010484       4.956791   \n","3        5 2023-12-16       0.488530       0.196350       0.206587   \n","4        6 2023-12-16       1.144734       0.942700       0.767006   \n","...    ...        ...            ...            ...            ...   \n","49995   51 2023-12-16       1.061623       1.649244       1.543778   \n","49996   53 2023-12-16       0.098470       0.038732      -0.212735   \n","49997   54 2023-12-16       0.871705       0.616140       1.013480   \n","49998   55 2023-12-16       1.142060       1.293435       1.473662   \n","49999   56 2023-12-16       6.434525       8.506172       9.628937   \n","\n","       Prediction_4w  \n","0           1.514531  \n","1          -0.251350  \n","2           4.955416  \n","3           0.519681  \n","4           0.711150  \n","...              ...  \n","49995       2.170187  \n","49996      -0.420063  \n","49997       1.827708  \n","49998       1.732367  \n","49999       8.575683  \n","\n","[50000 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-54756ea7-d8e7-4306-85df-b5c40e6dc148\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fips</th>\n","      <th>Week_end</th>\n","      <th>Prediction_1w</th>\n","      <th>Prediction_2w</th>\n","      <th>Prediction_3w</th>\n","      <th>Prediction_4w</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2023-12-16</td>\n","      <td>1.617280</td>\n","      <td>1.146696</td>\n","      <td>0.627724</td>\n","      <td>1.514531</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2023-12-16</td>\n","      <td>0.245919</td>\n","      <td>0.087149</td>\n","      <td>-0.078879</td>\n","      <td>-0.251350</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>2023-12-16</td>\n","      <td>3.430712</td>\n","      <td>5.010484</td>\n","      <td>4.956791</td>\n","      <td>4.955416</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>2023-12-16</td>\n","      <td>0.488530</td>\n","      <td>0.196350</td>\n","      <td>0.206587</td>\n","      <td>0.519681</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>2023-12-16</td>\n","      <td>1.144734</td>\n","      <td>0.942700</td>\n","      <td>0.767006</td>\n","      <td>0.711150</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>51</td>\n","      <td>2023-12-16</td>\n","      <td>1.061623</td>\n","      <td>1.649244</td>\n","      <td>1.543778</td>\n","      <td>2.170187</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>53</td>\n","      <td>2023-12-16</td>\n","      <td>0.098470</td>\n","      <td>0.038732</td>\n","      <td>-0.212735</td>\n","      <td>-0.420063</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>54</td>\n","      <td>2023-12-16</td>\n","      <td>0.871705</td>\n","      <td>0.616140</td>\n","      <td>1.013480</td>\n","      <td>1.827708</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>55</td>\n","      <td>2023-12-16</td>\n","      <td>1.142060</td>\n","      <td>1.293435</td>\n","      <td>1.473662</td>\n","      <td>1.732367</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>56</td>\n","      <td>2023-12-16</td>\n","      <td>6.434525</td>\n","      <td>8.506172</td>\n","      <td>9.628937</td>\n","      <td>8.575683</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54756ea7-d8e7-4306-85df-b5c40e6dc148')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-54756ea7-d8e7-4306-85df-b5c40e6dc148 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-54756ea7-d8e7-4306-85df-b5c40e6dc148');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d1e9c13a-cb1f-4c07-b346-ae43ab9e193f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1e9c13a-cb1f-4c07-b346-ae43ab9e193f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d1e9c13a-cb1f-4c07-b346-ae43ab9e193f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_231df36f-b04e-4b9c-893f-f25a4b1461f7\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('n_result')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_231df36f-b04e-4b9c-893f-f25a4b1461f7 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('n_result');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":14}],"source":["n_result"]},{"cell_type":"code","source":[],"metadata":{"id":"ZFd7FcfCiLAP"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyMdASkEd5uLJTWsUp87GS3Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}